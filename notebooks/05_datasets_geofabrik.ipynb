{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4460eac-f6b8-4d46-b971-109ed6ba24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp datasets.geofabrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f3485c-20cb-44c9-a82d-3cef6a4047cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# no_test\n",
    "![ -e /content ] && pip install -Uqq geowrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ad1a2-b0df-4675-af9e-3223c8f36e31",
   "metadata": {},
   "source": [
    "# Datasets Geofabrik\n",
    "> Download geofabrik data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8022060f-88b9-4d07-9e32-6ce9dce27e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "import os\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from urllib.parse import urlparse\n",
    "from urllib.request import HTTPError\n",
    "\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "from fastcore.all import patch, urlcheck\n",
    "from loguru import logger\n",
    "\n",
    "from geowrangler.datasets.utils import make_report_hook, urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e33cd05-ad3e-4f20-8902-b961c8e58ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "DEFAULT_CACHE_DIR = \"~/.cache/geowrangler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57334510-4bc1-4a2b-a085-e839f456a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "@lru_cache(maxsize=None)\n",
    "def load_geofabrik_data():\n",
    "    return requests.get(\"https://download.geofabrik.de/index-v1-nogeom.json\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a30a6d-c28d-4be2-9325-ac7618d49a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def list_geofabrik_regions() -> dict:\n",
    "    \"\"\"Get list of regions from geofabrik index\"\"\"\n",
    "    geofabrik_data = load_geofabrik_data()\n",
    "    return {\n",
    "        k[\"properties\"][\"id\"]: k[\"properties\"][\"urls\"].get(\"shp\")\n",
    "        for k in geofabrik_data[\"features\"]\n",
    "        if k[\"properties\"][\"urls\"].get(\"shp\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6f3030-d40a-46c4-8685-9e5606a8798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_osm_download_url(region, year=None):\n",
    "    geofabrik_info = list_geofabrik_regions()\n",
    "    if region not in geofabrik_info:\n",
    "        raise ValueError(\n",
    "            f\"{region} not found in geofabrik. Run list_geofabrik_regions() to learn more about available areas\"\n",
    "        )\n",
    "    url = geofabrik_info[region]\n",
    "    if year is not None:\n",
    "        short_year = str(year)[-2:]  # take last 2 digits\n",
    "        year_prefix = f\"{short_year}0101\"\n",
    "        url = url.replace(\"latest\", year_prefix)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e382c869-35f0-40af-91a0-0385e236fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_download_filepath(url, directory):\n",
    "    parsed_url = urlparse(url)\n",
    "    filename = Path(os.path.basename(parsed_url.path))\n",
    "    filepath = directory / filename\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "422dd365-2772-44bc-a755-00269d576c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def download_geofabrik_region(\n",
    "    region: str,\n",
    "    directory: str = \"data/\",\n",
    "    overwrite=False,\n",
    "    year=None,\n",
    "    show_progress=True,\n",
    "    chunksize=8192,\n",
    ") -> Union[Path, None]:\n",
    "    \"\"\"Download geofabrik region to path\"\"\"\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory)\n",
    "    url = get_osm_download_url(region, year=year)\n",
    "    filepath = get_download_filepath(url, directory)\n",
    "\n",
    "    if not filepath.exists() or overwrite:\n",
    "        reporthook = make_report_hook(show_progress)\n",
    "\n",
    "        try:\n",
    "            filepath, _, _ = urlretrieve(\n",
    "                url, filepath, reporthook=reporthook, chunksize=chunksize\n",
    "            )\n",
    "        except HTTPError as err:\n",
    "            if err.code == 404:\n",
    "                if year is not None:\n",
    "                    logger.warning(\n",
    "                        f\"No data found for year {year} in region {region} : {url}\"\n",
    "                    )\n",
    "                else:\n",
    "                    logger.warning(f\"No url found for region {region} : {url} \")\n",
    "                return None\n",
    "            else:\n",
    "                raise err\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd0cb59e-7ee6-487c-bb8b-2e83cbd7f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def download_osm_region_data(\n",
    "    region,\n",
    "    year=None,\n",
    "    cache_dir=DEFAULT_CACHE_DIR,\n",
    "    use_cache=True,\n",
    "    chunksize=8192,\n",
    "    show_progress=True,\n",
    "):\n",
    "\n",
    "    osm_cache_dir = os.path.join(os.path.expanduser(cache_dir), \"osm/\")\n",
    "\n",
    "    url = get_osm_download_url(region, year)\n",
    "    region_zip_file = get_download_filepath(url, osm_cache_dir)\n",
    "    logger.info(\n",
    "        f\"OSM Data: Cached data available for {region} at {region_zip_file}? {region_zip_file.exists()}\"\n",
    "    )\n",
    "    if use_cache and region_zip_file.exists():\n",
    "        return region_zip_file\n",
    "\n",
    "    # Download if cache is invalid or user specified use_cache = False\n",
    "    if not urlcheck(url):\n",
    "        if year is None:\n",
    "            logger.warning(f\"OSM data for {region} is not available\")\n",
    "        else:\n",
    "            logger.warning(f\"OSM data for {region} and year {year} is not available\")\n",
    "        return None\n",
    "\n",
    "    logger.info(\n",
    "        f\"OSM Data: Re-initializing OSM region zip file at {region_zip_file}...\"\n",
    "    )\n",
    "    if region_zip_file.exists():\n",
    "        region_zip_file.unlink()\n",
    "\n",
    "    # This downloads a zip file to the region cache dir\n",
    "    logger.info(f\"OSM Data: Downloading Geofabrik in {region_zip_file}...\")\n",
    "    zipfile_path = download_geofabrik_region(\n",
    "        region,\n",
    "        year=year,\n",
    "        directory=osm_cache_dir,\n",
    "        overwrite=not use_cache,\n",
    "        show_progress=show_progress,\n",
    "        chunksize=chunksize,\n",
    "    )\n",
    "    if zipfile_path is None:\n",
    "        return None\n",
    "    if year is None:\n",
    "        logger.info(\n",
    "            f\"OSM Data: Successfully downloaded and cached OSM data for {region} at {zipfile_path}!\"\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"OSM Data: Successfully downloaded and cached OSM data for {region} and {year} at {zipfile_path}!\"\n",
    "        )\n",
    "\n",
    "    return zipfile_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d821382d-fd08-414f-b302-6941650fae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class OsmDataManager:\n",
    "    \"\"\"An instance of this class provides convenience functions for loading and caching OSM data\"\"\"\n",
    "\n",
    "    def __init__(self, cache_dir=DEFAULT_CACHE_DIR):\n",
    "        self.cache_dir = os.path.expanduser(cache_dir)\n",
    "        self.pois_cache = {}\n",
    "        self.roads_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9019916-7d44-40ce-93dc-dc736db0886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def load_pois(\n",
    "    self: OsmDataManager,\n",
    "    region,\n",
    "    year=None,\n",
    "    use_cache=True,\n",
    "    chunksize=1024 * 1024,\n",
    "    show_progress=True,\n",
    "):\n",
    "    # Get from RAM cache if already available\n",
    "    if year is None:\n",
    "        if region in self.pois_cache:\n",
    "            logger.debug(f\"OSM POIs for {region} found in cache.\")\n",
    "            return self.pois_cache[region]\n",
    "    else:\n",
    "        short_year = str(year)[-2:]\n",
    "        lookup = f\"{region}_{short_year}\"\n",
    "        if lookup in self.pois_cache:\n",
    "            logger.debug(f\"OSM POIs for {region} and year {year} found in cache.\")\n",
    "            return self.pois_cache[lookup]\n",
    "\n",
    "    # Otherwise, load from file and add to cache\n",
    "    region_zip_file = download_osm_region_data(\n",
    "        region,\n",
    "        year=year,\n",
    "        cache_dir=self.cache_dir,\n",
    "        use_cache=use_cache,\n",
    "        chunksize=chunksize,\n",
    "        show_progress=show_progress,\n",
    "    )\n",
    "    if region_zip_file is None:\n",
    "        return None\n",
    "\n",
    "    osm_pois_filepath = f\"{region_zip_file}!gis_osm_pois_free_1.shp\"\n",
    "    if year is None:\n",
    "        logger.debug(f\"OSM POIs for {region} being loaded from {region_zip_file}\")\n",
    "    else:\n",
    "        logger.debug(\n",
    "            f\"OSM POIs for {region} and year {year} being loaded from {region_zip_file}\"\n",
    "        )\n",
    "    gdf = gpd.read_file(osm_pois_filepath)\n",
    "\n",
    "    if year is None:\n",
    "        self.pois_cache[region] = gdf\n",
    "    else:\n",
    "        short_year = str(year)[-2:]\n",
    "        lookup = f\"{region}_{short_year}\"\n",
    "        self.pois_cache[lookup] = gdf\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a19e6acb-a7e9-4735-8ffd-bc7027bc0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@patch\n",
    "def load_roads(\n",
    "    self: OsmDataManager,\n",
    "    region,\n",
    "    year=None,\n",
    "    use_cache=True,\n",
    "    chunksize=1024 * 1024,\n",
    "    show_progress=True,\n",
    "):\n",
    "    # Get from RAM cache if already available\n",
    "    if year is None:\n",
    "        if region in self.roads_cache:\n",
    "            logger.debug(f\"OSM POIs for {region} found in cache.\")\n",
    "            return self.roads_cache[region]\n",
    "    else:\n",
    "        short_year = str(year)[-2:]\n",
    "        lookup = f\"{region}_{short_year}\"\n",
    "        if lookup in self.roads_cache:\n",
    "            logger.debug(f\"OSM POIs for {region} and year {year} found in cache.\")\n",
    "            return self.roads_cache[lookup]\n",
    "\n",
    "    # Otherwise, load from file and add to cache\n",
    "    region_zip_file = download_osm_region_data(\n",
    "        region,\n",
    "        year=year,\n",
    "        cache_dir=self.cache_dir,\n",
    "        use_cache=use_cache,\n",
    "        chunksize=chunksize,\n",
    "        show_progress=show_progress,\n",
    "    )\n",
    "\n",
    "    if region_zip_file is None:\n",
    "        return None\n",
    "\n",
    "    osm_roads_filepath = f\"{region_zip_file}!gis_osm_roads_free_1.shp\"\n",
    "    if year is None:\n",
    "        logger.debug(f\"OSM Roads for {region} being loaded from {region_zip_file}\")\n",
    "    else:\n",
    "        logger.debug(\n",
    "            f\"OSM Roads for {region} and year {year} being loaded from {region_zip_file}\"\n",
    "        )\n",
    "    gdf = gpd.read_file(osm_roads_filepath)\n",
    "\n",
    "    if year is None:\n",
    "        self.roads_cache[region] = gdf\n",
    "    else:\n",
    "        short_year = str(year)[-2:]\n",
    "        lookup = f\"{region}_{short_year}\"\n",
    "        self.roads_cache[lookup] = gdf\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23d8b707-6b41-426b-9135-a422d5a2ad37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 05_datasets_geofabrik.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# no_test\n",
    "\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script(\"05_datasets_geofabrik.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a07a05096b6351e45107f092fcbc6d58e4d1183d490a1128ce24e8ca5af3ddc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
