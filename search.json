[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geowrangler",
    "section": "",
    "text": "Overview\n  \nGeowrangler is a Python package for geodata wrangling. It helps you build data transformation workflows that have no out-of-the-box solutions from other geospatial libraries.\nWe surveyed our past geospatial projects to extract these solutions for our work and hope that these will be useful for others as well.\nOur audience are researchers, analysts, and engineers delivering geospatial projects.\nWe welcome your comments, suggestions, bug reports, and code contributions to make Geowrangler better.\n\n\n\nContext\nGeowrangler was borne out of our efforts to reduce the amount of boilerplate code in wrangling geospatial data. It builds on top of existing geospatial libraries such as geopandas, rasterio, rasterstats, morecantile, and others. Our goals are centered on the following tasks:\n\nExtracting area of interest zonal statistics from vector and raster data\nGridding areas of interest\nValidating geospatial datasets\nDownloading of publically available geospatial datasets (e.g., OSM, Ookla, and Nightlights)\nOther geospatial vector and raster data processing tasks\n\nTo make it easy to document, maintain, and extend the package, we opted to maintain the source code, tests and documentation on Jupyter notebooks. We use nbdev to generate the Python package and documentation from the notebooks. See this document to learn more about our development workflow.\nBy doing this, we hope to make it easy for geospatial analysts, scientists, and engineers to learn, explore, and extend this package for their geospatial processing needs.\nAside from providing reference documentation for each module, we have included extensive tutorials and use case examples in order to make it easy to learn and use.\n\n\nModules\n\nGrid Tile Generation\nGeometry Validation\nVector Zonal Stats\nRaster Zonal Stats\nArea Zonal Stats\nDistance Zonal Stats\nVector to Raster Mask\nRaster to Dataframe\nRaster Processing\nDemographic and Health Survey (DHS) Processing Utils\nGeofabrik (OSM) Data Download\nOokla Data Download\nNight Lights\nDataset Utils\nTile Clustering\nSpatial Join Highest Intersection\n\nCheck this page for more details about our Roadmap.\n\n\nInstallation\npip install geowrangler\n\n\nExploring the Documentation\nWe develop the package modules alongside their documentation. Each page comes with an Open in Colab button that will open the Jupyter notebook in Colab for exploration (including this page).\nClick on the Open in Colab button below to open this page as a Google Colab notebook.\n\n\n# view the source of a grid component\ngdf = gpd.GeoDataFrame()\ngrid = geowrangler.grids.SquareGridGenerator(gdf, 1)\ngrid??\n\n\nType:        SquareGridGenerator\nString form: &lt;geowrangler.grids.SquareGridGenerator object&gt;\nFile:        ~/work/unicef-ai4d/geowrangler-1/geowrangler/grids.py\nSource:     \nclass SquareGridGenerator:\n    def __init__(\n        self,\n        cell_size: float,  # height and width of a square cell in meters\n        grid_projection: str = \"EPSG:3857\",  # projection of grid output\n        boundary: Union[SquareGridBoundary, List[float]] = None,  # original boundary\n    ):\n        self.cell_size = cell_size\n        self.grid_projection = grid_projection\n        self.boundary = boundary\n\n\n\n\n\nTutorials\n\nGrids Generation\nGeometry Validation\nVector Zonal Stats\nRaster Zonal Stats\nArea Zonal Stats\nDistance Zonal Stats\nDHS Processing Utils\nDataset Downloads\nSpatial Join Using Highest Intersection\nTile Clustering\nRaster Processing\nRaster to Dataframe\n\n\n\nReference\n\nGrids Generation\nPolygon Fill Algorithms\nGeometry Validation\nVector Zonal Stats\nRaster Zonal Stats\nArea Zonal Stats\nDistance Zonal Stats\nDHS Processing Utils\nDataset Geofabrik (OSM)\nDataset Ookla\n\n\n\n\n\n\n\nNote\n\n\n\nAll the documentation pages (including the references) are executable Jupyter notebooks.",
    "crumbs": [
      "Geowrangler"
    ]
  },
  {
    "objectID": "tutorial.vector_zonal_stats.html",
    "href": "tutorial.vector_zonal_stats.html",
    "title": "Vector Zonal Stats Tutorial",
    "section": "",
    "text": "A basic introduction to vector zonal stats",
    "crumbs": [
      "Tutorials",
      "Vector Zonal Stats Tutorial"
    ]
  },
  {
    "objectID": "tutorial.vector_zonal_stats.html#basic-usage",
    "href": "tutorial.vector_zonal_stats.html#basic-usage",
    "title": "Vector Zonal Stats Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nGenerate zonal stats for a GeoDataframe containing areas of interest\nTerms:\n\naoi - (area of interest) a geodataframe which we are interested in generating zonal statistics for\ndata - the source geodataframe containing the features which are interested in collecting zonal stats for our aoi.\n\n\nUse case 1 - Count POIs (Points of Interest)\n\nExample 1: Count POIs for Regions\n\nInput:\n\naoi - region3,4,ncr regions (Admin Level 1) (Central Luzon) geometry (geom_type - polygon, multipolygon\ndata - Philippine pois (geom_type - points)\noverlap_method = ‘intersects’\naggregations:\n\ncount - number of pois within aoi\n\n\nOutput\n\naoi with pois count (default output column: index_count)\n\n\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport geowrangler.vector_zonal_stats as vzs\n\n\n# area multipolygons for regions 3,4,ncr of the philippines\naoi = gpd.read_file(\"../data/region34ncr_admin.geojson\")\n\nCPU times: user 1.42 s, sys: 97.1 ms, total: 1.52 s\nWall time: 1.54 s\n\n\n\nax = aoi.plot(\n    ax=plt.axes(),\n    facecolor=\"none\",\n    edgecolor=[\n        \"#C62828\",\n        \"#283593\",\n        \"#FF9800\",\n    ],\n)\n\n\n\n\n\n\n\n\n\naoi\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n\n\n\n\n\n\n\n\n# raw pois from osm data (subset of region3,4, ncr only)\nraw_data = gpd.read_file(\"../data/region34ncr_osm_pois.geojson\")\n\nCPU times: user 29.7 ms, sys: 1.75 ms, total: 31.4 ms\nWall time: 32.6 ms\n\n\n\nraw_data.columns.values\n\narray(['osm_id', 'code', 'fclass', 'name', 'BARANGAY_CODE', 'geometry'],\n      dtype=object)\n\n\n\nraw_data.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nBARANGAY_CODE\ngeometry\n\n\n\n\n0\n311568428\n2701\ntourist_info\nManila American Cemetery and Memorial Visitor ...\n137602022\nPOINT (121.04852 14.54398)\n\n\n1\n672565496\n2701\ntourist_info\necopark paging and first aid station\n137404141\nPOINT (121.07479 14.71173)\n\n\n2\n672565498\n2701\ntourist_info\nEcopark ticket counter\n137404141\nPOINT (121.07326 14.71291)\n\n\n3\n1585389544\n2701\ntourist_info\nArea Formerly Occupied by Fort Bonifacio Museum\n137602021\nPOINT (121.05837 14.55071)\n\n\n4\n1834855424\n2701\ntourist_info\nLotto Booth\n137601020\nPOINT (120.99216 14.42312)\n\n\n\n\n\n\n\n\nax = aoi.plot(\n    ax=plt.axes(),\n    facecolor=\"none\",\n    edgecolor=[\n        \"#C62828\",\n        \"#283593\",\n        \"#FF9800\",\n    ],\n)\nax = raw_data.plot(ax=ax)\n\n\n\n\n\n\n\n\nCompute POIs count per region\n\naoi = vzs.create_zonal_stats(\n    aoi,\n    raw_data,\n    overlap_method=\"intersects\",\n    aggregations=[{\"func\": \"count\"}],\n)\n\nCPU times: user 50.6 ms, sys: 7.81 ms, total: 58.4 ms\nWall time: 59.3 ms\n\n\nNew aoi with pois count in the column index_count. (The column name can be overridden as shown in the next example)\n\naoi\n\nCPU times: user 1 µs, sys: 0 ns, total: 1 µs\nWall time: 2.86 µs\n\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\nindex_count\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n880\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n701\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n1253\n\n\n\n\n\n\n\n\n\nExample 2: Count attractions for Regions\n\nInput:\n\naoi - region3,4,ncr regions (Admin Level 1) (Central Luzon, NCR, Calabarzon) geometry (geom_type - polygon, multipolygon)\ndata - attractions: filtered Philippine pois (Central Luzon, NCR, Calabarzon only) (geom_type - points) with fclass == ‘attraction’\noverlap_method = ‘intersects’\naggregations:\n\ncount\n\nnumber of pois within aoi\noutput column name attractions\n\n\n\nOutput\n\naoi with attractions count\n\n\nFilter the raw data\n\n# select only 'attraction' pois\nattractions = raw_data[raw_data.fclass == \"attraction\"]\n\n\nattractions.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nBARANGAY_CODE\ngeometry\n\n\n\n\n49\n159473554\n2721\nattraction\nChinatown Arch\n133902005\nPOINT (120.97671 14.59672)\n\n\n50\n622413978\n2721\nattraction\nPeace Bell\n137404020\nPOINT (121.04934 14.65026)\n\n\n51\n625180701\n2721\nattraction\nThe Glass Garden\n137403027\nPOINT (121.08194 14.61932)\n\n\n52\n681222977\n2721\nattraction\nLa Madre Filipina\n133908008\nPOINT (120.97773 14.58172)\n\n\n53\n820634039\n2721\nattraction\nIndependence Flag Pole\n133908008\nPOINT (120.97659 14.58155)\n\n\n\n\n\n\n\nCreate zonal stats for filtered data. Add output key to specify output column name for count\n\naoi_attr = vzs.create_zonal_stats(\n    aoi, attractions, aggregations=[{\"func\": \"count\", \"output\": \"attractions\"}]\n)\n\nCPU times: user 48 ms, sys: 6.33 ms, total: 54.4 ms\nWall time: 54.2 ms\n\n\n\naoi_attr\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\nattractions\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n136\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n205\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n312\n\n\n\n\n\n\n\n\n\nExample 3: Grid Tiles over POIs\n\nInput:\n\naoi - gridded tiles for Region 3 (Central Luzon) at 15km x 15km size\ndata - region 3 data filtered from philippine pois (geom_type - points)\noverlap_method = ‘intersects’\naggregations:\n\ncount\n\nnumber of pois within aoi\noutput column name:: pois_count\n\n\n\nOutput\n\naoi with pois count\n\n\n\n# load gridded tiles\ngrid_aoi = gpd.read_file(\"../data/region3_admin_grids.geojson\")\n\nCPU times: user 15.3 ms, sys: 808 µs, total: 16.1 ms\nWall time: 16.3 ms\n\n\n\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"#C62828\"\n)\nax = grid_aoi.plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\")\n\n\n\n\n\n\n\n\n\nregion3_pois = gpd.read_file(\"../data/region3_osm_pois.geojson\")\n\nCPU times: user 9.35 ms, sys: 467 µs, total: 9.81 ms\nWall time: 11 ms\n\n\n\nregion3_pois.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nBARANGAY_CODE\ngeometry\n\n\n\n\n0\n560410986\n2701\ntourist_info\nGawad Kalinga Office\n031420009\nPOINT (121.08516 14.83601)\n\n\n1\n1244301672\n2701\ntourist_info\nN 15deg 26' 11.1\", E 120deg 25' 50.2\", El...\n036918006\nPOINT (120.43045 15.43663)\n\n\n2\n1666684393\n2701\ntourist_info\nEco Park Tourist Information & DENR Environmen...\n036918006\nPOINT (120.44958 15.46446)\n\n\n3\n1679992929\n2701\ntourist_info\nLa Paz Tarlac - Zaragoza Nueva Ecija Boundary\n034932027\nPOINT (120.75832 15.44284)\n\n\n4\n1714645729\n2701\ntourist_info\nLucy Pineda\n035409019\nPOINT (120.61452 15.23359)\n\n\n\n\n\n\n\n\nlen(region3_pois)\n\n701\n\n\n\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"#C62828\"\n)\nax = region3_pois.plot(ax=ax)\n\n\n\n\n\n\n\n\nCompute pois count per grid\n\ngrid_aoi = vzs.create_zonal_stats(\n    grid_aoi,\n    region3_pois,\n    overlap_method=\"intersects\",\n    aggregations=[{\"func\": \"count\", \"output\": \"pois_count\"}],\n)\n\nCPU times: user 5.76 ms, sys: 860 µs, total: 6.62 ms\nWall time: 6.56 ms\n\n\n\ngrid_aoi[grid_aoi.pois_count &gt; 0].head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\npois_count\n\n\n\n\n11\n2\n28\nPOLYGON ((119.87566 15.6222, 119.92058 15.6222...\n1.0\n\n\n14\n2\n31\nPOLYGON ((119.87566 15.75193, 119.92058 15.751...\n1.0\n\n\n18\n3\n23\nPOLYGON ((119.92058 15.40581, 119.9655 15.4058...\n1.0\n\n\n21\n3\n26\nPOLYGON ((119.92058 15.53567, 119.9655 15.5356...\n4.0\n\n\n22\n3\n27\nPOLYGON ((119.92058 15.57894, 119.9655 15.5789...\n1.0\n\n\n\n\n\n\n\n\ngrid_aoi.pois_count.sum()\n\nnp.float64(701.0)\n\n\n\n# show grids with at least 1 poi\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(),\n    facecolor=\"none\",\n    edgecolor=[\n        \"#C62828\",\n    ],\n)\nax = grid_aoi[grid_aoi.pois_count &gt; 0].plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\n\n\n\n\n\nUse case 2 - Stats on a metric column\n\nExample 1 Regions over Population per Bgy Level\n\nInput:\n\naoi - region3,4,ncr geometry (geom_type - polygon, multipolygon)\ndata - region3,4, ncr population data (geom_type - pois)\ndata_type: ‘individual_pois’\noverlap_method = ‘intersects’\naggregations:\n\nmetric_columns: ‘population’,‘men’, etc.\n\neach row in the data has a column: population, men, women, etc. with numeric value\naggregation_functions - ‘min’,‘max’, ‘mean’, ‘sum’, etc.\noutput_columns - ‘pop_min’, ‘pop_max’, for each column\n\n\n\nOutput:\n\naoi with new output columns pop_min, pop_max etc\n\n\nLoad 2020 Region 3, Region 4, and NCR Population Data at Barangay level (Admin Level 4)\n\n\n\n\n\n\nNote\n\n\n\nThe population data came from the 2020 Facebook HRSL Dataset filtered for barangays covering Regions 3, Region 4, and NCR and converted the geometries from polygons to points by computing their centroids (projected to EPSG:3969). The land area was computed by projecting to EPSG:3123 and getting the geometry.area .\n\n\n\n# load region3,4,ncr population data at barangay level\nregion34ncr_pop_data = gpd.read_file(\"../data/region34ncr_population_land.geojson\")\n\nCPU times: user 115 ms, sys: 2.42 ms, total: 117 ms\nWall time: 121 ms\n\n\n\nregion34ncr_pop_data.head()\n\n\n\n\n\n\n\n\nBARANGAY_CODE\npopulation\nmen\nwomen\nchildren_under_five\nyouth_15_24\nwomen_of_reproductive_age_15_49\nelderly_60_plus\nland_area\ngeometry\n\n\n\n\n0\n31420020.0\n1807\n920\n887\n202\n359\n468\n77\n2.183518e+05\nPOINT (121.05919 14.85825)\n\n\n1\n34915006.0\n3093\n1594\n1499\n352\n658\n826\n159\n7.327482e+06\nPOINT (120.9959 15.62242)\n\n\n2\n35403009.0\n4241\n2158\n2083\n474\n821\n1112\n256\n8.740450e+05\nPOINT (120.7773 15.1458)\n\n\n3\n35409023.0\n3373\n1750\n1623\n296\n611\n895\n244\n6.484611e+05\nPOINT (120.58052 15.22315)\n\n\n4\n35413009.0\n20884\n10539\n10344\n2198\n3893\n5589\n1260\n2.015571e+06\nPOINT (120.68523 15.09163)\n\n\n\n\n\n\n\n\nregion34ncr_pop_data.columns.values\n\narray(['BARANGAY_CODE', 'population', 'men', 'women',\n       'children_under_five', 'youth_15_24',\n       'women_of_reproductive_age_15_49', 'elderly_60_plus', 'land_area',\n       'geometry'], dtype=object)\n\n\nCompute zonal stats for regions 3,4,NCR * barangay count per region (bgy_count) * sum and mean for each population statistic (population, men, women, etc) * sum, mean, std, min, max for land area statistic\n\naoi = vzs.create_zonal_stats(\n    aoi,\n    region34ncr_pop_data,\n    aggregations=[\n        {\"func\": \"count\", \"output\": \"bgy_count\"},\n        {\n            \"column\": \"population\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"pop_total\", \"pop_avg\"],\n        },\n        {\"column\": \"men\", \"func\": [\"sum\", \"mean\"], \"output\": [\"men_total\", \"men_avg\"]},\n        {\n            \"column\": \"women\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"women_total\", \"women_avg\"],\n        },\n        {\n            \"column\": \"children_under_five\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"under5_total\", \"under5_avg\"],\n        },\n        {\n            \"column\": \"youth_15_24\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"youth_total\", \"youth_avg\"],\n        },\n        {\n            \"column\": \"women_of_reproductive_age_15_49\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"women_repro_total\", \"women_repro_avg\"],\n        },\n        {\n            \"column\": \"elderly_60_plus\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"elderly_total\", \"elderly_avg\"],\n        },\n        {\n            \"column\": \"land_area\",\n            \"func\": [\"sum\", \"mean\", \"min\", \"max\", \"std\"],\n            \"output\": [\"land_total\", \"land_avg\", \"land_min\", \"land_max\", \"land_std\"],\n        },\n    ],\n    overlap_method=\"intersects\",\n)\n\nCPU times: user 60.5 ms, sys: 8.71 ms, total: 69.2 ms\nWall time: 71.2 ms\n\n\n\naoi.columns.values\n\narray(['Reg_Code', 'Reg_Name', 'Reg_Alt_Name', 'geometry', 'bgy_count',\n       'pop_total', 'pop_avg', 'men_total', 'men_avg', 'women_total',\n       'women_avg', 'under5_total', 'under5_avg', 'youth_total',\n       'youth_avg', 'women_repro_total', 'women_repro_avg',\n       'elderly_total', 'elderly_avg', 'land_total', 'land_avg',\n       'land_min', 'land_max', 'land_std'], dtype=object)\n\n\n\naoi.head()\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\nbgy_count\npop_total\npop_avg\nmen_total\nmen_avg\nwomen_total\n...\nyouth_avg\nwomen_repro_total\nwomen_repro_avg\nelderly_total\nelderly_avg\nland_total\nland_avg\nland_min\nland_max\nland_std\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n1707\n12484535\n7313.728764\n6132828\n3592.752197\n6350844\n...\n1468.077329\n3699839\n2167.451084\n653306\n382.721734\n5.945955e+08\n3.483277e+05\n2890.947906\n2.750653e+07\n1.065422e+06\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n3099\n10581859\n3414.604389\n5353309\n1727.431107\n5227035\n...\n655.773475\n2808810\n906.360116\n664150\n214.311068\n2.120885e+10\n6.843771e+06\n9589.467114\n3.496501e+08\n1.826504e+07\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n4010\n14081857\n3511.685037\n7035334\n1754.447382\n7044548\n...\n671.226185\n3857217\n961.899501\n780294\n194.587032\n1.551525e+10\n3.869139e+06\n3087.452331\n4.310269e+08\n1.119929e+07\n\n\n\n\n3 rows × 24 columns\n\n\n\n\n\nExample 2 : Grids over Population per Bgy Level\n\nInput:\n\naoi - region3 grids geometry (geom_type - polygon)\ndata - population data (geom_type - pois)\ndata_type: ‘individual_pois’\noverlap_method = ‘intersects’\naggregations:\n\nmetric_columns: ‘population’,‘men’, ‘land_area’\n\neach row in the data has a column population, men, women, including land with numeric value\naggregation_functions - ‘min’,‘max’, ‘mean’, ‘sum’, etc.\noutput_columns - ‘pop_min’, ‘pop_max’, for each\n\n\n\nOutput:\n\naoi with new columns pop_min, pop_max etc.\n\n\nLoad population and land POIs (Bgy level)\n\n\n\n\n\n\nNote\n\n\n\nThe dataset is similar to the previous one (Region 3, Region 4, and NCR) except that it has been filtered only data for the Region 3.\n\n\n\nregion3_pop_pois = gpd.read_file(\"../data/region3_population_pois.geojson\")\n\nCPU times: user 46.6 ms, sys: 1.15 ms, total: 47.7 ms\nWall time: 48.7 ms\n\n\n\nregion3_pop_pois.head()\n\n\n\n\n\n\n\n\nBARANGAY_CODE\npopulation\nmen\nwomen\nchildren_under_five\nyouth_15_24\nwomen_of_reproductive_age_15_49\nelderly_60_plus\nland_area\nReg_Name\ngeometry\n\n\n\n\n0\n31420020.0\n1807\n920\n887\n202\n359\n468\n77\n2.183518e+05\nRegion III\nPOINT (121.05919 14.85825)\n\n\n1\n34915006.0\n3093\n1594\n1499\n352\n658\n826\n159\n7.327482e+06\nRegion III\nPOINT (120.9959 15.62242)\n\n\n2\n35403009.0\n4241\n2158\n2083\n474\n821\n1112\n256\n8.740450e+05\nRegion III\nPOINT (120.7773 15.1458)\n\n\n3\n35409023.0\n3373\n1750\n1623\n296\n611\n895\n244\n6.484611e+05\nRegion III\nPOINT (120.58052 15.22315)\n\n\n4\n35413009.0\n20884\n10539\n10344\n2198\n3893\n5589\n1260\n2.015571e+06\nRegion III\nPOINT (120.68523 15.09163)\n\n\n\n\n\n\n\n\nregion3_pop_pois.columns.values\n\narray(['BARANGAY_CODE', 'population', 'men', 'women',\n       'children_under_five', 'youth_15_24',\n       'women_of_reproductive_age_15_49', 'elderly_60_plus', 'land_area',\n       'Reg_Name', 'geometry'], dtype=object)\n\n\nCreate zonal stats (same as previous example, but now for a more granular level for region 3 only)\n\ngrid_aoi = vzs.create_zonal_stats(\n    grid_aoi,\n    region3_pop_pois,\n    aggregations=[\n        {\"func\": \"count\", \"output\": \"bgy_count\"},\n        {\n            \"column\": \"population\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"pop_total\", \"pop_avg\"],\n        },\n        {\"column\": \"men\", \"func\": [\"sum\", \"mean\"], \"output\": [\"men_total\", \"men_avg\"]},\n        {\n            \"column\": \"women\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"women_total\", \"women_avg\"],\n        },\n        {\n            \"column\": \"children_under_five\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"under5_total\", \"under5_avg\"],\n        },\n        {\n            \"column\": \"youth_15_24\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"youth_total\", \"youth_avg\"],\n        },\n        {\n            \"column\": \"women_of_reproductive_age_15_49\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"women_repro_total\", \"women_repro_avg\"],\n        },\n        {\n            \"column\": \"elderly_60_plus\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"elderly_total\", \"elderly_avg\"],\n        },\n        {\n            \"column\": \"land_area\",\n            \"func\": [\"sum\", \"mean\", \"min\", \"max\", \"std\"],\n            \"output\": [\"land_total\", \"land_avg\", \"land_min\", \"land_max\", \"land_std\"],\n        },\n    ],\n    overlap_method=\"intersects\",\n)\n\nCPU times: user 9.92 ms, sys: 1.11 ms, total: 11 ms\nWall time: 10.8 ms\n\n\n\ngrid_aoi.head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\npois_count\nbgy_count\npop_total\npop_avg\nmen_total\nmen_avg\nwomen_total\n...\nyouth_avg\nwomen_repro_total\nwomen_repro_avg\nelderly_total\nelderly_avg\nland_total\nland_avg\nland_min\nland_max\nland_std\n\n\n\n\n0\n0\n30\nPOLYGON ((119.78583 15.7087, 119.83075 15.7087...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n0\n31\nPOLYGON ((119.78583 15.75193, 119.83075 15.751...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n0\n32\nPOLYGON ((119.78583 15.79516, 119.83075 15.795...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n1\n30\nPOLYGON ((119.83075 15.7087, 119.87566 15.7087...\nNaN\n1.0\n3415.0\n3415.0\n1744.0\n1744.0\n1670.0\n...\n648.0\n848.0\n848.0\n229.0\n229.0\n5.552401e+06\n5.552401e+06\n5.552401e+06\n5.552401e+06\nNaN\n\n\n4\n1\n32\nPOLYGON ((119.83075 15.79516, 119.87566 15.795...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 24 columns\n\n\n\nShow grids with bgy_count &gt; 0 and bgy_count == 0\n\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"black\"\n)\nax = grid_aoi[grid_aoi.bgy_count.notna()].plot(\n    ax=ax, facecolor=\"none\", edgecolor=\"blue\"\n)\nax = grid_aoi[grid_aoi.bgy_count.isna()].plot(ax=ax, facecolor=\"none\", edgecolor=\"red\")",
    "crumbs": [
      "Tutorials",
      "Vector Zonal Stats Tutorial"
    ]
  },
  {
    "objectID": "tutorial.vector_zonal_stats.html#generating-bing-tile-grid-zonal-stats",
    "href": "tutorial.vector_zonal_stats.html#generating-bing-tile-grid-zonal-stats",
    "title": "Vector Zonal Stats Tutorial",
    "section": "Generating Bing Tile Grid Zonal Stats",
    "text": "Generating Bing Tile Grid Zonal Stats\nIf our areas of interest use Bing Tile Grids (with the associated quadkeys),\nwe can use a much faster way of generating zonal stats by pre-computing the quadkeys for our data.\n\n\n\n\n\n\nNote\n\n\n\nYou can use the geowrangler.grids modules BingTileGridGenerator to convert your AOI into a Bing Tile Grid AOI.\n\n\n\nExample 1: Count POIs for Region 3 Bing Tile Grid AOI\n\nInput:\n\naoi bing tile grids zoom level 13 - region3 (Admin Level 1) (Central Luzon) geometry (geom_type - polygon, multipolygon)\ndata - Region 3 pois (geom_type - points)\naggregations:\n\ncount - number of pois within aoi\n\n\nOutput\n\naoi with pois count (default output column: index_count)\n\n\nLoad our bing tile grid aoi\n\n# load region3_admin area in bing tile grid ('ADM level 1 - Philippines, region 3, zoom level13')\n\nregion3_bingtile_grid = gpd.read_file(\"../data/region3_bingtile_grid13.geojson\")\n\n\nregion3_bingtile_grid.head()\n\n\n\n\n\n\n\n\nquadkey\ngeometry\n\n\n\n\n0\n1323030303301\nPOLYGON ((120.10254 14.73239, 120.10254 14.774...\n\n\n1\n1323030303300\nPOLYGON ((120.05859 14.73239, 120.05859 14.774...\n\n\n2\n1323030303311\nPOLYGON ((120.19043 14.73239, 120.19043 14.774...\n\n\n3\n1323030303133\nPOLYGON ((120.19043 14.77488, 120.19043 14.817...\n\n\n4\n1323030303131\nPOLYGON ((120.19043 14.81737, 120.19043 14.859...\n\n\n\n\n\n\n\n\nax = plt.axes()\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\")\nax = region3_bingtile_grid.plot(ax=ax, facecolor=\"none\", edgecolor=\"red\")\n\n\n\n\n\n\n\n\nLets compute the quadkeys for our Region3 pois\n\nDATA_ZOOM_LEVEL = 23  # for pois, it can be as high as 24\n\n\nregion3_pois_quadkeys = vzs.compute_quadkey(region3_pois, DATA_ZOOM_LEVEL)\n\nCPU times: user 19.4 ms, sys: 861 µs, total: 20.2 ms\nWall time: 20.4 ms\n\n\n\nregion3_pois_quadkeys.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nBARANGAY_CODE\ngeometry\nquadkey\n\n\n\n\n0\n560410986\n2701\ntourist_info\nGawad Kalinga Office\n031420009\nPOINT (121.08516 14.83601)\n13230312020312101332220\n\n\n1\n1244301672\n2701\ntourist_info\nN 15deg 26' 11.1\", E 120deg 25' 50.2\", El...\n036918006\nPOINT (120.43045 15.43663)\n13230301323000331033200\n\n\n2\n1666684393\n2701\ntourist_info\nEco Park Tourist Information & DENR Environmen...\n036918006\nPOINT (120.44958 15.46446)\n13230301321223132232132\n\n\n3\n1679992929\n2701\ntourist_info\nLa Paz Tarlac - Zaragoza Nueva Ecija Boundary\n034932027\nPOINT (120.75832 15.44284)\n13230301332111310110220\n\n\n4\n1714645729\n2701\ntourist_info\nLucy Pineda\n035409019\nPOINT (120.61452 15.23359)\n13230303110021032011230\n\n\n\n\n\n\n\nLets compute the zonal stats for each grid as the pois_count. &gt; Notice the computation time is pretty fast\n\nregion3_bingtile_pois = vzs.create_bingtile_zonal_stats(\n    region3_bingtile_grid,\n    region3_pois_quadkeys,\n    aggregations=[dict(func=\"count\", output=\"pois_count\", fillna=True)],\n)\n\nCPU times: user 6.03 ms, sys: 817 µs, total: 6.85 ms\nWall time: 6.36 ms\n\n\n\nregion3_bingtile_pois[region3_bingtile_pois.pois_count &gt; 0].head()\n\n\n\n\n\n\n\n\nquadkey\ngeometry\npois_count\n\n\n\n\n5\n1323030312020\nPOLYGON ((120.23438 14.81737, 120.23438 14.859...\n8.0\n\n\n8\n1323030121200\nPOLYGON ((119.88281 15.74996, 119.88281 15.792...\n1.0\n\n\n11\n1323030121222\nPOLYGON ((119.88281 15.62304, 119.88281 15.665...\n1.0\n\n\n13\n1323030123002\nPOLYGON ((119.88281 15.53838, 119.88281 15.580...\n1.0\n\n\n22\n1323030123001\nPOLYGON ((119.92676 15.58071, 119.92676 15.623...\n1.0\n\n\n\n\n\n\n\n\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"black\"\n)\nax = region3_bingtile_pois[region3_bingtile_pois.pois_count &gt; 0].plot(\n    column=\"pois_count\", ax=ax, edgecolor=\"blue\", alpha=0.4\n)\nax = region3_bingtile_pois[region3_bingtile_pois.pois_count == 0].plot(\n    ax=ax, facecolor=\"none\", edgecolor=\"red\", alpha=0.4\n)\n\n\n\n\n\n\n\n\n\n\nExample 2: Population stats for Region 3 Bing Tile Grid AOI\n\nInput:\n\naoi bing tile grids zoom level 13 - region3 (Admin Level 1) (Central Luzon) geometry (geom_type - polygon, multipolygon)\ndata - Region 3 pop data (geom_type - points)\naggregations:\n\npop totals, avg, men total and avg, etc , barangay counts, etc.\n\n\nOutput\n\naoi bing tile grids zoom level 13 with additional stats\n\n\nWe can also reuse the region34ncr population data to add more zonal statistics to our region3 bingtile pois\n\n# Add quadkeys to region34ncr population data\nregion34ncr_pop_data = vzs.compute_quadkey(\n    region34ncr_pop_data, DATA_ZOOM_LEVEL\n)\n\nCPU times: user 180 ms, sys: 775 µs, total: 180 ms\nWall time: 180 ms\n\n\n\nregion34ncr_pop_data.head()\n\n\n\n\n\n\n\n\nBARANGAY_CODE\npopulation\nmen\nwomen\nchildren_under_five\nyouth_15_24\nwomen_of_reproductive_age_15_49\nelderly_60_plus\nland_area\ngeometry\nquadkey\n\n\n\n\n0\n31420020.0\n1807\n920\n887\n202\n359\n468\n77\n2.183518e+05\nPOINT (121.05919 14.85825)\n13230312020301100210231\n\n\n1\n34915006.0\n3093\n1594\n1499\n352\n658\n826\n159\n7.327482e+06\nPOINT (120.9959 15.62242)\n13230310220010101012220\n\n\n2\n35403009.0\n4241\n2158\n2083\n474\n821\n1112\n256\n8.740450e+05\nPOINT (120.7773 15.1458)\n13230303111220301103213\n\n\n3\n35409023.0\n3373\n1750\n1623\n296\n611\n895\n244\n6.484611e+05\nPOINT (120.58052 15.22315)\n13230303101131332000021\n\n\n4\n35413009.0\n20884\n10539\n10344\n2198\n3893\n5589\n1260\n2.015571e+06\nPOINT (120.68523 15.09163)\n13230303112102100203003\n\n\n\n\n\n\n\n\nregion3_bingtile_pois_pop_data = vzs.create_bingtile_zonal_stats(\n    region3_bingtile_pois,  # reuse from previous example\n    region34ncr_pop_data,  # updated with quadkeys\n    aggregations=[\n        {\"func\": \"count\", \"output\": \"bgy_count\"},\n        {\n            \"column\": \"population\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"pop_total\", \"pop_avg\"],\n        },\n        {\"column\": \"men\", \"func\": [\"sum\", \"mean\"], \"output\": [\"men_total\", \"men_avg\"]},\n        {\n            \"column\": \"women\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"women_total\", \"women_avg\"],\n        },\n        {\n            \"column\": \"children_under_five\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"under5_total\", \"under5_avg\"],\n        },\n        {\n            \"column\": \"youth_15_24\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"youth_total\", \"youth_avg\"],\n        },\n        {\n            \"column\": \"women_of_reproductive_age_15_49\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"women_repro_total\", \"women_repro_avg\"],\n        },\n        {\n            \"column\": \"elderly_60_plus\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"elderly_total\", \"elderly_avg\"],\n        },\n        {\n            \"column\": \"land_area\",\n            \"func\": [\"sum\", \"mean\", \"min\", \"max\", \"std\"],\n            \"output\": [\"land_total\", \"land_avg\", \"land_min\", \"land_max\", \"land_std\"],\n        },\n    ],\n)\n\nCPU times: user 12.1 ms, sys: 672 µs, total: 12.8 ms\nWall time: 12.2 ms\n\n\n\nregion3_bingtile_pois_pop_data[region3_bingtile_pois_pop_data.bgy_count.notna()].head()\n\n\n\n\n\n\n\n\nquadkey\ngeometry\npois_count\nbgy_count\npop_total\npop_avg\nmen_total\nmen_avg\nwomen_total\nwomen_avg\n...\nyouth_avg\nwomen_repro_total\nwomen_repro_avg\nelderly_total\nelderly_avg\nland_total\nland_avg\nland_min\nland_max\nland_std\n\n\n\n\n5\n1323030312020\nPOLYGON ((120.23438 14.81737, 120.23438 14.859...\n8.0\n5.0\n40890.0\n8178.000000\n20398.0\n4079.600000\n20490.0\n4098.000000\n...\n1662.000000\n11493.0\n2298.600000\n2337.0\n467.4\n4.156777e+06\n8.313554e+05\n1.319242e+05\n2.503691e+06\n9.727404e+05\n\n\n6\n1323030120313\nPOLYGON ((119.83887 15.70766, 119.83887 15.749...\n0.0\n1.0\n3415.0\n3415.000000\n1744.0\n1744.000000\n1670.0\n1670.000000\n...\n648.000000\n848.0\n848.000000\n229.0\n229.0\n5.552401e+06\n5.552401e+06\n5.552401e+06\n5.552401e+06\nNaN\n\n\n7\n1323030121022\nPOLYGON ((119.88281 15.79225, 119.88281 15.834...\n0.0\n1.0\n4742.0\n4742.000000\n2438.0\n2438.000000\n2304.0\n2304.000000\n...\n828.000000\n1114.0\n1114.000000\n370.0\n370.0\n5.485826e+06\n5.485826e+06\n5.485826e+06\n5.485826e+06\nNaN\n\n\n8\n1323030121200\nPOLYGON ((119.88281 15.74996, 119.88281 15.792...\n1.0\n7.0\n21755.0\n3107.857143\n11047.0\n1578.142857\n10707.0\n1529.571429\n...\n587.857143\n5364.0\n766.285714\n1631.0\n233.0\n1.343751e+07\n1.919645e+06\n5.222719e+05\n4.416378e+06\n1.395113e+06\n\n\n9\n1323030121202\nPOLYGON ((119.88281 15.70766, 119.88281 15.749...\n0.0\n5.0\n10146.0\n2029.200000\n5257.0\n1051.400000\n4887.0\n977.400000\n...\n376.600000\n2393.0\n478.600000\n668.0\n133.6\n1.836666e+07\n3.673332e+06\n2.364678e+06\n5.247429e+06\n1.068957e+06\n\n\n\n\n5 rows × 23 columns\n\n\n\n\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"black\"\n)\nax = region3_bingtile_pois_pop_data[\n    region3_bingtile_pois_pop_data.bgy_count.notna()\n].plot(column=\"pop_total\", ax=ax, edgecolor=\"blue\", alpha=0.4)\nax = region3_bingtile_pois_pop_data[\n    region3_bingtile_pois_pop_data.bgy_count.isna()\n].plot(ax=ax, facecolor=\"none\", edgecolor=\"red\", alpha=0.4)",
    "crumbs": [
      "Tutorials",
      "Vector Zonal Stats Tutorial"
    ]
  },
  {
    "objectID": "tutorial.datasets.html",
    "href": "tutorial.datasets.html",
    "title": "Datasets Download",
    "section": "",
    "text": "Basic introduction to downloading open geospatial data using Geowrangler",
    "crumbs": [
      "Tutorials",
      "Datasets Download"
    ]
  },
  {
    "objectID": "tutorial.datasets.html#downloading-geofabrik-data",
    "href": "tutorial.datasets.html#downloading-geofabrik-data",
    "title": "Datasets Download",
    "section": "Downloading Geofabrik Data",
    "text": "Downloading Geofabrik Data\n\nimport geopandas as gpd\nfrom geowrangler.datasets import geofabrik\n\n\nListing down available regions\n\nregions = geofabrik.list_geofabrik_regions()\n# list down regions in asia\n{k: v for k, v in regions.items() if \"asia\" in v}\n\n{'afghanistan': 'https://download.geofabrik.de/asia/afghanistan-latest-free.shp.zip',\n 'armenia': 'https://download.geofabrik.de/asia/armenia-latest-free.shp.zip',\n 'azerbaijan': 'https://download.geofabrik.de/asia/azerbaijan-latest-free.shp.zip',\n 'bangladesh': 'https://download.geofabrik.de/asia/bangladesh-latest-free.shp.zip',\n 'bhutan': 'https://download.geofabrik.de/asia/bhutan-latest-free.shp.zip',\n 'cambodia': 'https://download.geofabrik.de/asia/cambodia-latest-free.shp.zip',\n 'central-zone': 'https://download.geofabrik.de/asia/india/central-zone-latest-free.shp.zip',\n 'china': 'https://download.geofabrik.de/asia/china-latest-free.shp.zip',\n 'chubu': 'https://download.geofabrik.de/asia/japan/chubu-latest-free.shp.zip',\n 'chugoku': 'https://download.geofabrik.de/asia/japan/chugoku-latest-free.shp.zip',\n 'east-timor': 'https://download.geofabrik.de/asia/east-timor-latest-free.shp.zip',\n 'eastern-zone': 'https://download.geofabrik.de/asia/india/eastern-zone-latest-free.shp.zip',\n 'gcc-states': 'https://download.geofabrik.de/asia/gcc-states-latest-free.shp.zip',\n 'hokkaido': 'https://download.geofabrik.de/asia/japan/hokkaido-latest-free.shp.zip',\n 'iran': 'https://download.geofabrik.de/asia/iran-latest-free.shp.zip',\n 'iraq': 'https://download.geofabrik.de/asia/iraq-latest-free.shp.zip',\n 'israel-and-palestine': 'https://download.geofabrik.de/asia/israel-and-palestine-latest-free.shp.zip',\n 'java': 'https://download.geofabrik.de/asia/indonesia/java-latest-free.shp.zip',\n 'jordan': 'https://download.geofabrik.de/asia/jordan-latest-free.shp.zip',\n 'kalimantan': 'https://download.geofabrik.de/asia/indonesia/kalimantan-latest-free.shp.zip',\n 'kansai': 'https://download.geofabrik.de/asia/japan/kansai-latest-free.shp.zip',\n 'kanto': 'https://download.geofabrik.de/asia/japan/kanto-latest-free.shp.zip',\n 'kazakhstan': 'https://download.geofabrik.de/asia/kazakhstan-latest-free.shp.zip',\n 'kyrgyzstan': 'https://download.geofabrik.de/asia/kyrgyzstan-latest-free.shp.zip',\n 'kyushu': 'https://download.geofabrik.de/asia/japan/kyushu-latest-free.shp.zip',\n 'laos': 'https://download.geofabrik.de/asia/laos-latest-free.shp.zip',\n 'lebanon': 'https://download.geofabrik.de/asia/lebanon-latest-free.shp.zip',\n 'malaysia-singapore-brunei': 'https://download.geofabrik.de/asia/malaysia-singapore-brunei-latest-free.shp.zip',\n 'maldives': 'https://download.geofabrik.de/asia/maldives-latest-free.shp.zip',\n 'maluku': 'https://download.geofabrik.de/asia/indonesia/maluku-latest-free.shp.zip',\n 'mongolia': 'https://download.geofabrik.de/asia/mongolia-latest-free.shp.zip',\n 'myanmar': 'https://download.geofabrik.de/asia/myanmar-latest-free.shp.zip',\n 'nepal': 'https://download.geofabrik.de/asia/nepal-latest-free.shp.zip',\n 'north-eastern-zone': 'https://download.geofabrik.de/asia/india/north-eastern-zone-latest-free.shp.zip',\n 'north-korea': 'https://download.geofabrik.de/asia/north-korea-latest-free.shp.zip',\n 'northern-zone': 'https://download.geofabrik.de/asia/india/northern-zone-latest-free.shp.zip',\n 'nusa-tenggara': 'https://download.geofabrik.de/asia/indonesia/nusa-tenggara-latest-free.shp.zip',\n 'pakistan': 'https://download.geofabrik.de/asia/pakistan-latest-free.shp.zip',\n 'papua': 'https://download.geofabrik.de/asia/indonesia/papua-latest-free.shp.zip',\n 'philippines': 'https://download.geofabrik.de/asia/philippines-latest-free.shp.zip',\n 'shikoku': 'https://download.geofabrik.de/asia/japan/shikoku-latest-free.shp.zip',\n 'south-korea': 'https://download.geofabrik.de/asia/south-korea-latest-free.shp.zip',\n 'southern-zone': 'https://download.geofabrik.de/asia/india/southern-zone-latest-free.shp.zip',\n 'sri-lanka': 'https://download.geofabrik.de/asia/sri-lanka-latest-free.shp.zip',\n 'sulawesi': 'https://download.geofabrik.de/asia/indonesia/sulawesi-latest-free.shp.zip',\n 'sumatra': 'https://download.geofabrik.de/asia/indonesia/sumatra-latest-free.shp.zip',\n 'syria': 'https://download.geofabrik.de/asia/syria-latest-free.shp.zip',\n 'taiwan': 'https://download.geofabrik.de/asia/taiwan-latest-free.shp.zip',\n 'tajikistan': 'https://download.geofabrik.de/asia/tajikistan-latest-free.shp.zip',\n 'thailand': 'https://download.geofabrik.de/asia/thailand-latest-free.shp.zip',\n 'tohoku': 'https://download.geofabrik.de/asia/japan/tohoku-latest-free.shp.zip',\n 'turkmenistan': 'https://download.geofabrik.de/asia/turkmenistan-latest-free.shp.zip',\n 'uzbekistan': 'https://download.geofabrik.de/asia/uzbekistan-latest-free.shp.zip',\n 'vietnam': 'https://download.geofabrik.de/asia/vietnam-latest-free.shp.zip',\n 'western-zone': 'https://download.geofabrik.de/asia/india/western-zone-latest-free.shp.zip',\n 'yemen': 'https://download.geofabrik.de/asia/yemen-latest-free.shp.zip'}\n\n\n\n\nDownloading a region file to a directory\n\ndownloaded_file = geofabrik.download_geofabrik_region(\"laos\", \"../test_dir\")\ndownloaded_file\n\n2023-02-01 17:00:04.495 | INFO     | geowrangler.datasets.utils:urlretrieve:27 - Retrieving https://download.geofabrik.de/asia/laos-latest-free.shp.zip into ../test_dir/laos-latest-free.shp.zip\n\n\n\n\n\n\n\n    \n      \n      100.00% [97345536/97341916 00:17&lt;00:00]\n    \n    \n\n\nCPU times: user 1.58 s, sys: 980 ms, total: 2.56 s\nWall time: 18 s\n\n\nPath('../test_dir/laos-latest-free.shp.zip')\n\n\n\n\nLoading geofabrik files\n\ngdf = gpd.read_file(downloaded_file)\ngdf.head()\n\nCPU times: user 19.4 s, sys: 528 ms, total: 19.9 s\nWall time: 19.9 s\n\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\ntype\ngeometry\n\n\n\n\n0\n36192811\n1500\nbuilding\nDon Chan Palace\nNone\nPOLYGON ((102.61392 17.95514, 102.61419 17.955...\n\n\n1\n36195671\n1500\nbuilding\nຕະຫລາດເຊົ້າ. 早市塲\nNone\nPOLYGON ((102.61382 17.96520, 102.61393 17.965...\n\n\n2\n36195973\n1500\nbuilding\nMercure Hotel Laotel\nNone\nPOLYGON ((102.59386 17.96890, 102.59432 17.968...\n\n\n3\n36784437\n1500\nbuilding\nNone\nNone\nPOLYGON ((105.79786 15.11905, 105.79838 15.119...\n\n\n4\n37886432\n1500\nbuilding\nPresidential Palace\nNone\nPOLYGON ((102.60940 17.96246, 102.60951 17.962...\n\n\n\n\n\n\n\nYou can also list the contents of the zipped shape file as well as load the shape file within it\n\n!unzip -l {downloaded_file.as_posix()}\n\nArchive:  ../test_dir/laos-latest-free.shp.zip\n  Length      Date    Time    Name\n---------  ---------- -----   ----\n      647  2023-02-01 09:00   README\n        6  2023-02-01 09:00   gis_osm_buildings_a_free_1.cpg\n 68322734  2023-02-01 09:00   gis_osm_buildings_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_buildings_a_free_1.prj\n 60089724  2023-02-01 09:00   gis_osm_buildings_a_free_1.shp\n  3312708  2023-02-01 09:00   gis_osm_buildings_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_landuse_a_free_1.cpg\n  2845642  2023-02-01 09:00   gis_osm_landuse_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_landuse_a_free_1.prj\n 14407732  2023-02-01 09:00   gis_osm_landuse_a_free_1.shp\n   157092  2023-02-01 09:00   gis_osm_landuse_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_natural_a_free_1.cpg\n     7702  2023-02-01 09:00   gis_osm_natural_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_natural_a_free_1.prj\n    15556  2023-02-01 09:00   gis_osm_natural_a_free_1.shp\n      516  2023-02-01 09:00   gis_osm_natural_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_natural_free_1.cpg\n   753872  2023-02-01 09:00   gis_osm_natural_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_natural_free_1.prj\n   145644  2023-02-01 09:00   gis_osm_natural_free_1.shp\n    41684  2023-02-01 09:00   gis_osm_natural_free_1.shx\n        6  2023-02-01 09:00   gis_osm_places_a_free_1.cpg\n    26854  2023-02-01 09:00   gis_osm_places_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_places_a_free_1.prj\n   441004  2023-02-01 09:00   gis_osm_places_a_free_1.shp\n     1476  2023-02-01 09:00   gis_osm_places_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_places_free_1.cpg\n  1142544  2023-02-01 09:00   gis_osm_places_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_places_free_1.prj\n   206460  2023-02-01 09:00   gis_osm_places_free_1.shp\n    59060  2023-02-01 09:00   gis_osm_places_free_1.shx\n        6  2023-02-01 09:00   gis_osm_pofw_a_free_1.cpg\n    39602  2023-02-01 09:00   gis_osm_pofw_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_pofw_a_free_1.prj\n    49992  2023-02-01 09:00   gis_osm_pofw_a_free_1.shp\n     2276  2023-02-01 09:00   gis_osm_pofw_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_pofw_free_1.cpg\n    66427  2023-02-01 09:00   gis_osm_pofw_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_pofw_free_1.prj\n    12896  2023-02-01 09:00   gis_osm_pofw_free_1.shp\n     3756  2023-02-01 09:00   gis_osm_pofw_free_1.shx\n        6  2023-02-01 09:00   gis_osm_pois_a_free_1.cpg\n   274067  2023-02-01 09:00   gis_osm_pois_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_pois_a_free_1.prj\n   351936  2023-02-01 09:00   gis_osm_pois_a_free_1.shp\n    15212  2023-02-01 09:00   gis_osm_pois_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_pois_free_1.cpg\n  1884292  2023-02-01 09:00   gis_osm_pois_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_pois_free_1.prj\n   363932  2023-02-01 09:00   gis_osm_pois_free_1.shp\n   104052  2023-02-01 09:00   gis_osm_pois_free_1.shx\n        6  2023-02-01 09:00   gis_osm_railways_free_1.cpg\n   100110  2023-02-01 09:00   gis_osm_railways_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_railways_free_1.prj\n   101636  2023-02-01 09:00   gis_osm_railways_free_1.shp\n     5124  2023-02-01 09:00   gis_osm_railways_free_1.shx\n        6  2023-02-01 09:00   gis_osm_roads_free_1.cpg\n 20909019  2023-02-01 09:00   gis_osm_roads_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_roads_free_1.prj\n 50224636  2023-02-01 09:00   gis_osm_roads_free_1.shp\n   914140  2023-02-01 09:00   gis_osm_roads_free_1.shx\n        6  2023-02-01 09:00   gis_osm_traffic_a_free_1.cpg\n   102532  2023-02-01 09:00   gis_osm_traffic_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_traffic_a_free_1.prj\n   131304  2023-02-01 09:00   gis_osm_traffic_a_free_1.shp\n     5748  2023-02-01 09:00   gis_osm_traffic_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_traffic_free_1.cpg\n   275807  2023-02-01 09:00   gis_osm_traffic_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_traffic_free_1.prj\n    53328  2023-02-01 09:00   gis_osm_traffic_free_1.shp\n    15308  2023-02-01 09:00   gis_osm_traffic_free_1.shx\n        6  2023-02-01 09:00   gis_osm_transport_a_free_1.cpg\n    10892  2023-02-01 09:00   gis_osm_transport_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_transport_a_free_1.prj\n    28840  2023-02-01 09:00   gis_osm_transport_a_free_1.shp\n      692  2023-02-01 09:00   gis_osm_transport_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_transport_free_1.cpg\n    82522  2023-02-01 09:00   gis_osm_transport_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_transport_free_1.prj\n    16004  2023-02-01 09:00   gis_osm_transport_free_1.shp\n     4644  2023-02-01 09:00   gis_osm_transport_free_1.shx\n        6  2023-02-01 09:00   gis_osm_water_a_free_1.cpg\n   979927  2023-02-01 09:00   gis_osm_water_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_water_a_free_1.prj\n 14026044  2023-02-01 09:00   gis_osm_water_a_free_1.shp\n    54156  2023-02-01 09:00   gis_osm_water_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_waterways_free_1.cpg\n  1662494  2023-02-01 09:00   gis_osm_waterways_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_waterways_free_1.prj\n 14396164  2023-02-01 09:00   gis_osm_waterways_free_1.shp\n    88756  2023-02-01 09:00   gis_osm_waterways_free_1.shx\n---------                     -------\n259339618                     91 files\n\n\n\ngdf2 = gpd.read_file(f\"{downloaded_file.as_posix()}!gis_osm_pois_free_1.shp\")\n\nCPU times: user 745 ms, sys: 19.4 ms, total: 764 ms\nWall time: 773 ms\n\n\n\n\nUnzipping and Caching OSM\nIn addition downloading, the geofabrik module provides an unzipping and caching facility (default cache directory: ~/.cache/geowrangler/osm ) to make it easier to access OSM data.\n\ndownload_path = geofabrik.download_osm_region_data(\"afghanistan\")\ndownload_path\n\n2023-02-01 17:00:42.767 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for afghanistan at /home/butchtm/.cache/geowrangler/osm/afghanistan-latest-free.shp.zip? False\n2023-02-01 17:00:43.526 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:141 - OSM Data: Re-initializing OSM region zip file at /home/butchtm/.cache/geowrangler/osm/afghanistan-latest-free.shp.zip...\n2023-02-01 17:00:43.529 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:148 - OSM Data: Downloading Geofabrik in /home/butchtm/.cache/geowrangler/osm/afghanistan-latest-free.shp.zip...\n2023-02-01 17:00:44.247 | INFO     | geowrangler.datasets.utils:urlretrieve:27 - Retrieving https://download.geofabrik.de/asia/afghanistan-latest-free.shp.zip into /home/butchtm/.cache/geowrangler/osm/afghanistan-latest-free.shp.zip\n\n\n\n\n\n\n\n    \n      \n      100.00% [241524736/241516716 00:39&lt;00:00]\n    \n    \n\n\n2023-02-01 17:01:23.951 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:159 - OSM Data: Successfully downloaded and cached OSM data for afghanistan at /home/butchtm/.cache/geowrangler/osm/afghanistan-latest-free.shp.zip!\n\n\nCPU times: user 3.22 s, sys: 1.76 s, total: 4.98 s\nWall time: 41.2 s\n\n\nPath('/home/butchtm/.cache/geowrangler/osm/afghanistan-latest-free.shp.zip')\n\n\nDownloading it the second time around should be much faster as it only checks if its in the cache and returns the path\n\ndownload_path2 = geofabrik.download_osm_region_data(\"afghanistan\")\ndownload_path2\n\n2023-02-01 17:01:23.973 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for afghanistan at /home/butchtm/.cache/geowrangler/osm/afghanistan-latest-free.shp.zip? True\n\n\nCPU times: user 2.22 ms, sys: 349 µs, total: 2.57 ms\nWall time: 2.08 ms\n\n\nPath('/home/butchtm/.cache/geowrangler/osm/afghanistan-latest-free.shp.zip')\n\n\n\n!ls -aldh  {download_path2}\n\n-rw-r--r-- 1 butchtm butchtm 231M Feb  1 17:01 /home/butchtm/.cache/geowrangler/osm/afghanistan-latest-free.shp.zip\n\n\n\n\nUsing the OSM Data Manager\nWe also provide an OSM Data Manager which, in addition to using the default cache (~/.cache/geowrangler/osm), also caches the geodataframe for either the pois or the roads datasets from OSM in memory to avoid having to reload the OSM data from disk.\n\n# Create the osm data manager\nodm = geofabrik.OsmDataManager()\n\n\npois_ph = odm.load_pois(\"philippines\")\n\n2023-02-01 17:01:24.214 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for philippines at /home/butchtm/.cache/geowrangler/osm/philippines-latest-free.shp.zip? False\n2023-02-01 17:01:25.631 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:141 - OSM Data: Re-initializing OSM region zip file at /home/butchtm/.cache/geowrangler/osm/philippines-latest-free.shp.zip...\n2023-02-01 17:01:25.634 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:148 - OSM Data: Downloading Geofabrik in /home/butchtm/.cache/geowrangler/osm/philippines-latest-free.shp.zip...\n2023-02-01 17:01:26.355 | INFO     | geowrangler.datasets.utils:urlretrieve:27 - Retrieving https://download.geofabrik.de/asia/philippines-latest-free.shp.zip into /home/butchtm/.cache/geowrangler/osm/philippines-latest-free.shp.zip\n\n\n\n\n\n\n\n    \n      \n      100.08% [1185939456/1185011560 07:39&lt;00:00]\n    \n    \n\n\n2023-02-01 17:09:06.368 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:159 - OSM Data: Successfully downloaded and cached OSM data for philippines at /home/butchtm/.cache/geowrangler/osm/philippines-latest-free.shp.zip!\n2023-02-01 17:09:06.370 | DEBUG    | geowrangler.datasets.geofabrik:load_pois:218 - OSM POIs for philippines being loaded from /home/butchtm/.cache/geowrangler/osm/philippines-latest-free.shp.zip\n\n\n\npois_ph.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\ngeometry\n\n\n\n\n0\n21717820\n2907\ncamera_surveillance\nNone\nPOINT (121.02120 14.57608)\n\n\n1\n21717872\n2722\nmuseum\nAyala Museum\nPOINT (121.02324 14.55358)\n\n\n2\n24078301\n2402\nmotel\nSogo Grand Hotel\nPOINT (121.04515 14.56449)\n\n\n3\n24078959\n2907\ncamera_surveillance\nNone\nPOINT (121.05945 14.60098)\n\n\n4\n24797511\n2542\nbicycle_shop\nChristine Sports Cycle Marketing\nPOINT (120.99506 14.55224)\n\n\n\n\n\n\n\n\nroads_ph = odm.load_roads(\"philippines\")\n\n2023-02-01 17:09:10.649 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for philippines at /home/butchtm/.cache/geowrangler/osm/philippines-latest-free.shp.zip? True\n2023-02-01 17:09:10.653 | DEBUG    | geowrangler.datasets.geofabrik:load_roads:274 - OSM Roads for philippines being loaded from /home/butchtm/.cache/geowrangler/osm/philippines-latest-free.shp.zip\n\n\n\nroads_ph.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nref\noneway\nmaxspeed\nlayer\nbridge\ntunnel\ngeometry\n\n\n\n\n0\n267\n5115\ntertiary\nMaharlika Street\nNone\nF\n30\n0\nF\nF\nLINESTRING (121.05195 14.65011, 121.05209 14.6...\n\n\n1\n2508359\n5153\nfootway\nSagada Mission Compound\nNone\nB\n0\n0\nF\nF\nLINESTRING (120.90199 17.08090, 120.90197 17.0...\n\n\n2\n2667097\n5113\nprimary\nTaft Avenue\n170\nF\n60\n0\nF\nF\nLINESTRING (120.99682 14.55577, 120.99671 14.5...\n\n\n3\n2667099\n5113\nprimary\nLerma Street\n170\nF\n60\n0\nF\nF\nLINESTRING (120.98539 14.60460, 120.98545 14.6...\n\n\n4\n2667105\n5122\nresidential\nManalito Street\nNone\nB\n0\n0\nF\nF\nLINESTRING (120.99380 14.54125, 120.99497 14.5...",
    "crumbs": [
      "Tutorials",
      "Datasets Download"
    ]
  },
  {
    "objectID": "tutorial.datasets.html#loading-osm-data-from-other-years",
    "href": "tutorial.datasets.html#loading-osm-data-from-other-years",
    "title": "Datasets Download",
    "section": "Loading OSM data from other years",
    "text": "Loading OSM data from other years\nIn addition to providing access to the latest OSM shape files, we also provide an optional year parameter, which allows you to download OSM data from previous years.\n\n\n\n\n\n\nNote\n\n\n\nThe availability of data from previous years is dependent on what geofabrik has made available. Please check the Geofabrik download site for the list of available data.\n\n\n\npois_ph = odm.load_pois(\"philippines\", year=\"2017\")\n\n2023-02-01 17:10:30.351 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for philippines at /home/butchtm/.cache/geowrangler/osm/philippines-170101-free.shp.zip? False\n2023-02-01 17:10:33.834 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:141 - OSM Data: Re-initializing OSM region zip file at /home/butchtm/.cache/geowrangler/osm/philippines-170101-free.shp.zip...\n2023-02-01 17:10:33.838 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:148 - OSM Data: Downloading Geofabrik in /home/butchtm/.cache/geowrangler/osm/philippines-170101-free.shp.zip...\n2023-02-01 17:10:35.780 | INFO     | geowrangler.datasets.utils:urlretrieve:27 - Retrieving https://download.geofabrik.de/asia/philippines-170101-free.shp.zip into /home/butchtm/.cache/geowrangler/osm/philippines-170101-free.shp.zip\n\n\n\n\n\n\n\n    \n      \n      100.25% [412090368/411074511 01:49&lt;00:00]\n    \n    \n\n\n2023-02-01 17:12:24.933 | INFO     | geowrangler.datasets.geofabrik:download_osm_region_data:163 - OSM Data: Successfully downloaded and cached OSM data for philippines and 2017 at /home/butchtm/.cache/geowrangler/osm/philippines-170101-free.shp.zip!\n2023-02-01 17:12:24.935 | DEBUG    | geowrangler.datasets.geofabrik:load_pois:220 - OSM POIs for philippines and year 2017 being loaded from /home/butchtm/.cache/geowrangler/osm/philippines-170101-free.shp.zip\n\n\n\npois_ph\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\ngeometry\n\n\n\n\n0\n14401658\n2742\nviewpoint\nEast Point\nPOINT (120.62020 14.38562)\n\n\n1\n14446500\n2721\nattraction\nIntramuros\nPOINT (120.97533 14.59059)\n\n\n2\n21717872\n2722\nmuseum\nAyala Museum\nPOINT (121.02324 14.55358)\n\n\n3\n24078301\n2401\nhotel\nSogo Grand Hotel\nPOINT (121.04515 14.56449)\n\n\n4\n24078959\n2907\ncamera_surveillance\nNone\nPOINT (121.05945 14.60098)\n\n\n...\n...\n...\n...\n...\n...\n\n\n67400\n4584129489\n2502\nbakery\nCome-on bakery\nPOINT (123.26424 9.19066)\n\n\n67401\n4584130190\n2401\nhotel\nL-mansion\nPOINT (121.00280 14.55968)\n\n\n67402\n4584164592\n2721\nattraction\nLugnason Falls\nPOINT (123.53406 9.14808)\n\n\n67403\n4584215391\n2742\nviewpoint\nNone\nPOINT (123.53406 9.14804)\n\n\n67404\n4584253097\n2511\nconvenience\nHerlyn's Burger House\nPOINT (120.58250 14.99107)\n\n\n\n\n67405 rows × 5 columns",
    "crumbs": [
      "Tutorials",
      "Datasets Download"
    ]
  },
  {
    "objectID": "tutorial.datasets.html#downloading-ookla-data",
    "href": "tutorial.datasets.html#downloading-ookla-data",
    "title": "Datasets Download",
    "section": "Downloading Ookla Data",
    "text": "Downloading Ookla Data\n\nimport geopandas as gpd\nimport pandas as pd\n\nfrom geowrangler.datasets import ookla\n\n\nListing down available files\n\nookla_files = ookla.list_ookla_files()\nookla_files\n\n{OoklaQuarter(type='fixed', year='2019', quarter='1'): '2019-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2019', quarter='2'): '2019-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2019', quarter='3'): '2019-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2019', quarter='4'): '2019-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='1'): '2020-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='2'): '2020-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='3'): '2020-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='4'): '2020-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='1'): '2021-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='2'): '2021-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='3'): '2021-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='4'): '2021-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='1'): '2022-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='2'): '2022-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='3'): '2022-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='4'): '2022-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='1'): '2019-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='2'): '2019-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='3'): '2019-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='4'): '2019-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='1'): '2020-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='2'): '2020-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='3'): '2020-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='4'): '2020-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='1'): '2021-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='2'): '2021-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='3'): '2021-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='4'): '2021-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='1'): '2022-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='2'): '2022-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='3'): '2022-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='4'): '2022-10-01_performance_mobile_tiles.parquet'}\n\n\n\n\nDownloading an ookla file to a directory\n\n\n\n\n\n\nWarning\n\n\n\nOokla files are &gt;300MB and can reach ~550MB. Download with caution.\n\n\n\n!mkdir -p ../test_dir\ndownloaded_file = ookla.download_ookla_file(\n    type_=\"fixed\", year=\"2019\", quarter=\"1\", directory=\"../test_dir\"\n)\ndownloaded_file\n\nPath('../test_dir/2019-01-01_performance_fixed_tiles.parquet')\n\n\n\n\nLoading ookla data\n\ndf = pd.read_parquet(downloaded_file)\ndf.head()\n\n\n\n\n\n\n\n\nquadkey\ntile\navg_d_kbps\navg_u_kbps\navg_lat_ms\ntests\ndevices\n\n\n\n\n0\n0022133222312322\nPOLYGON((-160.02685546875 70.6435894914449, -1...\n8763\n3646\n45\n1\n1\n\n\n1\n0022133222330013\nPOLYGON((-160.032348632812 70.6399478155463, -...\n9195\n3347\n43\n1\n1\n\n\n2\n0022133222330023\nPOLYGON((-160.043334960938 70.6363054807905, -...\n6833\n3788\n42\n1\n1\n\n\n3\n0022133222330100\nPOLYGON((-160.02685546875 70.6417687358462, -1...\n8895\n3429\n43\n2\n2\n\n\n4\n0022320121121332\nPOLYGON((-166.739501953125 68.3526207780586, -...\n4877\n935\n45\n3\n2",
    "crumbs": [
      "Tutorials",
      "Datasets Download"
    ]
  },
  {
    "objectID": "tutorial.tile_clustering.html",
    "href": "tutorial.tile_clustering.html",
    "title": "Tile Clustering Tutorial",
    "section": "",
    "text": "A basic introduction to using tile clustering",
    "crumbs": [
      "Tutorials",
      "Tile Clustering Tutorial"
    ]
  },
  {
    "objectID": "tutorial.tile_clustering.html#summary",
    "href": "tutorial.tile_clustering.html#summary",
    "title": "Tile Clustering Tutorial",
    "section": "Summary",
    "text": "Summary\nClusters adjacent grid tiles together. Usage of this function assumes that the input is a grid dataset.",
    "crumbs": [
      "Tutorials",
      "Tile Clustering Tutorial"
    ]
  },
  {
    "objectID": "tutorial.tile_clustering.html#how-does-it-work",
    "href": "tutorial.tile_clustering.html#how-does-it-work",
    "title": "Tile Clustering Tutorial",
    "section": "How does it work?",
    "text": "How does it work?\nTile clustering works by assigning the same ID to grid cells belonging to the same cluster. There are options to: (a) cluster adjacent cells by category, (b) cluster grid cells via adjacent edges or corners.\n\nTileClustering().cluster_tiles(df, category_col)\n\n\n\n\n\n\n\n\n\n\n\ntype\ndefault\noptional/required\ndetails\n\n\n\n\ncluster_type\nString\nfour_way\noptional\nLeave blank () if using four_way cluster_type (top, bottom, left, right sides of a cell). Put in eight_way if preference is to cluster via four sides and corners of a cell.\n\n\ndf\nGeoDataFrame\nnone\nrequired\ndataframe for clustering\n\n\ncategory_col\nString\nnone\noptional\ncolumn for category if need to cluster adjacent cells by category\n\n\n\nA technical step-by-step explanation of how TileClustering().cluster_tiles works is detailed in the cell blocks below. An example on how to use it with its arguments is shown in the sample use case section thereafter.\n\nDefine the class.\n\nclass TileClustering:\n    def __init__(\n        self,\n        cluster_type: str = \"four_way\",\n    ) -&gt; None:\n\n        assert cluster_type in [\"four_way\", \"eight_way\"]\n        self.cluster_type = cluster_type\n        self.tile_cluster_col = \"tile_cluster\"\n\nDefine the function.\n\n@patch\ndef cluster_tiles(\n    self: TileClustering,\n    df: pd.DataFrame,\n    grid_x_col=\"x\",\n    grid_y_col=\"y\",\n    category_col: Optional[str] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Appends the cluster ID for each square grid cell\n    \"\"\"\n\n    if category_col is None:\n        cluster_df = self._cluster_tiles_single(df, grid_x_col, grid_y_col)\n    else:\n        assert (\n            not df[category_col].isnull().any()\n        ), f\"There shouldn't be null values for {category_col}\"\n        unique_categories = df[category_col].unique().tolist()\n\n        cluster_df_list = []\n        for i, category in enumerate(unique_categories, start=1):\n            bool_mask = df[category_col] == category\n            filtered_df = df.loc[bool_mask, :].copy()\n            cluster_filtered_df = self._cluster_tiles_single(\n                filtered_df, grid_x_col, grid_y_col\n            )\n            cluster_filtered_df[self.tile_cluster_col] = cluster_filtered_df[\n                self.tile_cluster_col\n            ].apply(lambda key: f\"{key}-{i}\")\n            cluster_df_list.append(cluster_filtered_df)\n        cluster_df = pd.concat(cluster_df_list, axis=0, ignore_index=True)\n\n    df = pd.merge(left=df, right=cluster_df, on=[grid_x_col, grid_y_col], how=\"left\")\n\n    return df\n\nCategorize commands depending on input of category_col. Append cluster ID for each grid cell.\n\n    # no entry in category_col - run the patched function _cluster_tiles_single\n    if category_col is None:\n        cluster_df = self._cluster_tiles_single(df, grid_x_col, grid_y_col)\n\n    # entry in category_col - make sure that all rows have values\n    else:\n        assert (\n            not df[category_col].isnull().any()\n        ), f\"There shouldn't be null values for {category_col}\"\n        unique_categories = df[category_col].unique().tolist()\n\n    # append cluster ID for each grid cell\n        cluster_df_list = []\n        for i, category in enumerate(unique_categories, start=1):\n            bool_mask = df[category_col] == category\n            filtered_df = df.loc[bool_mask, :].copy()\n            cluster_filtered_df = self._cluster_tiles_single(\n                filtered_df, grid_x_col, grid_y_col\n            )\n            cluster_filtered_df[self.tile_cluster_col] = cluster_filtered_df[\n                self.tile_cluster_col\n            ].apply(lambda key: f\"{key}-{i}\")\n            cluster_df_list.append(cluster_filtered_df)\n        cluster_df = pd.concat(cluster_df_list, axis=0, ignore_index=True)\n\nMerge grid cells with same cluster ID.\n\n    df = pd.merge(left=df, right=cluster_df, on=[grid_x_col, grid_y_col], how=\"left\")\n\nReturn output dataframe.\n\n    return df\n\nOther @patch functions\n\n_cluster_tiles_single - called when there is no entry in category_col\n@patch\ndef _cluster_tiles_single(\n    self: TileClustering,\n    df: pd.DataFrame,\n    grid_x_col=\"x\",\n    grid_y_col=\"y\",\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Performs tile clustering on a single category\n    \"\"\"\n\n    if self.tile_cluster_col in df.columns:\n        raise ValueError(\n            f\"{self.tile_cluster_col} already exists as a column. Please rename\"\n        )\n\n    grid_x = df[grid_x_col]\n    grid_y = df[grid_y_col]\n\n    self.grid_idx = set(zip(grid_x, grid_y))\n\n    self.tile_cluster_dict = {}\n    self.cluster_id = 0\n\n    for key in self.grid_idx:\n        if key not in self.tile_cluster_dict.keys():\n            self.cluster_id += 1\n\n            # reset the call stack per iteration\n            self.call_stack = deque()\n            self._dfs_connected_components(key)\n\n    cluster_df = pd.DataFrame.from_dict(\n        self.tile_cluster_dict, orient=\"index\", columns=[self.tile_cluster_col]\n    )\n    cluster_df = cluster_df.reset_index()\n    cluster_df[grid_x_col] = cluster_df[\"index\"].apply(lambda idx: idx[0])\n    cluster_df[grid_y_col] = cluster_df[\"index\"].apply(lambda idx: idx[1])\n    cluster_df = cluster_df.drop(columns=\"index\")\n\n    return cluster_df\n_get_adjacent_keys - defines how four_way and eight_way clustering works\n@patch\ndef _get_adjacent_keys(\n    self: TileClustering,\n    key: Tuple[int, int],\n) -&gt; List[Tuple[int, int]]:\n\n    x_idx = key[0]\n    y_idx = key[1]\n\n    east_key = (x_idx + 1, y_idx)\n    west_key = (x_idx - 1, y_idx)\n    south_key = (x_idx, y_idx - 1)\n    north_key = (x_idx, y_idx + 1)\n\n    if self.cluster_type == \"four_way\":\n        adjacent_keys = [east_key, west_key, south_key, north_key]\n\n    if self.cluster_type == \"eight_way\":\n        northeast_key = (x_idx + 1, y_idx + 1)\n        northwest_key = (x_idx - 1, y_idx + 1)\n        southeast_key = (x_idx + 1, y_idx - 1)\n        southwest_key = (x_idx - 1, y_idx - 1)\n\n        adjacent_keys = [\n            east_key,\n            west_key,\n            south_key,\n            north_key,\n            northeast_key,\n            northwest_key,\n            southeast_key,\n            southwest_key,\n        ]\n\n    return adjacent_keys\n_dfs_connected_components - a non-recursive depth-first search implementation of connected components\n@patch\ndef _dfs_connected_components(\n    self: TileClustering,\n    key: Tuple[int, int],\n) -&gt; None:\n\n    self.call_stack.append(key)\n    while self.call_stack:\n        ref_key = self.call_stack.pop()\n\n        # check if key exists in the first place\n        if ref_key in self.grid_idx:\n            # check if adjacent key has already been assigned\n            if ref_key not in self.tile_cluster_dict.keys():\n                self.tile_cluster_dict[ref_key] = self.cluster_id\n\n                adjacent_keys = self._get_adjacent_keys(ref_key)\n                for adjacent_key in adjacent_keys:\n                    self.call_stack.append(adjacent_key)",
    "crumbs": [
      "Tutorials",
      "Tile Clustering Tutorial"
    ]
  },
  {
    "objectID": "tutorial.tile_clustering.html#sample-use-case--clustering-areas-based-on-scores",
    "href": "tutorial.tile_clustering.html#sample-use-case--clustering-areas-based-on-scores",
    "title": "Tile Clustering Tutorial",
    "section": "Sample use case- Clustering areas based on scores",
    "text": "Sample use case- Clustering areas based on scores\nInput: - grid_gdf5k - GeoDataFrame of randomly scored 5km x 5km grid cells - class - category column for basis of of clustering\nOutput: - clustered grid based on class\n\nStep 1: Import packages\n\nimport geopandas as gpd\nimport numpy as np\n\nimport geowrangler.grids as grids\n\nimport geowrangler.tile_clustering as tile_clustering\n\n\n\nStep 2: Load GeoDataFrame and generate grid\n\ngrid_generator5k = grids.SquareGridGenerator(5_000)\ngrid_gdf5k = grid_generator5k.generate_grid(region3_gdf)\n\n\ngrid_gdf5k\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n\n\n3\n2\n24\nPOLYGON ((119.87566 15.4491, 119.92058 15.4491...\n\n\n4\n2\n25\nPOLYGON ((119.87566 15.49239, 119.92058 15.492...\n\n\n...\n...\n...\n...\n\n\n1069\n54\n44\nPOLYGON ((122.21128 16.31312, 122.2562 16.3131...\n\n\n1070\n54\n45\nPOLYGON ((122.21128 16.35623, 122.2562 16.3562...\n\n\n1071\n54\n46\nPOLYGON ((122.21128 16.39932, 122.2562 16.3993...\n\n\n1072\n54\n47\nPOLYGON ((122.21128 16.4424, 122.2562 16.4424,...\n\n\n1073\n54\n48\nPOLYGON ((122.21128 16.48548, 122.2562 16.4854...\n\n\n\n\n1074 rows × 3 columns\n\n\n\n\ngrid_gdf5k.plot();\n\n\n\n\n\n\n\n\n\n\nStep 3: Assign scores\n\ngrid_gdf5k\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nscore\nclass\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n0.216056\nFalse\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n0.198387\nFalse\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n0.508601\nFalse\n\n\n3\n2\n24\nPOLYGON ((119.87566 15.4491, 119.92058 15.4491...\n0.186705\nFalse\n\n\n4\n2\n25\nPOLYGON ((119.87566 15.49239, 119.92058 15.492...\n0.383824\nFalse\n\n\n...\n...\n...\n...\n...\n...\n\n\n1069\n54\n44\nPOLYGON ((122.21128 16.31312, 122.2562 16.3131...\n0.059555\nFalse\n\n\n1070\n54\n45\nPOLYGON ((122.21128 16.35623, 122.2562 16.3562...\n0.824039\nTrue\n\n\n1071\n54\n46\nPOLYGON ((122.21128 16.39932, 122.2562 16.3993...\n0.903166\nTrue\n\n\n1072\n54\n47\nPOLYGON ((122.21128 16.4424, 122.2562 16.4424,...\n0.186872\nFalse\n\n\n1073\n54\n48\nPOLYGON ((122.21128 16.48548, 122.2562 16.4854...\n0.208694\nFalse\n\n\n\n\n1074 rows × 5 columns\n\n\n\n\n\nStep 4: Tile clustering\n\noutput = tile_clustering.TileClustering().cluster_tiles(\n    df=grid_gdf5k, category_col=\"class\"\n)\n\n\noutput\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nscore\nclass\ntile_cluster\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n0.216056\nFalse\n1-1\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n0.198387\nFalse\n1-1\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n0.508601\nFalse\n1-1\n\n\n3\n2\n24\nPOLYGON ((119.87566 15.4491, 119.92058 15.4491...\n0.186705\nFalse\n1-1\n\n\n4\n2\n25\nPOLYGON ((119.87566 15.49239, 119.92058 15.492...\n0.383824\nFalse\n1-1\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n1069\n54\n44\nPOLYGON ((122.21128 16.31312, 122.2562 16.3131...\n0.059555\nFalse\n2-1\n\n\n1070\n54\n45\nPOLYGON ((122.21128 16.35623, 122.2562 16.3562...\n0.824039\nTrue\n33-2\n\n\n1071\n54\n46\nPOLYGON ((122.21128 16.39932, 122.2562 16.3993...\n0.903166\nTrue\n33-2\n\n\n1072\n54\n47\nPOLYGON ((122.21128 16.4424, 122.2562 16.4424,...\n0.186872\nFalse\n2-1\n\n\n1073\n54\n48\nPOLYGON ((122.21128 16.48548, 122.2562 16.4854...\n0.208694\nFalse\n2-1\n\n\n\n\n1074 rows × 6 columns\n\n\n\n\noutput.plot(column=\"class\", categorical=True, cmap=\"Spectral\");",
    "crumbs": [
      "Tutorials",
      "Tile Clustering Tutorial"
    ]
  },
  {
    "objectID": "tutorial.geometry_validation.html",
    "href": "tutorial.geometry_validation.html",
    "title": "Geometry Validation Tutorial",
    "section": "",
    "text": "A basic introduction to using geometry validation",
    "crumbs": [
      "Tutorials",
      "Geometry Validation Tutorial"
    ]
  },
  {
    "objectID": "tutorial.geometry_validation.html#basic-usage",
    "href": "tutorial.geometry_validation.html#basic-usage",
    "title": "Geometry Validation Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nLoading a geojson with invalid geometries\n\nimport geopandas as gpd\nimport pandas as pd\n\n\ngdf = gpd.read_file(\"../data/broken.geojson\")\ngdf = pd.concat([gdf, gpd.GeoDataFrame({\"geometry\": [None], \"id\": \"null geometry\"})])\ngdf\n\n/home/jt/.cache/pypoetry/virtualenvs/geowrangler-U9oiUrW5-py3.9/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\nid\ngeometry\n\n\n\n\n0\nvalid\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 0....\n\n\n1\nout_of_crs_bounds\nPOLYGON ((200.00000 0.00000, 0.00000 1.00000, ...\n\n\n2\nmisoriented\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\n\n\n3\nself_intersecting\nPOLYGON ((0.00000 0.00000, 1.00000 1.00000, 2....\n\n\n4\ncounterclockwise\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\n\n\n5\nsliver\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 0....\n\n\n6\nholes\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\n\n\n7\nnon-closed polygon\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\n\n\n8\nmultipolygon\nMULTIPOLYGON (((0.00000 0.00000, 1.00000 0.000...\n\n\n9\npolygon z\nPOLYGON Z ((0.00000 0.00000 1.00000, 1.00000 0...\n\n\n10\ncomplex self-intersecting polygon\nPOLYGON ((0.00000 0.00000, 5.00000 0.00000, 5....\n\n\n0\nnull geometry\nNone\n\n\n\n\n\n\n\nWe then run Geometry Validation. By default, these append a new column if the validation fails, applies a fix if possible, and raises a warning if no fix is available.\n\nfrom geowrangler.validation import GeometryValidation\n\n\nGeometryValidation(gdf)\n\nvalidated_gdf = GeometryValidation(gdf).validate_all()\nvalidated_gdf\n\n/home/jt/repos/geowrangler/geowrangler/validation.py:107: UserWarning: Found null geometries\n  warnings.warn(self.warning_message)\n/home/jt/repos/geowrangler/geowrangler/validation.py:107: UserWarning: Found geometries out of bounds from crs\n  warnings.warn(self.warning_message)\n/home/jt/repos/geowrangler/geowrangler/validation.py:107: UserWarning: Found geometries with area equals or less than zero\n  warnings.warn(self.warning_message)\n\n\n\n\n\n\n\n\n\nid\ngeometry\nis_not_null\nis_not_self_intersecting\nis_oriented_properly\nis_within_crs_bounds\narea_is_not_zero\n\n\n\n\n0\nvalid\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 0....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n1\nout_of_crs_bounds\nPOLYGON ((200.00000 0.00000, 0.00000 1.00000, ...\nTrue\nTrue\nTrue\nFalse\nTrue\n\n\n2\nmisoriented\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nFalse\nTrue\nTrue\n\n\n3\nself_intersecting\nMULTIPOLYGON (((0.00000 2.00000, 0.00000 0.000...\nTrue\nFalse\nFalse\nTrue\nTrue\n\n\n4\ncounterclockwise\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n5\nsliver\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 0....\nTrue\nTrue\nTrue\nTrue\nFalse\n\n\n6\nholes\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n7\nnon-closed polygon\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n8\nmultipolygon\nMULTIPOLYGON (((0.00000 0.00000, 1.00000 0.000...\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n9\npolygon z\nPOLYGON Z ((0.00000 0.00000 1.00000, 1.00000 0...\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n10\ncomplex self-intersecting polygon\nPOLYGON ((0.00000 5.00000, 0.00000 2.50000, 0....\nTrue\nFalse\nFalse\nTrue\nTrue\n\n\n0\nnull geometry\nNone\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n\n\n\n\n\n\ngdf.iloc[5].geometry.area\n\n0.0\n\n\nRunning the validation again shows that validation applies some fixes\n\nGeometryValidation(validated_gdf[[\"id\", \"geometry\"]]).validate_all()\n\n/home/jt/repos/geowrangler/geowrangler/validation.py:107: UserWarning: Found null geometries\n  warnings.warn(self.warning_message)\n/home/jt/repos/geowrangler/geowrangler/validation.py:107: UserWarning: Found geometries out of bounds from crs\n  warnings.warn(self.warning_message)\n/home/jt/repos/geowrangler/geowrangler/validation.py:107: UserWarning: Found geometries with area equals or less than zero\n  warnings.warn(self.warning_message)\n\n\n\n\n\n\n\n\n\nid\ngeometry\nis_not_null\nis_not_self_intersecting\nis_oriented_properly\nis_within_crs_bounds\narea_is_not_zero\n\n\n\n\n0\nvalid\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 0....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n1\nout_of_crs_bounds\nPOLYGON ((200.00000 0.00000, 0.00000 1.00000, ...\nTrue\nTrue\nTrue\nFalse\nTrue\n\n\n2\nmisoriented\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n3\nself_intersecting\nMULTIPOLYGON (((0.00000 2.00000, 0.00000 0.000...\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n4\ncounterclockwise\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n5\nsliver\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 0....\nTrue\nTrue\nTrue\nTrue\nFalse\n\n\n6\nholes\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n7\nnon-closed polygon\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n8\nmultipolygon\nMULTIPOLYGON (((0.00000 0.00000, 1.00000 0.000...\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n9\npolygon z\nPOLYGON Z ((0.00000 0.00000 1.00000, 1.00000 0...\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n10\ncomplex self-intersecting polygon\nPOLYGON ((0.00000 5.00000, 0.00000 2.50000, 0....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n0\nnull geometry\nNone\nFalse\nTrue\nTrue\nTrue\nTrue",
    "crumbs": [
      "Tutorials",
      "Geometry Validation Tutorial"
    ]
  },
  {
    "objectID": "tutorial.geometry_validation.html#passing-validators",
    "href": "tutorial.geometry_validation.html#passing-validators",
    "title": "Geometry Validation Tutorial",
    "section": "Passing Validators",
    "text": "Passing Validators\nYou can pass a list of Validators to selective run validators, the default uses the following - NullValidator - Checks if geometry is null. No fix - OrientationValidator - Check the orientation of the outer most ring of each polygon is counter clockwise. Converts it to counter-clockwise if as the fix - SelfIntersectingValidator - Checks if the polygons is self intersecting. Runs shapely.validation.make_valid as the fix. - CrsBoundsValidator - Checks if bounds of each geometry are within the CRS. No fix - AreaValidator - Checks if polygons or multipolygon have an area greater than zero\n\nfrom geowrangler.validation import NullValidator, SelfIntersectingValidator\n\n\nvalidated_gdf = GeometryValidation(\n    gdf, validators=[NullValidator, SelfIntersectingValidator]\n).validate_all()\nvalidated_gdf\n\n/home/jt/repos/geowrangler/geowrangler/validation.py:107: UserWarning: Found null geometries\n  warnings.warn(self.warning_message)\n\n\n\n\n\n\n\n\n\nid\ngeometry\nis_not_null\nis_not_self_intersecting\n\n\n\n\n0\nvalid\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 0....\nTrue\nTrue\n\n\n1\nout_of_crs_bounds\nPOLYGON ((200.00000 0.00000, 0.00000 1.00000, ...\nTrue\nTrue\n\n\n2\nmisoriented\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\nTrue\nTrue\n\n\n3\nself_intersecting\nMULTIPOLYGON (((0.00000 2.00000, 1.00000 1.000...\nTrue\nFalse\n\n\n4\ncounterclockwise\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\n\n\n5\nsliver\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 0....\nTrue\nTrue\n\n\n6\nholes\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\n\n\n7\nnon-closed polygon\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\n\n\n8\nmultipolygon\nMULTIPOLYGON (((0.00000 0.00000, 1.00000 0.000...\nTrue\nTrue\n\n\n9\npolygon z\nPOLYGON Z ((0.00000 0.00000 1.00000, 1.00000 0...\nTrue\nTrue\n\n\n10\ncomplex self-intersecting polygon\nPOLYGON ((0.00000 5.00000, 5.00000 5.00000, 5....\nTrue\nFalse\n\n\n0\nnull geometry\nNone\nFalse\nTrue\n\n\n\n\n\n\n\nYou can also use a single validator at a time\n\nSelfIntersectingValidator().validate(gdf)\n\n\n\n\n\n\n\n\nid\ngeometry\nis_not_self_intersecting\n\n\n\n\n0\nvalid\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 0....\nTrue\n\n\n1\nout_of_crs_bounds\nPOLYGON ((200.00000 0.00000, 0.00000 1.00000, ...\nTrue\n\n\n2\nmisoriented\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\nTrue\n\n\n3\nself_intersecting\nMULTIPOLYGON (((0.00000 2.00000, 1.00000 1.000...\nFalse\n\n\n4\ncounterclockwise\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\n\n\n5\nsliver\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 0....\nTrue\n\n\n6\nholes\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\n\n\n7\nnon-closed polygon\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\n\n\n8\nmultipolygon\nMULTIPOLYGON (((0.00000 0.00000, 1.00000 0.000...\nTrue\n\n\n9\npolygon z\nPOLYGON Z ((0.00000 0.00000 1.00000, 1.00000 0...\nTrue\n\n\n10\ncomplex self-intersecting polygon\nPOLYGON ((0.00000 5.00000, 5.00000 5.00000, 5....\nFalse\n\n\n0\nnull geometry\nNone\nTrue",
    "crumbs": [
      "Tutorials",
      "Geometry Validation Tutorial"
    ]
  },
  {
    "objectID": "tutorial.geometry_validation.html#building-your-own-validator",
    "href": "tutorial.geometry_validation.html#building-your-own-validator",
    "title": "Geometry Validation Tutorial",
    "section": "Building your own validator",
    "text": "Building your own validator\nLet’s build a validator that check if the is point below 0 in the x axis, if that is the case we set it to 0\n\nfrom shapely.geometry.point import Point\nfrom shapely.geometry.polygon import Polygon\n\nfrom geowrangler.validation import BaseValidator\n\n\nclass PointValidator(BaseValidator):\n    validator_column_name = \"is_not_point\"\n    geometry_types = [\"Point\"]  # What kind of geometies to validate and fix\n\n    def check(self, geometry):\n        # Checks if the geometry is valid. If False, applies the fix\n        return geometry.x &gt; 0\n\n    def fix(self, geometry):\n        return Point(0, geometry.y)\n\n\ngdf = gpd.GeoDataFrame(\n    geometry=[Point(-0.1, 0), Polygon([(-0.1, 0.1), (-0.1, 1), (1, 1)])]\n)\nvalidated_gdf = PointValidator().validate(gdf)\n\nax = gdf.plot()\nax = validated_gdf.plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are several cases where no fix is available or you want to fix them manualy, we can create a validator that warns the users.\n\nfrom shapely.geometry.point import Point\nfrom shapely.geometry.polygon import Polygon\n\nfrom geowrangler.validation import BaseValidator\n\n\nclass PointValidator(BaseValidator):\n    validator_column_name = \"is_not_point\"\n    fix_available = False  # Telling the validator that there is no available fixes\n    warning_message = \"Found geometries that are points below 0\"  # warning message\n    geometry_types = [\"Point\"]  # What kind of geometies to validate and fix\n\n    def check(self, geometry):\n        # Checks if the geometry is valid. If False, warn the user\n        return geometry.x &gt; 0\n\n\ngdf = gpd.GeoDataFrame(geometry=[Point(-0.1, 0), Polygon([(0, 0.0), (0, 1), (1, 1)])])\nvalidated_gdf = PointValidator().validate(gdf)\nvalidated_gdf\n\n/home/jt/repos/geowrangler/geowrangler/validation.py:107: UserWarning: Found geometries that are points below 0\n  warnings.warn(self.warning_message)\n\n\n\n\n\n\n\n\n\ngeometry\nis_not_point\n\n\n\n\n0\nPOINT (-0.10000 0.00000)\nFalse\n\n\n1\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\nTrue",
    "crumbs": [
      "Tutorials",
      "Geometry Validation Tutorial"
    ]
  },
  {
    "objectID": "raster_to_dataframe.html",
    "href": "raster_to_dataframe.html",
    "title": "Raster to Dataframe",
    "section": "",
    "text": "from rasterio import features\nfrom rasterio.plot import show\nfrom rasterio.windows import Window, transform",
    "crumbs": [
      "Module Reference",
      "Raster to Dataframe"
    ]
  },
  {
    "objectID": "raster_to_dataframe.html#test-data",
    "href": "raster_to_dataframe.html#test-data",
    "title": "Raster to Dataframe",
    "section": "Test data",
    "text": "Test data\n\nGenerating a raster mask\n\n# Get filepaths\ntiff_file = \"../data/vector_to_raster_mask_sample/cabanglasan.tif\"\nshape_file = \"../data/vector_to_raster_mask_sample/labels_20220816.gpkg\"\ntarget_file = shape_file.replace(\"gpkg\", \"tiff\")\n\nGiven a raster image of a certain area that will be masked to use as a reference and a shape file that contains that area. Note that the shape file must include a column that contains labels/categories.\n\ngpd.read_file(shape_file).head(3)\n\n\n\n\n\n\n\n\nyear\nlabel\nuid\nADM3_EN\nADM3_PCODE\nADM2_EN\nADM2_PCODE\nADM1_EN\nADM1_PCODE\ngeometry\n\n\n\n\n0\n2017.0\nmining\n72_2017_mining\nSofronio Española\nPH175324000\nPalawan\nPH175300000\nRegion IV-B\nPH170000000\nMULTIPOLYGON Z (((117.95961 9.03303 0, 117.959...\n\n\n1\n2017.0\nmining\n71_2017_mining\nSofronio Española\nPH175324000\nPalawan\nPH175300000\nRegion IV-B\nPH170000000\nMULTIPOLYGON Z (((117.95507 9.03809 0, 117.955...\n\n\n2\n2017.0\nmining\n70_2017_mining\nSofronio Española\nPH175324000\nPalawan\nPH175300000\nRegion IV-B\nPH170000000\nMULTIPOLYGON Z (((117.95663 9.03869 0, 117.956...\n\n\n\n\n\n\n\nAnd a dictionary with your desired labels and assigned values in creating a mask\n\nlabels = {\n    \"mining\": 1,\n    \"neg\": 2,\n    \"agriculture\": 3,\n    \"product_extraction\": 4,\n    \"kaingin\": 5,\n    \"biophysical\": 6,\n}\n\nInput them in the generate_mask function to create a raster mask of the same dimension as the reference raster image\n\n# Generate masks for a file\nmasks, grids, values = generate_mask(\n    tiff_file=tiff_file,\n    shape_file=shape_file,\n    output_file=target_file,\n    labels_column=\"label\",\n    labels_dict=labels,\n    plot=True,\n)\n\n\n\n\n\n\n\n\n\nmasks\n\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint16)\n\n\n\ngrids\n\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint16)\n\n\n\nvalues\n\n{'mining': 1,\n 'neg': 2,\n 'agriculture': 3,\n 'product_extraction': 4,\n 'kaingin': 5,\n 'biophysical': 6}\n\n\nChoose raster images to convert into a dataframe and use the generated raster mask to add the labels the converted dataframe.\n\ntiff_files = [\"../data/vector_to_raster_mask_sample/cabanglasan.tif\"]\nmask_file = \"../data/vector_to_raster_mask_sample/labels_20220816.tiff\"\n\n\ndata = read_bands(tiff_files, mask_file)\n\n\ndata\n\n\n\n\n\n\n\n\nB1_0\nB2_0\nB3_0\nB4_0\nB5_0\nB6_0\nB7_0\nB8_0\nB9_0\nB10_0\nB11_0\nB12_0\nlabel\n\n\n\n\n0\n0.1198\n0.09635\n0.09330\n0.0698\n0.10665\n0.20250\n0.2490\n0.23525\n0.28125\n0.0377\n0.19925\n0.1002\n0\n\n\n1\n0.1198\n0.09580\n0.09245\n0.0708\n0.10665\n0.20250\n0.2490\n0.23925\n0.28125\n0.0377\n0.19925\n0.1002\n0\n\n\n2\n0.1148\n0.09420\n0.09460\n0.0707\n0.10380\n0.20395\n0.2478\n0.23150\n0.27165\n0.0385\n0.18240\n0.0902\n0\n\n\n3\n0.1148\n0.09190\n0.08850\n0.0631\n0.10380\n0.20395\n0.2478\n0.23300\n0.27165\n0.0385\n0.18240\n0.0902\n0\n\n\n4\n0.1148\n0.09350\n0.09080\n0.0643\n0.10565\n0.20830\n0.2466\n0.24205\n0.26990\n0.0385\n0.18050\n0.0894\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n775824\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n775825\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n775826\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n775827\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n775828\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n\n\n775829 rows × 13 columns",
    "crumbs": [
      "Module Reference",
      "Raster to Dataframe"
    ]
  },
  {
    "objectID": "distance_zonal_stats.html",
    "href": "distance_zonal_stats.html",
    "title": "Distance Zonal Stats",
    "section": "",
    "text": "source",
    "crumbs": [
      "Module Reference",
      "Distance Zonal Stats"
    ]
  },
  {
    "objectID": "distance_zonal_stats.html#test-data",
    "href": "distance_zonal_stats.html#test-data",
    "title": "Distance Zonal Stats",
    "section": "Test data",
    "text": "Test data\n\nSimple squares\nGiven an aoi (simple_aoi) and geodataframe containing sample data (simple_data)\n\nsimple_aoi\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n\n\n\n\n\n\n\n\nsimple_data\n\n\n\n\n\n\n\n\ngeometry\npopulation\ninternet_speed\n\n\n\n\n0\nPOLYGON ((0.25 0, 0.25 1, 1.25 1, 1.25 0, 0.25...\n100\n20.0\n\n\n1\nPOLYGON ((1.25 0, 1.25 1, 2.25 1, 2.25 0, 1.25...\n200\n10.0\n\n\n2\nPOLYGON ((2.25 0, 2.25 1, 3.25 1, 3.25 0, 2.25...\n300\n5.0\n\n\n\n\n\n\n\nWe also have simple point data which do not intersect with our AOIs.\n\nsimple_point_data\n\n\n\n\n\n\n\n\ngeometry\npopulation\ninternet_speed\n\n\n\n\n0\nPOINT (0.5 3)\n100\n20.0\n\n\n1\nPOINT (0.5 4)\n600\n120.0\n\n\n2\nPOINT (0.5 5)\n1100\n220.0\n\n\n3\nPOINT (0.5 6)\n1600\n320.0\n\n\n4\nPOINT (0.5 7)\n2100\n420.0\n\n\n5\nPOINT (1.5 3)\n200\n10.0\n\n\n6\nPOINT (1.5 4)\n700\n110.0\n\n\n7\nPOINT (1.5 5)\n1200\n210.0\n\n\n8\nPOINT (1.5 6)\n1700\n310.0\n\n\n9\nPOINT (1.5 7)\n2200\n410.0\n\n\n10\nPOINT (2.5 3)\n300\n5.0\n\n\n11\nPOINT (2.5 4)\n800\n105.0\n\n\n12\nPOINT (2.5 5)\n1300\n205.0\n\n\n13\nPOINT (2.5 6)\n1800\n305.0\n\n\n14\nPOINT (2.5 7)\n2300\n405.0\n\n\n\n\n\n\n\n\nax = plt.axes()\nax = simple_data.plot(\n    ax=ax, color=[\"orange\", \"brown\", \"purple\"], edgecolor=\"yellow\", alpha=0.4\n)\nax = simple_aoi.plot(ax=ax, facecolor=\"none\", edgecolor=[\"r\", \"g\", \"b\"])\nax = simple_point_data.plot(ax=ax)\n\n\n\n\n\n\n\n\nThe red,green,blue outlines are the 3 regions of interest (aoi) while the orange,brown, purple areas are the data areas.The blue dots are data which do not intersect our AOIs.\n\nresults = create_distance_zonal_stats(\n    simple_aoi,\n    simple_point_data,\n    max_distance=7,\n    aggregations=[\n        dict(func=\"count\"),\n        dict(func=\"sum\", column=\"population\"),\n        dict(func=\"mean\", column=\"internet_speed\"),\n    ],\n)\n\nCPU times: user 6.33 ms, sys: 1.07 ms, total: 7.4 ms\nWall time: 7.26 ms\n\n\n\nresults\n\n\n\n\n\n\n\n\ngeometry\nindex_count\npopulation_sum\ninternet_speed_mean\nnearest\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n1\n100\n20.0\n2.0\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n1\n200\n10.0\n2.0\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n1\n300\n5.0\n2.0\n\n\n\n\n\n\n\n\nresults2 = create_distance_zonal_stats(\n    simple_aoi,\n    simple_data,\n    max_distance=1,\n    aggregations=[\n        dict(func=\"count\"),\n        dict(func=\"sum\", column=\"population\"),\n        dict(func=\"mean\", column=\"internet_speed\"),\n    ],\n)\n\nCPU times: user 4.56 ms, sys: 203 µs, total: 4.76 ms\nWall time: 4.7 ms\n\n\n\nresults2\n\n\n\n\n\n\n\n\ngeometry\nindex_count\npopulation_sum\ninternet_speed_mean\nnearest\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n1\n100\n20.0\n0.0\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n2\n300\n15.0\n0.0\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n2\n500\n7.5\n0.0",
    "crumbs": [
      "Module Reference",
      "Distance Zonal Stats"
    ]
  },
  {
    "objectID": "datasets_utils.html",
    "href": "datasets_utils.html",
    "title": "Datasets Utils",
    "section": "",
    "text": "source\n\nurlretrieve\n\n urlretrieve (url, filename, headers=None, reporthook=None, timeout=None,\n              chunksize=8192)\n\nSame as urllib.request.urlretrieve but also works with Request objects\n\nsource\n\n\nmake_report_hook\n\n make_report_hook (show_progress)",
    "crumbs": [
      "Module Reference",
      "Datasets Utils"
    ]
  },
  {
    "objectID": "vector_zonal_stats.html",
    "href": "vector_zonal_stats.html",
    "title": "Vector Zonal Stats",
    "section": "",
    "text": "Aggregations\nIn order to generate zonal stats for an area (or areas) of interest (aoi) , we have come up with the concept of an aggregation specification or agg spec, which is a way to specify what aggregation functions (such as count,sum, mean,std etc.) are to be applied to columns in the source dataframe (data).\nThe method create_zonal_stats can then take in a list of these agg specs and apply them to create zonal stats from the data for the aoi.\nEach agg spec consists of a dict with the following keys:\n\nfunc: (Required) a str or a list [str] of aggregation functions. See the pandas documentation for agg\ncolumn: (Optional) an existing column in the data to generate the zonal statistic from. If not specified, the grouping key based on the index of the aoi applied to the data is used as default.\noutput: (Optional) a str or a list [str] of the name(s) of the output zonal statistic column. If not specified it is concatenated from the column and func i.e. {column}_{func} (e.g. 'func':'mean' on 'column':'population' has a default value 'output':'population_mean')\nfillna: (Optional) a bool or a list [bool] of the flag(s) that indicates whether to to a fillna(0) step for the new zonal column, True meaning it will set any NA values in the resulting zonal stat to 0, and False will retain any NA values. The default value of the flag(s) is False.\n\nExamples\n\nThe simplest aggregation spec. This will result in an output column named index_count as it will use the aoi index as the default column.\n\n{\"func\":\"count\"}\n\nThe sum function is applied to the data column population which will create an output column named total_population.\n\n{\n \"func:\"sum\",\n \"column\": \"population\",\n \"output\": \"total_population\"\n}\n\nCompute the zonal stats mean,sum,max on the population column and rename the output columns (by default) to population_mean, population_sum and population_max.\n\n{\n \"func\": [\"mean\",\"sum\",\"max\"],\n \"column\": \"population\",\n}\n\nA full aggregation spec with fillna. fillna == False for std means it will remain an NA if there is no data for the column in the group. The default value for fillna is True which means that 0 is used to replace any NA in the output column.\n\n{\n \"func\": [\"mean\", \"sum\", \"std\"],\n \"column\":\"population\",\n \"output\": [\"avg_pop\", \"total_pop\", \"std_dev\"],\n \"fillna\": [True,True,False],\n}\nThe agg spec in the list of aggregations can contain the same columns, but the output columns must be unique since they will added as columns in the results.\n\n\nRegular and Grid Zonal Stats\n\nVector zonal stats for user defined areas and grids (e.g. Admin areas)\n\n\nsource\n\n\ncreate_zonal_stats\n\n create_zonal_stats (aoi:geopandas.geodataframe.GeoDataFrame,\n                     data:geopandas.geodataframe.GeoDataFrame,\n                     aggregations:List[Dict[str,Any]],\n                     overlap_method:str='intersects')\n\nCreate zonal stats for area of interest from data using aggregration operations on data columns. Returns the same aoi with additional columns containing the computed zonal features.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\naoi\nGeoDataFrame\n\nArea of interest for which zonal stats are to be computed for\n\n\ndata\nGeoDataFrame\n\nSource gdf containing data to compute zonal stats from\n\n\naggregations\nList\n\nList of agg specs, with each agg spec applied to a data column\n\n\noverlap_method\nstr\nintersects\nspatial predicate to used in spatial join of aoi and data geopandas.sjoin for more details\n\n\nReturns\nGeoDataFrame\n\ncategorical_column_options: str = None,\n\n\n\n\nsimple_aoi  # sample aoi\n\n\n\n\n\n\n\n\ncol1\nlat0\nlon0\nlat1\nlon1\nlat2\nlon2\nlat3\nlon3\ngeometry\n\n\n\n\n0\n1\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n\n\n1\n2\n1.0\n0.0\n1.0\n1.0\n2.0\n1.0\n2.0\n0.0\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n\n\n2\n3\n2.0\n0.0\n2.0\n1.0\n3.0\n1.0\n3.0\n0.0\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n\n\n\n\n\n\n\n\nsimple_data  # sample data\n\n\n\n\n\n\n\n\ncol1\nlat\nlon\ngeometry\n\n\n\n\n0\n1\n0.50\n0.50\nPOINT (0.5 0.5)\n\n\n1\n2\n1.50\n0.50\nPOINT (1.5 0.5)\n\n\n2\n3\n2.50\n0.50\nPOINT (2.5 0.5)\n\n\n3\n4\n0.45\n0.50\nPOINT (0.45 0.5)\n\n\n4\n5\n1.45\n0.50\nPOINT (1.45 0.5)\n\n\n5\n6\n2.45\n0.50\nPOINT (2.45 0.5)\n\n\n6\n7\n0.45\n0.45\nPOINT (0.45 0.45)\n\n\n7\n8\n1.45\n0.45\nPOINT (1.45 0.45)\n\n\n8\n9\n2.45\n0.45\nPOINT (2.45 0.45)\n\n\n9\n10\n0.45\n1.45\nPOINT (0.45 1.45)\n\n\n10\n11\n1.45\n1.45\nPOINT (1.45 1.45)\n\n\n11\n12\n2.45\n1.45\nPOINT (2.45 1.45)\n\n\n\n\n\n\n\n\nax = simple_aoi.plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=[\"red\", \"blue\", \"green\"]\n)\nax = simple_data.plot(ax=ax, color=\"purple\")\n\n\n\n\n\n\n\n\n\nresults = create_zonal_stats(simple_aoi, simple_data, aggregations=[{\"func\": \"count\"}])\nresults\n\n\n\n\n\n\n\n\ncol1\nlat0\nlon0\nlat1\nlon1\nlat2\nlon2\nlat3\nlon3\ngeometry\nindex_count\n\n\n\n\n0\n1\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n3\n\n\n1\n2\n1.0\n0.0\n1.0\n1.0\n2.0\n1.0\n2.0\n0.0\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n3\n\n\n2\n3\n2.0\n0.0\n2.0\n1.0\n3.0\n1.0\n3.0\n0.0\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n3\n\n\n\n\n\n\n\nIndex name is not none\n\nnamed_index_aoi = simple_aoi.copy()\nnamed_index_aoi.index.name = \"myindex\"\n\n\nnamed_index_aoi\n\n\n\n\n\n\n\n\ncol1\nlat0\nlon0\nlat1\nlon1\nlat2\nlon2\nlat3\nlon3\ngeometry\n\n\nmyindex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n\n\n1\n2\n1.0\n0.0\n1.0\n1.0\n2.0\n1.0\n2.0\n0.0\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n\n\n2\n3\n2.0\n0.0\n2.0\n1.0\n3.0\n1.0\n3.0\n0.0\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n\n\n\n\n\n\n\n\nnamed_index_results = create_zonal_stats(\n    named_index_aoi, simple_data, aggregations=[{\"func\": \"count\"}]\n)\n\n\nnamed_index_results.head()\n\n\n\n\n\n\n\n\ncol1\nlat0\nlon0\nlat1\nlon1\nlat2\nlon2\nlat3\nlon3\ngeometry\nindex_count\n\n\nmyindex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n3\n\n\n1\n2\n1.0\n0.0\n1.0\n1.0\n2.0\n1.0\n2.0\n0.0\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n3\n\n\n2\n3\n2.0\n0.0\n2.0\n1.0\n3.0\n1.0\n3.0\n0.0\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n3\n\n\n\n\n\n\n\n\n\nBing Map Tile Grid Zonal Stats\n\nGenerating zonal stats for Bing tile grid AOIs\n\n\nsource\n\n\ncompute_quadkey\n\n compute_quadkey (data:geopandas.geodataframe.GeoDataFrame,\n                  zoom_level:int, quadkey_column:str='quadkey')\n\nComputes the quadkeys for the geometries of the data. If geometries are not points, the quadkeys are computed from the centroids of the geometries.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nGeoDataFrame\n\nThe geodataframe\n\n\nzoom_level\nint\n\nThe quadkey zoom level (1-23)\n\n\nquadkey_column\nstr\nquadkey\nThe name of the quadkey output column\n\n\nReturns\nGeoDataFrame\n\n\n\n\n\nIf our existing data geodataframe doesn’t have quadkeys, we can use the compute_quadkey to generate the quadkeys for the centroid of the data’s geometries.\n\nDATA_ZOOM_LEVEL = 19\nAOI_ZOOM_LEVEL = 9\nsimple_data_quadkey = compute_quadkey(simple_data, DATA_ZOOM_LEVEL)\n\nCPU times: user 4.32 ms, sys: 684 µs, total: 5 ms\nWall time: 4.98 ms\n\n\n\nsimple_data_quadkey.head()\n\n\n\n\n\n\n\n\ncol1\nlat\nlon\ngeometry\nquadkey\n\n\n\n\n0\n1\n0.50\n0.5\nPOINT (0.5 0.5)\n1222222221211211222\n\n\n1\n2\n1.50\n0.5\nPOINT (1.5 0.5)\n1222222320210201222\n\n\n2\n3\n2.50\n0.5\nPOINT (2.5 0.5)\n1222222331200311222\n\n\n3\n4\n0.45\n0.5\nPOINT (0.45 0.5)\n1222222221210201333\n\n\n4\n5\n1.45\n0.5\nPOINT (1.45 0.5)\n1222222320200311333\n\n\n\n\n\n\n\n\nsource\n\n\ncreate_bingtile_zonal_stats\n\n create_bingtile_zonal_stats (aoi:pandas.core.frame.DataFrame,\n                              data:pandas.core.frame.DataFrame,\n                              aggregations:List[Dict[str,Any]],\n                              aoi_quadkey_column:str='quadkey',\n                              data_quadkey_column:str='quadkey')\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\naoi\nDataFrame\n\nAn aoi with quadkey column\n\n\ndata\nDataFrame\n\nData with quadkey column\n\n\naggregations\nList\n\nList of agg specs, with each agg spec applied to a data column\n\n\naoi_quadkey_column\nstr\nquadkey\nColumn name of aoi quadkey\n\n\ndata_quadkey_column\nstr\nquadkey\nColumn name of data quadkey\n\n\nReturns\nDataFrame\n\n\n\n\n\nTo create bingtile zonal stats, we need to compute the quadkeys for the areas of interest (AOI) and the data.\nThe geowrangler.grids module provides a BingTileGridGenerator that will generate the quadkeys for the areas covered by your AOIs.\n\nimport geowrangler.grids as gr\n\n\nbgtile_generator = gr.BingTileGridGenerator(AOI_ZOOM_LEVEL)\nsimple_aoi_bingtiles = bgtile_generator.generate_grid(simple_aoi)\n\nUsing the data with the computed quadkeys, we can generate zonal stats for our bingtile grid aois. This just uses the regular pandas grouping and merging function and skips any geospatial joins which results in faster computation.\n\nbingtile_results = create_bingtile_zonal_stats(\n    simple_aoi_bingtiles,\n    simple_data_quadkey,\n    aggregations=[dict(func=\"count\", fillna=True)],\n)\n\nCPU times: user 5.02 ms, sys: 438 µs, total: 5.46 ms\nWall time: 6.08 ms\n\n\n\nbingtile_results\n\n\n\n\n\n\n\n\nquadkey\ngeometry\nindex_count\n\n\n\n\n0\n122222220\nPOLYGON ((0 0.70311, 0 1.40611, 0.70312 1.4061...\n0.0\n\n\n1\n122222221\nPOLYGON ((0.70312 0.70311, 0.70312 1.40611, 1....\n0.0\n\n\n2\n122222230\nPOLYGON ((1.40625 0.70311, 1.40625 1.40611, 2....\n0.0\n\n\n3\n122222231\nPOLYGON ((2.10937 0.70311, 2.10937 1.40611, 2....\n0.0\n\n\n4\n122222320\nPOLYGON ((2.8125 0.70311, 2.8125 1.40611, 3.51...\n0.0\n\n\n5\n122222222\nPOLYGON ((0 0, 0 0.70311, 0.70312 0.70311, 0.7...\n3.0\n\n\n6\n122222223\nPOLYGON ((0.70312 0, 0.70312 0.70311, 1.40625 ...\n0.0\n\n\n7\n122222232\nPOLYGON ((1.40625 0, 1.40625 0.70311, 2.10937 ...\n3.0\n\n\n8\n122222233\nPOLYGON ((2.10937 0, 2.10937 0.70311, 2.8125 0...\n3.0\n\n\n9\n122222322\nPOLYGON ((2.8125 0, 2.8125 0.70311, 3.51562 0....\n0.0\n\n\n\n\n\n\n\nWe can also use any bingtile grid for any zoom level lower than the data’s zoom level\n\nbgtile_generator10 = gr.BingTileGridGenerator(AOI_ZOOM_LEVEL + 1)\nsimple_aoi_bingtiles10 = bgtile_generator10.generate_grid(simple_aoi)\n\n\nbingtile_results10 = create_bingtile_zonal_stats(\n    simple_aoi_bingtiles10,\n    simple_data_quadkey,\n    aggregations=[dict(func=\"count\", fillna=True)],\n)\n\n\nbingtile_results10[bingtile_results10.index_count &gt; 0]\n\n\n\n\n\n\n\n\nquadkey\ngeometry\nindex_count\n\n\n\n\n10\n1222222221\nPOLYGON ((0.35156 0.35156, 0.35156 0.70311, 0....\n3.0\n\n\n13\n1222222320\nPOLYGON ((1.40625 0.35156, 1.40625 0.70311, 1....\n3.0\n\n\n15\n1222222330\nPOLYGON ((2.10937 0.35156, 2.10937 0.70311, 2....\n2.0\n\n\n16\n1222222331\nPOLYGON ((2.46094 0.35156, 2.46094 0.70311, 2....\n1.0\n\n\n\n\n\n\n\n\nax = results.plot(ax=plt.axes(), column=\"index_count\", edgecolor=\"blue\", alpha=0.2)\nax = simple_data.plot(ax=ax, color=\"purple\")\nax = bingtile_results.plot(ax=ax, column=\"index_count\", edgecolor=\"black\", alpha=0.4)\nax = bingtile_results10.plot(ax=ax, column=\"index_count\", edgecolor=\"red\", alpha=0.4)",
    "crumbs": [
      "Module Reference",
      "Vector Zonal Stats"
    ]
  },
  {
    "objectID": "tutorial.raster_process.html",
    "href": "tutorial.raster_process.html",
    "title": "Raster Processing Tutorial",
    "section": "",
    "text": "A basic introduction to raster processing",
    "crumbs": [
      "Tutorials",
      "Raster Processing Tutorial"
    ]
  },
  {
    "objectID": "tutorial.raster_process.html#summary",
    "href": "tutorial.raster_process.html#summary",
    "title": "Raster Processing Tutorial",
    "section": "Summary",
    "text": "Summary\nCropping rasters based on the borders of a polygon. Usage of this function assumes an input raster and a geodataframe from which to extract bounds. There is also an option to crop multiple geometries at once (e.g., crop raster using bounds of each cell in a grid).",
    "crumbs": [
      "Tutorials",
      "Raster Processing Tutorial"
    ]
  },
  {
    "objectID": "tutorial.raster_process.html#how-does-it-work",
    "href": "tutorial.raster_process.html#how-does-it-work",
    "title": "Raster Processing Tutorial",
    "section": "How does it work?",
    "text": "How does it work?\nReturns a subset of a rasterio dataset. This function assumes that the bounding coordinates for the desired cropped rasters are present in the input geodataframe’s geometry column.\n\nquery_window_by_polygon(raster, output_folder, gdf, mask)\nFor cropping a raster based on boundaries of a single polygon. A technical step-by-step explanation of how query_window_by_polygon works is detailed in the cell blocks below.\n\n\n\n\n\n\n\n\n\n\n\ntype\ndefault\noptional/ required\ndetails\n\n\n\n\nraster\nString\nnone\nrequired\nlocal filename of raster or open raster dataset\n\n\noutput_folder\nString\nnone\nrequired\nfile path where cropped raster outputs will be saved\n\n\ngdf\nGeoDataFrame\nnone\nrequired\npolygon that will become basis of boundaries for cropping\n\n\nmask\nBoolean\nnone\nrequired\nTrue- Assign NULL to areas outside borders of a non-rectangular polygon  False- Retain values outside borders of a non-rectangular polygon\n\n\n\n\nDefine the function and its arguments.\n\ndef query_window_by_polygon(\n    input_raster: Union[str, DatasetReader, PosixPath],\n    output_path: str,\n    geometry: Polygon,\n    mask=False,\n) -&gt; None:\n\nCheck if raster is specified as PosixPath and convert to String.\n\n    if isinstance(input_raster, PosixPath):\n        input_raster = str(input_raster)\n\nCheck if raster is path to a file or an open raster dataset.\n\n    if isinstance(input_raster,str):\n         input_dset = rio.open(input_raster)\n    else:\n         input_dset = input_raster\n\nGet the window bounds (left, right, top, bottom coordinates) from polygon geometry and check if it has the correct number of elements.\n\n    window_bounds = geometry.bounds\n    assert (\n        len(window_bounds) == 4\n    ), \n\nUnroll window bounds.\n\n    left, bottom, right, top = window_bounds\n\nOpen raster as input.\n\n    with rio.open(input_raster) as input_dst:\n\nGet profile of input_dst:\n\n        input_profile = input_dst.profile\n\nSpecify window and query subset.\n\n        window = rio.windows.from_bounds(left, bottom, right, top, input_dst.transform)\n        subset = input_dst.read(window=window)\n\nGet the shape of the output subset.\n\n        number_of_bands, height, width = subset.shape\n\nGet the transformation of the subset based on the window.\n\n        win_transform = input_dst.window_transform(window)\n\nUpdate metadata for the output.\n\n        output_profile = input_profile.copy()\n        update_params = {\n            \"count\": number_of_bands,\n            \"height\": height,\n            \"width\": width,\n            \"transform\": win_transform,\n        }\n        output_profile.update(update_params)\n\nWrite image to output file.\n\n        with rio.open(output_path, \"w\", **output_profile) as output_dst:\n            output_dst.write(subset)\n            output_dst.colorinterp = input_dst.colorinterp\n\nApply mask according to shape of the polygon.\n\n    if mask:\n        with rio.open(output_path) as dst:\n            masked_image, masked_transform = rio.mask.mask(dst, [geometry], crop=True)\n        with rio.open(output_path, \"w\", **output_profile) as output_dst:\n            update_params = {\n                \"height\": masked_image.shape[1],\n                \"width\": masked_image.shape[2],\n                \"transform\": masked_transform,\n            }\n            output_profile.update(update_params)\n            output_dst.write(masked_image)\n\nReturn output.\n\n    return \n\n\nquery_window_by_gdf(raster, output_folder, gdf, name_col, mask)\nFor cropping a raster based on boundaries of multiple polygons. A step-by-step explanation of how query_window_by_gdf works is detailed in the cell blocks below.\n\n\n\n\n\n\n\n\n\n\n\ntype\ndefault\noptional/ required\ndetails\n\n\n\n\nraster\nString\nnone\nrequired\nlocal filename of raster or open raster dataset\n\n\noutput_folder\nString\nnone\nrequired\nfile path where cropped raster outputs will be saved\n\n\ngdf\nGeoDataFrame\nnone\nrequired\npolygon that will become basis of boundaries for cropping\n\n\nname_col\nString\nnone\noptional\ncolumn name to base output filepath on. if left blank, outputs will be name sequentially as ‘output_0.tif’\n\n\nmask\nBoolean\nnone\nrequired\nTrue- Assign NULL to areas outside borders of a non-rectangular polygon  False- Retain values outside borders of a non-rectangular polygon\n\n\n\n\nDefine the function and create a copy of the geodataframe.\n\ndef query_window_by_gdf(\n    input_raster: Union[str, DatasetReader, PosixPath],\n    output_folder: str,\n    gdf,\n    name_col=None,\n    mask=False,\n) -&gt; None:\n    gdf = gdf.copy()\n\nCheck if the coordinate reference systems of the raster and geodataframe match.\n\n    with rio.open(input_raster) as dst:\n        assert dst.meta[\"crs\"] == gdf.crs, \"input_raster and gdf CRS must match!\"\n\nName outputs based on values from name_col.\n\n    if name_col is None:\n        name_col = \"name\"\n        gdf[name_col] = \"output_\" + gdf.reset_index().index.astype(str) + \".tif\"\n    else:\n        gdf[name_col] = gdf[name_col] + \".tif\"\n\n    for i, row in gdf.iterrows():\n        polygon = row.geometry\n        output_name = row[name_col]\n        output_path = output_folder / output_name\n        print(output_path)\n        query_window_by_polygon(input_raster, output_path, polygon, mask)",
    "crumbs": [
      "Tutorials",
      "Raster Processing Tutorial"
    ]
  },
  {
    "objectID": "tutorial.raster_process.html#sample-use-case-1--crop-raster-with-single-circular-polygon",
    "href": "tutorial.raster_process.html#sample-use-case-1--crop-raster-with-single-circular-polygon",
    "title": "Raster Processing Tutorial",
    "section": "Sample use case 1- Crop raster with single circular polygon",
    "text": "Sample use case 1- Crop raster with single circular polygon\nInput: - input_image - raster of 2020 Philippine population - output_folder - filepath to where output raster will be saved - circle_gdf - GeoDataFrame containining single circular polygon - mask - True- to assign NULL values to cells outside the circular polygon\nOutput: - cropped raster (GeoTiff) containing only values within circular polygon\n\nStep 1: Import packages\n\nimport rasterio as rio\n\nimport geowrangler.raster_process as raster_process\n\n\n\nStep 2: Load raster\n\ninput_image\n\n'../data/phl_ppp_2020_constrained.tif'\n\n\n\nraster = rio.open(input_image)\n\n\nshow(raster.read(1), cmap=\"plasma\", transform=raster.transform);\n\n\n\n\n\n\n\n\n\n\nStep 3: Load polygon\n\ncircle_gdf\n\n\n\n\n\n\n\n\nlat\nlon\ngeometry\n\n\n\n\n0\n14.599512\n120.984222\nPOLYGON ((121.99932 14.59951, 121.99443 14.503...\n\n\n\n\n\n\n\n\n\nStep 4: Check if the polygon is within bounds of the raster.\n\nfig, ax = plt.subplots(1, 1, figsize=(4, 8))\nshow(raster.read(1), cmap=\"viridis\", ax=ax, transform=raster.transform)\ncircle_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"yellow\")\nax;\n\n\n\n\n\n\n\n\n\n\nStep 5: State filepath of output folder.\n\noutput_folder = Path(\"../data\")\n\n\n\nStep 6: Crop raster\n\nraster_process.query_window_by_gdf(input_image, output_folder, circle_gdf, mask=True)\n\n../data/output_0.tif\n\n\n\nwith rio.open(output_folder / \"output_0.tif\") as dst:\n    fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n\n    show(dst.read(1), cmap=\"viridis\", ax=ax, transform=dst.transform)\n    circle_gdf.plot(facecolor=\"none\", edgecolor=\"yellow\", ax=ax)\n    print(dst.read(1))\nax;\n\n[[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n ...\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]]",
    "crumbs": [
      "Tutorials",
      "Raster Processing Tutorial"
    ]
  },
  {
    "objectID": "tutorial.raster_process.html#sample-use-case-2--crop-raster-with-multiple-cells-from-a-grid",
    "href": "tutorial.raster_process.html#sample-use-case-2--crop-raster-with-multiple-cells-from-a-grid",
    "title": "Raster Processing Tutorial",
    "section": "Sample use case 2- Crop raster with multiple cells from a grid",
    "text": "Sample use case 2- Crop raster with multiple cells from a grid\nInput: - input_image - raster of 2020 Philippine population - output_folder - filepath to where output rasters will be saved - grid_gdf - GeoDataFrame containining multiple polygons (grid cells) - mask - False- no need to assign NULL values because grid cells occupy full space from image center to boundaries\nOutput: - multiple cropped rasters (GeoTiff) split according to grid cell polygons\n\nStep 1: Import packages\n\nimport rasterio as rio\n\nimport geowrangler.raster_process\n\n\n\nStep 2: Load raster\n\ninput_image\n\n'../data/phl_ppp_2020_constrained.tif'\n\n\n\nraster = rio.open(input_image)\nshow(raster.read(1), cmap=\"plasma\", transform=raster.transform)\n\n\n\n\n\n\n\n\n\n\nStep 3: Load grid\n\ngrid_gdf\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nname\n\n\n\n\n0\n0\n0\nPOLYGON ((119.96913 13.61504, 120.86744 13.615...\ngridxy-0-0\n\n\n1\n0\n1\nPOLYGON ((119.96913 14.48647, 120.86744 14.486...\ngridxy-0-1\n\n\n2\n0\n2\nPOLYGON ((119.96913 15.35449, 120.86744 15.354...\ngridxy-0-2\n\n\n3\n1\n0\nPOLYGON ((120.86744 13.61504, 121.76576 13.615...\ngridxy-1-0\n\n\n4\n1\n1\nPOLYGON ((120.86744 14.48647, 121.76576 14.486...\ngridxy-1-1\n\n\n5\n1\n2\nPOLYGON ((120.86744 15.35449, 121.76576 15.354...\ngridxy-1-2\n\n\n6\n2\n0\nPOLYGON ((121.76576 13.61504, 122.66407 13.615...\ngridxy-2-0\n\n\n7\n2\n1\nPOLYGON ((121.76576 14.48647, 122.66407 14.486...\ngridxy-2-1\n\n\n\n\n\n\n\n\n\nStep 4: Check if the grid is within bounds of the raster.\n\nfig, ax = plt.subplots(1, 1, figsize=(4, 8))\nshow(raster.read(1), cmap=\"viridis\", ax=ax, transform=raster.transform)\ngrid_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"yellow\")\nax\n\n\n\n\n\n\n\n\n\n\nStep 5: State filepath of output folder.\n\noutput_folder = Path(\"../data\")\n\n\n\nStep 6: Crop raster\n\nraster_process.query_window_by_gdf(\n    input_image, output_folder, grid_gdf, name_col=\"name\", mask=False\n)\n\n../data/gridxy-0-0.tif\n../data/gridxy-0-1.tif\n../data/gridxy-0-2.tif\n../data/gridxy-1-0.tif\n../data/gridxy-1-1.tif\n../data/gridxy-1-2.tif\n../data/gridxy-2-0.tif\n../data/gridxy-2-1.tif\n\n\n\nfor name in grid_gdf[\"name\"]:\n    image_path = output_folder / (name + \".tif\")\n    with rio.open(image_path) as dst:\n        fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n        ax.set_title(image_path)\n        show(dst.read(1), cmap=\"viridis\", ax=ax, transform=dst.transform)",
    "crumbs": [
      "Tutorials",
      "Raster Processing Tutorial"
    ]
  },
  {
    "objectID": "tile_clustering.html",
    "href": "tile_clustering.html",
    "title": "Tile Clustering",
    "section": "",
    "text": "source",
    "crumbs": [
      "Module Reference",
      "Tile Clustering"
    ]
  },
  {
    "objectID": "tile_clustering.html#test-data",
    "href": "tile_clustering.html#test-data",
    "title": "Tile Clustering",
    "section": "Test data",
    "text": "Test data\nCreate sample scores for square grid cells and cluster the cells\n\nimport geopandas as gpd\nimport numpy as np\n\nfrom geowrangler import grids\n\n\nnp.random.seed(1562)\n\nregion3_gdf = gpd.read_file(\"../data/region3_admin.geojson\")\n\n\ngrid_generator5k = grids.SquareGridGenerator(5_000)\ngrid_gdf5k = grid_generator5k.generate_grid(region3_gdf)\ngrid_gdf5k.head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n\n\n3\n9\n9\nPOLYGON ((120.19008 14.79871, 120.23499 14.798...\n\n\n4\n10\n9\nPOLYGON ((120.23499 14.79871, 120.27991 14.798...\n\n\n\n\n\n\n\n\ngrid_gdf5k.plot()\n\n\n\n\n\n\n\n\n\ngrid_gdf5k[\"score\"] = np.random.random(len(grid_gdf5k))\ngrid_gdf5k[\"class\"] = grid_gdf5k[\"score\"] &gt; 0.7\ngrid_gdf5k.head()\n\nCPU times: user 3.15 ms, sys: 1.32 ms, total: 4.47 ms\nWall time: 10 ms\n\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nscore\nclass\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n0.761806\nTrue\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n0.012455\nFalse\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n0.446552\nFalse\n\n\n3\n9\n9\nPOLYGON ((120.19008 14.79871, 120.23499 14.798...\n0.669020\nFalse\n\n\n4\n10\n9\nPOLYGON ((120.23499 14.79871, 120.27991 14.798...\n0.815914\nTrue\n\n\n\n\n\n\n\n\ntileclustering = TileClustering()\ngrid_gdf5k = tileclustering.cluster_tiles(grid_gdf5k, category_col=\"class\")\ngrid_gdf5k.head()\n\nCPU times: user 25.8 ms, sys: 0 ns, total: 25.8 ms\nWall time: 47.6 ms\n\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nscore\nclass\ntile_cluster\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n0.761806\nTrue\n6-1\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n0.012455\nFalse\n7-2\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n0.446552\nFalse\n1-2\n\n\n3\n9\n9\nPOLYGON ((120.19008 14.79871, 120.23499 14.798...\n0.669020\nFalse\n1-2\n\n\n4\n10\n9\nPOLYGON ((120.23499 14.79871, 120.27991 14.798...\n0.815914\nTrue\n23-1\n\n\n\n\n\n\n\n\ngrid_gdf5k[\"tile_cluster\"].nunique()\n\n160\n\n\n\ngrid_gdf5k.plot(column=\"class\", categorical=True, cmap=\"Spectral\")",
    "crumbs": [
      "Module Reference",
      "Tile Clustering"
    ]
  },
  {
    "objectID": "overview.usecase_ookla.html",
    "href": "overview.usecase_ookla.html",
    "title": "Exploring Internet Speeds with Ookla",
    "section": "",
    "text": "A simple use case demo for using geowrangler modules to find the Philippine provinces/towns with the slowest/fastest internet speeds.",
    "crumbs": [
      "Use Case Demos",
      "Exploring Internet Speeds with Ookla"
    ]
  },
  {
    "objectID": "overview.usecase_ookla.html#summary",
    "href": "overview.usecase_ookla.html#summary",
    "title": "Exploring Internet Speeds with Ookla",
    "section": "Summary",
    "text": "Summary\nThis Use Case Demo shows how to use the geowrangler.datasets.ookla and the geowrangler.area_zonal_stats modules to find the slowest/fastest internet speeds within an area or region of interest.\n\nHow geowrangler can make this process easier\nGeowrangler can:\n\nValidate your geodataframes\nHelp you download Ookla data (internet speed)\nGenerate zonal stats for your province/town\n\n\n\nWhat you need to do\n\nGet your AOIs (areas of interest) - get the boundaries of your administrative regions\nDownload ookla data\nValidate AOIs and ookla data\nGenerate zonal Stats\nAnalyze and find fastest/slowest internet speeds",
    "crumbs": [
      "Use Case Demos",
      "Exploring Internet Speeds with Ookla"
    ]
  },
  {
    "objectID": "overview.usecase_ookla.html#tutorial",
    "href": "overview.usecase_ookla.html#tutorial",
    "title": "Exploring Internet Speeds with Ookla",
    "section": "Tutorial",
    "text": "Tutorial\n\nImport libraries\nLets start by importing the required libraries\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport geowrangler.area_zonal_stats as azs\n\n\n\nDownload Admin Areas\nNext, we get the administrative boundaries geodataset using data from Humanitarian Data Exchange\n\nSet Region Filter\n\n\n\n\n\n\nImportant\n\n\n\nSetting the region filter to None will compute the zonal stats for the whole Philippines and can take a lot longer than for a region.\n\n\nSet the REGION_FILTER to your Region (or None for the whole Philippines).\n\n# REGION_FILTER = None  # All regions\nREGION_FILTER = \"National Capital Region (NCR)\"  # limit to 1 to speed up processin\n\nDownload the geodataset containing the admin areas of your country.\nHere we are using the data for the Philippines.\n\nphl_admin_file = \"phl_adminboundaries\"\nphl_admin_zip = f\"{phl_admin_file}.zip\"\n# shapefiles\nphl_admin_link = f\"https://data.humdata.org/dataset/caf116df-f984-4deb-85ca-41b349d3f313/resource/12457689-6a86-4474-8032-5ca9464d38a8/download/phl_adm_psa_namria_20231106_shp.zip\"\n\nDownload the zipped file. Depending on your internet connection, it can take several minutes.\n\n![ ! -e ../data/{phl_admin_zip} ] && curl -L -o ../data/{phl_admin_zip} {phl_admin_link}\n\nCPU times: user 901 µs, sys: 2.68 ms, total: 3.59 ms\nWall time: 279 ms\n\n\n\n!mkdir -p ../data/{phl_admin_file}\n\n\nmain_file = \"phl_admbnda_adm3_psa_namria_20231106\"\nphl_admin3_shp = f\"../data/{phl_admin_file}/{main_file}.shp\"\n\n\n![ ! -e {phl_admin3_shp} ] && unzip -d ../data/{phl_admin_file} ../data/{phl_admin_zip}\n\nCPU times: user 907 µs, sys: 2.5 ms, total: 3.41 ms\nWall time: 279 ms\n\n\nLoad the admin area geo dataset.\nIn our example we are loading the .shp or shape file as a geopandas dataframe.\n\nprint(f\"loading {phl_admin3_shp}\")\nadmin3 = gpd.read_file(phl_admin3_shp)\n\nloading ../data/phl_adminboundaries/phl_admbnda_adm3_psa_namria_20231106.shp\nCPU times: user 245 ms, sys: 68.7 ms, total: 313 ms\nWall time: 327 ms\n\n\n\nadmin3.head()\n\n\n\n\n\n\n\n\nADM3_EN\nADM3_PCODE\nADM2_EN\nADM2_PCODE\nADM1_EN\nADM1_PCODE\nADM0_EN\nADM0_PCODE\ndate\nvalidOn\nvalidTo\nADM3_REF\nADM3ALT1EN\nShape_Leng\nShape_Area\nAREA_SQKM\ngeometry\n\n\n\n\n0\nAdams\nPH0102801\nIlocos Norte\nPH01028\nRegion I (Ilocos Region)\nPH01\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.423604\n0.009506\n111.143026\nPOLYGON ((120.96915 18.51012, 120.95867 18.463...\n\n\n1\nBacarra\nPH0102802\nIlocos Norte\nPH01028\nRegion I (Ilocos Region)\nPH01\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.309136\n0.004725\n55.303195\nPOLYGON ((120.66821 18.28705, 120.66441 18.282...\n\n\n2\nBadoc\nPH0102803\nIlocos Norte\nPH01028\nRegion I (Ilocos Region)\nPH01\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.599295\n0.006880\n80.683970\nPOLYGON ((120.47814 17.97717, 120.47816 17.977...\n\n\n3\nBangui\nPH0102804\nIlocos Norte\nPH01028\nRegion I (Ilocos Region)\nPH01\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.483066\n0.009843\n115.059041\nPOLYGON ((120.81318 18.53457, 120.81358 18.533...\n\n\n4\nCity of Batac\nPH0102805\nIlocos Norte\nPH01028\nRegion I (Ilocos Region)\nPH01\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.613500\n0.013493\n158.123132\nPOLYGON ((120.61242 18.10947, 120.612 18.10679...\n\n\n\n\n\n\n\n\nlist(admin3.columns.values)\n\n['ADM3_EN',\n 'ADM3_PCODE',\n 'ADM2_EN',\n 'ADM2_PCODE',\n 'ADM1_EN',\n 'ADM1_PCODE',\n 'ADM0_EN',\n 'ADM0_PCODE',\n 'date',\n 'validOn',\n 'validTo',\n 'ADM3_REF',\n 'ADM3ALT1EN',\n 'Shape_Leng',\n 'Shape_Area',\n 'AREA_SQKM',\n 'geometry']\n\n\n\nadmin3.ADM1_EN.unique()\n\narray(['Region I (Ilocos Region)', 'Region II (Cagayan Valley)',\n       'Region III (Central Luzon)', 'Region IV-A (Calabarzon)',\n       'Region V (Bicol Region)', 'Region VI (Western Visayas)',\n       'Region VII (Central Visayas)', 'Region VIII (Eastern Visayas)',\n       'Region IX (Zamboanga Peninsula)', 'Region X (Northern Mindanao)',\n       'Region XI (Davao Region)', 'Region XII (Soccsksargen)',\n       'National Capital Region (NCR)',\n       'Cordillera Administrative Region (CAR)', 'Region XIII (Caraga)',\n       'Mimaropa Region',\n       'Bangsamoro Autonomous Region In Muslim Mindanao (BARMM)'],\n      dtype=object)\n\n\nLimit the admin regions to only 1 in order to make the process run faster.\nThe REGION FILTER is set in the Set Region Filter Section\n\nif REGION_FILTER:\n    admin3 = admin3[admin3.ADM1_EN == REGION_FILTER]\n\n\nimport matplotlib.pyplot as plt\n\n\nax = plt.axes()\nax = admin3.plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\")\n\n\n\n\n\n\n\n\n\n\n\nAdmin 3 Levels for NCR\n\n\n\nax = plt.axes()\nax = admin3[admin3.ADM3_EN == \"Pateros\"].plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\")\n\nCPU times: user 22.8 ms, sys: 1.43 ms, total: 24.2 ms\nWall time: 23.7 ms\n\n\n\n\n\n\n\n\n\n\nadmin3.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nadmin3.total_bounds\n\narray([120.90639543,  14.35172957, 121.13503641,  14.78529173])\n\n\n\nlen(admin3)\n\n17\n\n\n\n\n\nDownload Ookla data\nUse the geowrangler.datasets.ookla module to explore and download ookla (internet speed) data\n\nfrom geowrangler.datasets import ookla\n\nList the publically available ookla datasets\n\nookla_dsets = ookla.list_ookla_files()\nookla_dsets\n\nCPU times: user 34.2 ms, sys: 2.73 ms, total: 36.9 ms\nWall time: 639 ms\n\n\n{OoklaQuarter(type='fixed', year='2019', quarter='1'): '2019-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2019', quarter='2'): '2019-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2019', quarter='3'): '2019-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2019', quarter='4'): '2019-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='1'): '2020-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='2'): '2020-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='3'): '2020-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='4'): '2020-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='1'): '2021-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='2'): '2021-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='3'): '2021-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='4'): '2021-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='1'): '2022-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='2'): '2022-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='3'): '2022-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='4'): '2022-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2023', quarter='1'): '2023-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2023', quarter='2'): '2023-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2023', quarter='3'): '2023-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2023', quarter='4'): '2023-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2024', quarter='1'): '2024-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2024', quarter='2'): '2024-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='1'): '2019-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='2'): '2019-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='3'): '2019-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='4'): '2019-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='1'): '2020-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='2'): '2020-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='3'): '2020-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='4'): '2020-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='1'): '2021-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='2'): '2021-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='3'): '2021-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='4'): '2021-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='1'): '2022-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='2'): '2022-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='3'): '2022-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='4'): '2022-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2023', quarter='1'): '2023-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2023', quarter='2'): '2023-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2023', quarter='3'): '2023-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2023', quarter='4'): '2023-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2024', quarter='1'): '2024-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2024', quarter='2'): '2024-04-01_performance_mobile_tiles.parquet'}\n\n\nDownload the latest data (as of the time of writing this)\n\nookla_params = dict(year=\"2022\", quarter=\"2\", directory=\"../data\")\n\n\nookla_fixed = ookla.download_ookla_file(type_=\"fixed\", **ookla_params)\n\nCPU times: user 126 µs, sys: 63 µs, total: 189 µs\nWall time: 139 µs\n\n\n\nookla_fixed\n\nPath('../data/2022-04-01_performance_fixed_tiles.parquet')\n\n\n\n\nConvert ookla data into a GeoDataFrame\nThe downloaded file from ookla is not yet a geodataset, so we will h have to convert it into a GeoDataFrame suitable for use in geowrangler.\n\nimport pandas as pd\n\nThe downloaded ookla data contains the internet speed data for the whole world and can take a minute or two to load.\nLater, we will show how to filter the data to only include the data relevant to our AOI.\n\nfixed = pd.read_parquet(ookla_fixed)\n\nCPU times: user 3.1 s, sys: 1.57 s, total: 4.67 s\nWall time: 4.27 s\n\n\n\nlen(fixed)\n\n6598700\n\n\n\nfixed.head()\n\n\n\n\n\n\n\n\nquadkey\ntile\ntile_x\ntile_y\navg_d_kbps\navg_u_kbps\navg_lat_ms\navg_lat_down_ms\navg_lat_up_ms\ntests\ndevices\n\n\n\n\n0\n0022133222312322\nPOLYGON((-160.02685546875 70.6435894914449, -1...\n-160.0241\n70.6427\n8324\n3798\n91\nNaN\nNaN\n2\n1\n\n\n1\n0022133222330100\nPOLYGON((-160.02685546875 70.6417687358462, -1...\n-160.0241\n70.6409\n14972\n4461\n94\nNaN\nNaN\n29\n2\n\n\n2\n0022133222330201\nPOLYGON((-160.043334960938 70.6344840663086, -...\n-160.0406\n70.6336\n6253\n2818\n91\nNaN\nNaN\n1\n1\n\n\n3\n0022202203233313\nPOLYGON((-179.478149414062 68.9169336615194, -...\n-179.4754\n68.9159\n700\n126\n1090\nNaN\nNaN\n1\n1\n\n\n4\n0022222211003013\nPOLYGON((-178.884887695312 67.048162117316, -1...\n-178.8821\n67.0471\n6617\n2019\n977\nNaN\nNaN\n1\n1\n\n\n\n\n\n\n\n\nfixed.dtypes\n\nquadkey             object\ntile                object\ntile_x             float64\ntile_y             float64\navg_d_kbps           int64\navg_u_kbps           int64\navg_lat_ms           int64\navg_lat_down_ms    float64\navg_lat_up_ms      float64\ntests                int64\ndevices              int64\ndtype: object\n\n\nThe data is now a Pandas DataFrame but this needs to be converted to a GeoDataFrame by converting the tile column into a geometry with a crs (Coordinate Reference System).\nSee EPSG:4326 for more details about the CRS.\nConverting the data can also take a minute or two.\n\nfixed[\"geometry\"] = gpd.GeoSeries.from_wkt(fixed.tile, crs=\"EPSG:4326\")\n\nCPU times: user 7.99 s, sys: 775 ms, total: 8.77 s\nWall time: 9.25 s\n\n\n\nfixed.head()\n\n\n\n\n\n\n\n\nquadkey\ntile\ntile_x\ntile_y\navg_d_kbps\navg_u_kbps\navg_lat_ms\navg_lat_down_ms\navg_lat_up_ms\ntests\ndevices\ngeometry\n\n\n\n\n0\n0022133222312322\nPOLYGON((-160.02685546875 70.6435894914449, -1...\n-160.0241\n70.6427\n8324\n3798\n91\nNaN\nNaN\n2\n1\nPOLYGON ((-160.02686 70.64359, -160.02136 70.6...\n\n\n1\n0022133222330100\nPOLYGON((-160.02685546875 70.6417687358462, -1...\n-160.0241\n70.6409\n14972\n4461\n94\nNaN\nNaN\n29\n2\nPOLYGON ((-160.02686 70.64177, -160.02136 70.6...\n\n\n2\n0022133222330201\nPOLYGON((-160.043334960938 70.6344840663086, -...\n-160.0406\n70.6336\n6253\n2818\n91\nNaN\nNaN\n1\n1\nPOLYGON ((-160.04333 70.63448, -160.03784 70.6...\n\n\n3\n0022202203233313\nPOLYGON((-179.478149414062 68.9169336615194, -...\n-179.4754\n68.9159\n700\n126\n1090\nNaN\nNaN\n1\n1\nPOLYGON ((-179.47815 68.91693, -179.47266 68.9...\n\n\n4\n0022222211003013\nPOLYGON((-178.884887695312 67.048162117316, -1...\n-178.8821\n67.0471\n6617\n2019\n977\nNaN\nNaN\n1\n1\nPOLYGON ((-178.88489 67.04816, -178.87939 67.0...\n\n\n\n\n\n\n\n\nfixed = fixed.drop(columns=[\"tile\"])\n\nCPU times: user 106 ms, sys: 276 ms, total: 382 ms\nWall time: 592 ms\n\n\n\nfixed = gpd.GeoDataFrame(fixed, geometry=\"geometry\", crs=\"EPSG:4326\")\n\nCPU times: user 161 ms, sys: 105 ms, total: 266 ms\nWall time: 343 ms\n\n\n\n\nValidate AOI and Data Geometries\nIn order to prevent more headaches as we process and analyze geospatial datasets down the line, it is prudent to check that our datasets have valid geometries.\nWe can use the geowrangler.validation module to check as well fix these problems.\n\nfrom geowrangler.validation import GeometryValidation\n\n\nValidate AOI\n\nadmin3_gvm = GeometryValidation(admin3)\n\n\nvalid_admin3 = admin3_gvm.validate_all()\n\nCPU times: user 33 ms, sys: 2.37 ms, total: 35.4 ms\nWall time: 35 ms\n\n\n\nvalid_admin3.head()\n\n\n\n\n\n\n\n\nADM3_EN\nADM3_PCODE\nADM2_EN\nADM2_PCODE\nADM1_EN\nADM1_PCODE\nADM0_EN\nADM0_PCODE\ndate\nvalidOn\nvalidTo\nADM3_REF\nADM3ALT1EN\nShape_Leng\nShape_Area\nAREA_SQKM\ngeometry\nis_not_null\nis_not_self_intersecting\nis_oriented_properly\nis_within_crs_bounds\narea_is_not_zero\n\n\n\n\n1275\nCity of Manila\nPH1303901\nMetropolitan Manila First District\nPH13039\nNational Capital Region (NCR)\nPH13\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.600152\n0.003520\n41.960090\nPOLYGON ((120.98508 14.63998, 120.98502 14.639...\nTrue\nTrue\nFalse\nTrue\nTrue\n\n\n1276\nCity of Mandaluyong\nPH1307401\nMetropolitan Manila Second District\nPH13074\nNational Capital Region (NCR)\nPH13\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.141520\n0.000949\n11.314034\nPOLYGON ((121.05966 14.59007, 121.05729 14.589...\nTrue\nTrue\nFalse\nTrue\nTrue\n\n\n1277\nCity of Marikina\nPH1307402\nMetropolitan Manila Second District\nPH13074\nNational Capital Region (NCR)\nPH13\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.257017\n0.001924\n22.931403\nPOLYGON ((121.13338 14.65369, 121.13344 14.653...\nTrue\nTrue\nFalse\nTrue\nTrue\n\n\n1278\nCity of Pasig\nPH1307403\nMetropolitan Manila Second District\nPH13074\nNational Capital Region (NCR)\nPH13\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.344848\n0.002626\n31.304225\nPOLYGON ((121.10188 14.62066, 121.09785 14.619...\nTrue\nTrue\nFalse\nTrue\nTrue\n\n\n1279\nQuezon City\nPH1307404\nMetropolitan Manila Second District\nPH13074\nNational Capital Region (NCR)\nPH13\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.773902\n0.013630\n162.439224\nPOLYGON ((121.12563 14.71782, 121.1256 14.7178...\nTrue\nTrue\nFalse\nTrue\nTrue\n\n\n\n\n\n\n\n\nvalid_cols = [\n    \"is_oriented_properly\",\n    \"is_not_null\",\n    \"is_not_self_intersecting\",\n    \"is_within_crs_bounds\",\n    \"area_is_not_zero\",\n]\n\n\n[valid_admin3[col].value_counts() for col in valid_cols]\n\n[is_oriented_properly\n False    17\n Name: count, dtype: int64,\n is_not_null\n True    17\n Name: count, dtype: int64,\n is_not_self_intersecting\n True    17\n Name: count, dtype: int64,\n is_within_crs_bounds\n True    17\n Name: count, dtype: int64,\n area_is_not_zero\n True    17\n Name: count, dtype: int64]\n\n\nSo the admin areas have their geometry improperly oriented (i.e. layed out in a counter clockwise direction instead of clockwise direction) and this has been fixed, but passes all the other default validations.\n\nvalid_admin3 = valid_admin3.drop(columns=valid_cols)\n\n\n\nValidate Data Geometries\nBefore validating, let’s filter the data to only those intersecting our AOI because we don’t need to check all the data from around the world when we’re only interested in our AOI.\nBefore we validate, we need to create the spatial indexes for both the AOI and data geometries. Generating the spatial indexes of the data geometries can take a minute or two due to the size of the data and their geometries.\n\nvalid_admin3.geometry.sindex\n\nCPU times: user 181 µs, sys: 7 µs, total: 188 µs\nWall time: 190 µs\n\n\n&lt;geopandas.sindex.SpatialIndex&gt;\n\n\n\nfixed.geometry.sindex\n\nCPU times: user 1.31 s, sys: 1.4 s, total: 2.71 s\nWall time: 3.52 s\n\n\n&lt;geopandas.sindex.SpatialIndex&gt;\n\n\nLets now filter the data (filtered_fixed).\nFiltering the data using a spatial join can also take a minute or two.\n\nfiltered_fixed = fixed.sjoin(\n    valid_admin3[[\"geometry\"]], how=\"inner\", predicate=\"intersects\"\n)\n\nCPU times: user 244 ms, sys: 587 ms, total: 830 ms\nWall time: 1.42 s\n\n\n\nfiltered_fixed = filtered_fixed.drop(columns=[\"index_right\"])\n\n\nfixed_gvm = GeometryValidation(filtered_fixed)\n\n\nvalid_fixed = fixed_gvm.validate_all()\n\nCPU times: user 182 ms, sys: 5.59 ms, total: 188 ms\nWall time: 202 ms\n\n\n\n[valid_fixed[col].value_counts() for col in valid_cols]\n\nCPU times: user 595 µs, sys: 97 µs, total: 692 µs\nWall time: 695 µs\n\n\n[is_oriented_properly\n False    2202\n Name: count, dtype: int64,\n is_not_null\n True    2202\n Name: count, dtype: int64,\n is_not_self_intersecting\n True    2202\n Name: count, dtype: int64,\n is_within_crs_bounds\n True    2202\n Name: count, dtype: int64,\n area_is_not_zero\n True    2202\n Name: count, dtype: int64]\n\n\nAgain the data geometries have an improperly oriented geometry and have been fixed by the validator\n\nvalid_fixed = valid_fixed.drop(columns=valid_cols)\nfiltered_fixed = valid_fixed\n\n\n\n\nfiltered fixed ookla data\n\n\n\n\n\nGenerate Zonal Stats\nLets now generate the zonal stats – the statistics of the data we are interested in.\n\nfiltered_fixed.head()\n\n\n\n\n\n\n\n\nquadkey\ntile_x\ntile_y\navg_d_kbps\navg_u_kbps\navg_lat_ms\navg_lat_down_ms\navg_lat_up_ms\ntests\ndevices\ngeometry\n\n\n\n\n5658690\n1323030313311323\n120.9238\n14.7350\n43033\n47711\n9\nNaN\nNaN\n92\n23\nPOLYGON ((120.92102 14.7377, 120.92102 14.7323...\n\n\n5658692\n1323030313311332\n120.9293\n14.7350\n72579\n91717\n11\nNaN\nNaN\n149\n36\nPOLYGON ((120.92651 14.7377, 120.92651 14.7323...\n\n\n5658693\n1323030313311333\n120.9348\n14.7350\n52572\n67337\n3\nNaN\nNaN\n1\n1\nPOLYGON ((120.93201 14.7377, 120.93201 14.7323...\n\n\n5658698\n1323030313313033\n120.9128\n14.7138\n7615\n11991\n14\nNaN\nNaN\n14\n3\nPOLYGON ((120.91003 14.71645, 120.91003 14.711...\n\n\n5658702\n1323030313313110\n120.9293\n14.7297\n63551\n77540\n14\nNaN\nNaN\n600\n69\nPOLYGON ((120.92651 14.73239, 120.92651 14.727...\n\n\n\n\n\n\n\n\nlist(filtered_fixed.columns.values)\n\n['quadkey',\n 'tile_x',\n 'tile_y',\n 'avg_d_kbps',\n 'avg_u_kbps',\n 'avg_lat_ms',\n 'avg_lat_down_ms',\n 'avg_lat_up_ms',\n 'tests',\n 'devices',\n 'geometry']\n\n\n\nlen(filtered_fixed)\n\n2202\n\n\nConvert to planar CRS (since we are computing areas)\n\nvalid_admin3 = valid_admin3.to_crs(\"EPSG:3857\")\n\nCPU times: user 5.53 ms, sys: 2.28 ms, total: 7.81 ms\nWall time: 13 ms\n\n\n\nfiltered_fixed = filtered_fixed.to_crs(\"EPSG:3857\")\n\nCPU times: user 3.5 ms, sys: 1.08 ms, total: 4.58 ms\nWall time: 4.43 ms\n\n\nLets save the files so we can retrieve them as necessary without having to reprocess them again.\n\nvalid_admin3.to_file(\"../data/valid_admin3.geojson\", driver=\"GeoJSON\")\n\nCPU times: user 81.4 ms, sys: 3.95 ms, total: 85.3 ms\nWall time: 87.2 ms\n\n\n\nfiltered_fixed.to_file(\"../data/filtered_fixed.geojson\", driver=\"GeoJSON\")\n\nCPU times: user 45.2 ms, sys: 2.77 ms, total: 47.9 ms\nWall time: 48.9 ms\n\n\n\n# %%time\n# valid_admin3 = gpd.read_file(\"../data/valid_admin3.geojson\")\n\n\n# %%time\n# filtered_fixed = gpd.read_file(\"../data/filtered_fixed.geojson\")\n\nWe want the following statistics - mean (aka average), min (minimum), max (maximum) and the standard deviation (std) for the 3 data columns that ookla provides - average download speed (avg_d_kbps), average upload speed (avg_u_kbps) and average latency in milliseconds (avg_lat_ms)\n\nfuncs = [\"mean\", \"min\", \"max\", \"std\"]\ncolumns = [\"avg_d_kbps\", \"avg_u_kbps\", \"avg_lat_ms\"]\n\n\naggregations = [dict(func=funcs, column=c) for c in columns]\n\nThese are the aggregations to be performed for each data column\n\naggregations\n\n[{'func': ['mean', 'min', 'max', 'std'], 'column': 'avg_d_kbps'},\n {'func': ['mean', 'min', 'max', 'std'], 'column': 'avg_u_kbps'},\n {'func': ['mean', 'min', 'max', 'std'], 'column': 'avg_lat_ms'}]\n\n\nThe output columns use the default {column}_{func} format if not explicitly specified.\n\naoi = azs.create_area_zonal_stats(\n    valid_admin3, filtered_fixed, aggregations=aggregations\n)\n\nCPU times: user 287 ms, sys: 12.5 ms, total: 300 ms\nWall time: 304 ms\n\n\n\n\nAnalyze Zonal Stats\nThese are the results - the same dataframe as the original, with the addition of zonal statistics we specified as the aggregations.\n\naoi.head()\n\n\n\n\n\n\n\n\nADM3_EN\nADM3_PCODE\nADM2_EN\nADM2_PCODE\nADM1_EN\nADM1_PCODE\nADM0_EN\nADM0_PCODE\ndate\nvalidOn\nvalidTo\nADM3_REF\nADM3ALT1EN\nShape_Leng\nShape_Area\nAREA_SQKM\ngeometry\nintersect_area_sum\navg_d_kbps_mean\navg_d_kbps_min\navg_d_kbps_max\navg_d_kbps_std\navg_u_kbps_mean\navg_u_kbps_min\navg_u_kbps_max\navg_u_kbps_std\navg_lat_ms_mean\navg_lat_ms_min\navg_lat_ms_max\navg_lat_ms_std\n\n\n\n\n1275\nCity of Manila\nPH1303901\nMetropolitan Manila First District\nPH13039\nNational Capital Region (NCR)\nPH13\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.600152\n0.003520\n41.960090\nPOLYGON ((13467997.788 1647743.669, 13467990.2...\n5.319784e+07\n480.501342\n0.0\n208079\n19451.400409\n401.935738\n0.0\n252268\n21777.859621\n0.042510\n0.0\n160\n11.038219\n\n\n1276\nCity of Mandaluyong\nPH1307401\nMetropolitan Manila Second District\nPH13074\nNational Capital Region (NCR)\nPH13\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.141520\n0.000949\n11.314034\nPOLYGON ((13476299.72 1642002.083, 13476035.58...\n1.861584e+07\n1556.122992\n0.0\n169221\n19460.297726\n1391.349828\n0.0\n192392\n22225.667081\n0.141840\n0.0\n15\n2.309665\n\n\n1277\nCity of Marikina\nPH1307402\nMetropolitan Manila Second District\nPH13074\nNational Capital Region (NCR)\nPH13\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.257017\n0.001924\n22.931403\nPOLYGON ((13484505.693 1649321.548, 13484512.7...\n2.925728e+07\n890.018039\n0.0\n144549\n15060.305627\n814.873754\n0.0\n132992\n15016.269054\n0.060550\n0.0\n22\n2.928328\n\n\n1278\nCity of Pasig\nPH1307403\nMetropolitan Manila Second District\nPH13074\nNational Capital Region (NCR)\nPH13\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.344848\n0.002626\n31.304225\nPOLYGON ((13480999.467 1645520.671, 13480550.6...\n4.235474e+07\n654.028552\n0.0\n148007\n17091.663647\n589.939054\n0.0\n142586\n19958.543519\n0.052444\n0.0\n25\n3.773210\n\n\n1279\nQuezon City\nPH1307404\nMetropolitan Manila Second District\nPH13074\nNational Capital Region (NCR)\nPH13\nPhilippines (the)\nPH\n2022-11-09\n2023-11-06\n0000/00/00\nNone\nNone\n0.773902\n0.013630\n162.439224\nPOLYGON ((13483643.002 1656701.652, 13483639.5...\n1.744956e+08\n145.327232\n0.0\n269544\n20256.330164\n133.237247\n0.0\n260425\n20148.610313\n0.011825\n0.0\n29\n2.907006\n\n\n\n\n\n\n\nLets save the results\n\naoi.to_file(\"../data/admin3_internet_aoi.geojson\", driver=\"GeoJSON\")\n\nCPU times: user 83.8 ms, sys: 2.89 ms, total: 86.7 ms\nWall time: 101 ms\n\n\n\nlist(aoi.columns.values)\n\n['ADM3_EN',\n 'ADM3_PCODE',\n 'ADM2_EN',\n 'ADM2_PCODE',\n 'ADM1_EN',\n 'ADM1_PCODE',\n 'ADM0_EN',\n 'ADM0_PCODE',\n 'date',\n 'validOn',\n 'validTo',\n 'ADM3_REF',\n 'ADM3ALT1EN',\n 'Shape_Leng',\n 'Shape_Area',\n 'AREA_SQKM',\n 'geometry',\n 'intersect_area_sum',\n 'avg_d_kbps_mean',\n 'avg_d_kbps_min',\n 'avg_d_kbps_max',\n 'avg_d_kbps_std',\n 'avg_u_kbps_mean',\n 'avg_u_kbps_min',\n 'avg_u_kbps_max',\n 'avg_u_kbps_std',\n 'avg_lat_ms_mean',\n 'avg_lat_ms_min',\n 'avg_lat_ms_max',\n 'avg_lat_ms_std']\n\n\nLet’s sort the different admin level 3 areas (cities/municipalities/district) by average download speed (avg_d_kbps_mean) in descending order\n\nfastest_mean_download = aoi.sort_values(\"avg_d_kbps_mean\", ascending=False)\n\nCPU times: user 423 µs, sys: 61 µs, total: 484 µs\nWall time: 452 µs\n\n\n\nlen(fastest_mean_download)\n\n17\n\n\nSo according the latest ookla data (as of this writing) the district/town/province within the NCR Region with the fastest average download speed is Pateros!! :)\n\nfastest_mean_download.iloc[0]\n\nADM3_EN                                                         Pateros\nADM3_PCODE                                                    PH1307606\nADM2_EN                             Metropolitan Manila Fourth District\nADM2_PCODE                                                      PH13076\nADM1_EN                                   National Capital Region (NCR)\nADM1_PCODE                                                         PH13\nADM0_EN                                               Philippines (the)\nADM0_PCODE                                                           PH\ndate                                                2022-11-09 00:00:00\nvalidOn                                             2023-11-06 00:00:00\nvalidTo                                                      0000/00/00\nADM3_REF                                                           None\nADM3ALT1EN                                                         None\nShape_Leng                                                     0.068193\nShape_Area                                                     0.000135\nAREA_SQKM                                                      1.609302\ngeometry              POLYGON ((13478347.724949818 1637036.020144811...\nintersect_area_sum                                        3712583.54692\navg_d_kbps_mean                                             7583.799743\navg_d_kbps_min                                                      0.0\navg_d_kbps_max                                                   111120\navg_d_kbps_std                                             14196.753913\navg_u_kbps_mean                                             7591.256832\navg_u_kbps_min                                                      0.0\navg_u_kbps_max                                                   111569\navg_u_kbps_std                                             16428.535646\navg_lat_ms_mean                                                0.653218\navg_lat_ms_min                                                      0.0\navg_lat_ms_max                                                       22\navg_lat_ms_std                                                 6.301402\nName: 1290, dtype: object\n\n\nWhile the district/city/municipality within the NCR Regions with the slowest average download speed is Quezon City!!!\n\nfastest_mean_download.iloc[-1]\n\nADM3_EN                                                     Quezon City\nADM3_PCODE                                                    PH1307404\nADM2_EN                             Metropolitan Manila Second District\nADM2_PCODE                                                      PH13074\nADM1_EN                                   National Capital Region (NCR)\nADM1_PCODE                                                         PH13\nADM0_EN                                               Philippines (the)\nADM0_PCODE                                                           PH\ndate                                                2022-11-09 00:00:00\nvalidOn                                             2023-11-06 00:00:00\nvalidTo                                                      0000/00/00\nADM3_REF                                                           None\nADM3ALT1EN                                                         None\nShape_Leng                                                     0.773902\nShape_Area                                                      0.01363\nAREA_SQKM                                                    162.439224\ngeometry              POLYGON ((13483643.001879975 1656701.652220414...\nintersect_area_sum                                     174495583.968927\navg_d_kbps_mean                                              145.327232\navg_d_kbps_min                                                      0.0\navg_d_kbps_max                                                   269544\navg_d_kbps_std                                             20256.330164\navg_u_kbps_mean                                              133.237247\navg_u_kbps_min                                                      0.0\navg_u_kbps_max                                                   260425\navg_u_kbps_std                                             20148.610313\navg_lat_ms_mean                                                0.011825\navg_lat_ms_min                                                      0.0\navg_lat_ms_max                                                       29\navg_lat_ms_std                                                 2.907006\nName: 1279, dtype: object\n\n\nThe top 5 fastest areas are\n\nfastest_mean_download[[\"ADM3_EN\", \"ADM2_EN\", \"avg_d_kbps_mean\"]].head()\n\n\n\n\n\n\n\n\nADM3_EN\nADM2_EN\navg_d_kbps_mean\n\n\n\n\n1290\nPateros\nMetropolitan Manila Fourth District\n7583.799743\n\n\n1280\nCity of San Juan\nMetropolitan Manila Second District\n3060.079907\n\n\n1276\nCity of Mandaluyong\nMetropolitan Manila Second District\n1556.122992\n\n\n1283\nCity of Navotas\nMetropolitan Manila Third District\n1065.788943\n\n\n1282\nCity of Malabon\nMetropolitan Manila Third District\n1006.571673\n\n\n\n\n\n\n\nThe top 5 slowest areas are\n\nfastest_mean_download[[\"ADM3_EN\", \"ADM2_EN\", \"avg_d_kbps_mean\"]].tail()\n\n\n\n\n\n\n\n\nADM3_EN\nADM2_EN\navg_d_kbps_mean\n\n\n\n\n1275\nCity of Manila\nMetropolitan Manila First District\n480.501342\n\n\n1288\nCity of Parañaque\nMetropolitan Manila Fourth District\n470.097380\n\n\n1284\nCity of Valenzuela\nMetropolitan Manila Third District\n419.877335\n\n\n1281\nCaloocan City\nMetropolitan Manila Third District\n311.217504\n\n\n1279\nQuezon City\nMetropolitan Manila Second District\n145.327232\n\n\n\n\n\n\n\n\nax = plt.axes()\nax = fastest_mean_download.plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\")\nax = fastest_mean_download.iloc[:1].plot(ax=ax, facecolor=\"red\", edgecolor=\"red\")\nax = fastest_mean_download.iloc[-1:].plot(ax=ax, facecolor=\"green\", edgecolor=\"green\")\n\n\n\n\n\n\n\n\n\n\n\nfastest fixed ookla by adm3\n\n\nSo now, we’ve answered the question of where the fastest/slowest internet speeds are for the National Capital Region (NCR)\n\n\nAdditional Exercises\nYou can further experiment and try out other exercises to explore ookla data, or even try it out using a different country using a different geodataset from the Humanitarian Data Exchange site.\nThe following are more exercises you can try:\n\nRepeat the same process to find the fastest and slowest mobile internet speeds\nRepeat the same process for a different REGION_FILTER\nAggregate by adm2 level instead of adm3",
    "crumbs": [
      "Use Case Demos",
      "Exploring Internet Speeds with Ookla"
    ]
  },
  {
    "objectID": "overview.poverty_mapping_demo.html",
    "href": "overview.poverty_mapping_demo.html",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "",
    "text": "Building poverty mapping machine learning (ML) models with Geowrangler\nThe aim of this notebook is to demonstrate how Geowrangler can be used to make the process of generating ML-ready or analytics-ready datasets from raw geospatial data easier.\nConcretely, this shows a sample workflow for a wealth estimation model trained on a dataset constructed using:",
    "crumbs": [
      "Use Case Demos",
      "Explore Poverty Mapping Machine Learning Models"
    ]
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#set-up",
    "href": "overview.poverty_mapping_demo.html#set-up",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Set-up",
    "text": "Set-up\nInstall and import some libraries.\n\nfrom pathlib import Path\n\nimport folium\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport sklearn\nfrom shapely import wkt\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport geowrangler.area_zonal_stats as azs\nimport geowrangler.distance_zonal_stats as dzs\nimport geowrangler.raster_zonal_stats as rzs\nimport geowrangler.vector_zonal_stats as vzs\nfrom geowrangler import grids\nfrom geowrangler.datasets import geofabrik, ookla",
    "crumbs": [
      "Use Case Demos",
      "Explore Poverty Mapping Machine Learning Models"
    ]
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#pre-requisite-manual-data-download",
    "href": "overview.poverty_mapping_demo.html#pre-requisite-manual-data-download",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Pre-requisite: Manual Data Download",
    "text": "Pre-requisite: Manual Data Download\n\n# download data if not yet available\n![ ! -e ../data/phl_adm0.geojson ] && curl -s -o ../data/phl_adm0.geojson https://raw.githubusercontent.com/thinkingmachines/geowrangler/master/data/phl_adm0.geojson\n![ ! -e ../data/phl_dhs_cluster_level.csv ] && curl -s -o ../data/phl_dhs_cluster_level.csv https://raw.githubusercontent.com/thinkingmachines/geowrangler/master/data/phl_dhs_cluster_level.csv\n![ ! -e ../data/phl_ntl.tif ] && curl -s -o ../data/phl_ntl.tif https://raw.githubusercontent.com/thinkingmachines/geowrangler/master/data/phl_ntl.tif\n\n\nDATA_DIR = Path(\"../data/\")\n# Auto-creates the folder if it does not exist\nDATA_DIR.mkdir(parents=True, exist_ok=True)\n\nYour data directory should look something like this.\n\n\n\ndata_dir.PNG",
    "crumbs": [
      "Use Case Demos",
      "Explore Poverty Mapping Machine Learning Models"
    ]
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#data-preparation",
    "href": "overview.poverty_mapping_demo.html#data-preparation",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nDHS Ground Truth\nThe ground truth used in this demo notebook is from a DHS 2017 on-the-ground household survey conducted in the Philippines regarding the households’ socio-demographic information.\nThe file we provide is already a pre-processed version of the data that is aggregated on a household-cluster level, meaning the information cannot be tied back to any individual household. Specifically, we only provide a list of household clusters with their corresponding (jittered) GPS coordinate and DHS-computed wealth index.\nDue to the sensitive nature of the data and the DHS program terms of use, we cannot provide the raw data. You can, however, request for access to raw data yourself on the DHS website. In that case, you can use GeoWrangler’s DHS processing utils help perform the said pre-processing.\nOur first step is to create a GeoDataFrame from the data.\n\n# Load ground truth data as a DataFrame first\nGROUND_TRUTH_CSV = DATA_DIR / \"phl_dhs_cluster_level.csv\"\ndf = pd.read_csv(GROUND_TRUTH_CSV)\n\n# Some of the coordinates in the data are invalid. This filters them out.\ndf = df[(df.longitude &gt; 0) & (df.latitude &gt; 0)]\n\n# Create a GeoDataFrame from the longitude, latitude columns.\ngdf = gpd.GeoDataFrame(\n    df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=\"epsg:4326\"\n)\n\nprint(f\"There are {len(gdf):,} clusters.\")\ngdf.head()\n\nThere are 1,213 clusters.\n\n\n\n\n\n\n\n\n\nDHSCLUST\nWealth Index\nDHSID\nlongitude\nlatitude\ngeometry\n\n\n\n\n0\n1\n-31881.60870\nPH201700000001\n122.109807\n6.674652\nPOINT (122.10981 6.67465)\n\n\n1\n2\n-2855.37500\nPH201700000002\n122.132027\n6.662256\nPOINT (122.13203 6.66226)\n\n\n2\n3\n-57647.04762\nPH201700000003\n122.179496\n6.621822\nPOINT (122.1795 6.62182)\n\n\n3\n4\n-54952.66667\nPH201700000004\n122.137965\n6.485298\nPOINT (122.13796 6.4853)\n\n\n5\n6\n-80701.69565\nPH201700000006\n121.916094\n6.629457\nPOINT (121.91609 6.62946)\n\n\n\n\n\n\n\nNext, we want to create a buffer around each cluster centroid that represents the area’s neighborhood. This is so we can engineer some features and characterize these neighborhoods using open data.\nThis is a design decision, but for this demo, we’ll create a circlular area with a 2km radius following the random displacement introduced by DHS to preserve household privacy.\n\n# Make sure to convert to PH crs first for the buffer in meters, and then back to WGS84\ngdf = gdf.to_crs(\"epsg:3123\")\ngdf.geometry = gdf.geometry.buffer(2000)\ngdf = gdf.to_crs(\"epsg:4326\")\n\ngdf.head(5)\n\n\n\n\n\n\n\n\nDHSCLUST\nWealth Index\nDHSID\nlongitude\nlatitude\ngeometry\n\n\n\n\n0\n1\n-31881.60870\nPH201700000001\n122.109807\n6.674652\nPOLYGON ((122.12789 6.67461, 122.1278 6.67284,...\n\n\n1\n2\n-2855.37500\nPH201700000002\n122.132027\n6.662256\nPOLYGON ((122.15011 6.66221, 122.15002 6.66044...\n\n\n2\n3\n-57647.04762\nPH201700000003\n122.179496\n6.621822\nPOLYGON ((122.19758 6.62178, 122.19749 6.62001...\n\n\n3\n4\n-54952.66667\nPH201700000004\n122.137965\n6.485298\nPOLYGON ((122.15604 6.48526, 122.15595 6.48349...\n\n\n5\n6\n-80701.69565\nPH201700000006\n121.916094\n6.629457\nPOLYGON ((121.93418 6.62942, 121.93409 6.62765...\n\n\n\n\n\n\n\nWe can visualize what we’ve done so far on a map. \n\n# Uncomment the next line to display an interactive map\n# gdf.explore()\n\n\n\nDownload data and load them into memory\nNext, we’ll download some data from Ookla (internet speeds) and OSM (points of interest), which we’ll use to generate neighborhood characteristics to be used as ML features.\n\n\nOokla\nOokla has released global open data gathered from speedtests made on their platform. This gives us access to internet speed information across various geographies. In our context, this can give us a signal predictor.\nFirst, let’s download a local copy of data on fixed internet in the 1st quarter of 2019 (earliest data available).\nWe can use GeoWrangler’s Ookla data utility to automatically download and cache the desired data on your machine given the type, year, and quarter.\nThis is just a simplification for the demo. In practice, you might want to aggregate data across multiple time periods or incorporate wireless data.\n\nookla_fixed_2019_q1_filepath = ookla.download_ookla_file(\n    type_=\"fixed\", year=\"2019\", quarter=\"1\"\n)\n# This is where the downloaded file is located.\n# By default this downloads to your data/ folder, but you can customize this.\nookla_fixed_2019_q1_filepath\n\n2024-08-12 22:32:01.747 | INFO     | geowrangler.datasets.utils:urlretrieve:25 - Retrieving https://ookla-open-data.s3.us-west-2.amazonaws.com/parquet/performance/type=fixed/year=2019/quarter=1/2019-01-01_performance_fixed_tiles.parquet into data/2019-01-01_performance_fixed_tiles.parquet\n\n\n\n\n\n\n\n    \n      \n      100.00% [227835904/227829253 00:16&lt;00:00]\n    \n    \n\n\nPath('data/2019-01-01_performance_fixed_tiles.parquet')\n\n\n\n# This is a function to load and do some light pre-processing on the Ookla data.\n\n\ndef load_ookla_data(filename, mask=None):\n\n    # Ookla's parquet file doesn't seem to have geo metadata so need to read through pandas first\n    ookla_df = pd.read_parquet(filename)\n    ookla_gdf = gpd.GeoDataFrame(\n        ookla_df,\n        geometry=ookla_df[\"tile\"].apply(lambda x: wkt.loads(x)),\n        crs=\"epsg:4326\",\n    )\n    ookla_gdf = ookla_gdf.drop(columns=[\"tile\"])\n\n    # Ookla's data files contain data for the whole world.\n    # For our case, we're retaining only tiles that intersect with the given mask.\n    # This is to speed-up any processing we do later on.\n    if mask is not None:\n        keep_cols = ookla_gdf.columns\n        ookla_gdf = ookla_gdf.sjoin(mask, how=\"inner\", predicate=\"intersects\")\n        ookla_gdf = ookla_gdf[keep_cols]\n        ookla_gdf.head()\n\n    # Convert kbps to mbps for easier reading\n    ookla_gdf[\"avg_d_mbps\"] = ookla_gdf[\"avg_d_kbps\"] / 1000\n    ookla_gdf[\"avg_u_mbps\"] = ookla_gdf[\"avg_u_kbps\"] / 1000\n\n    return ookla_gdf\n\nThe Ookla data is quite large, and takes around 5 minutes to load.\n\nookla_gdf = load_ookla_data(ookla_fixed_2019_q1_filepath, mask=gdf)\n\nCPU times: user 22.3 s, sys: 3.6 s, total: 25.9 s\nWall time: 28.3 s\n\n\n\nprint(\n    f\"{len(ookla_gdf):,} Ookla data tiles retained that intersect with our DHS cluster neighborhoods.\"\n)\nookla_gdf.head()\n\n17,245 Ookla data tiles retained that intersect with our DHS cluster neighborhoods.\n\n\n\n\n\n\n\n\n\nquadkey\navg_d_kbps\navg_u_kbps\navg_lat_ms\ntests\ndevices\ngeometry\navg_d_mbps\navg_u_mbps\n\n\n\n\n4368240\n1323011210311031\n10\n21\n126\n1\n1\nPOLYGON ((121.96472 20.4579, 121.97021 20.4579...\n0.010\n0.021\n\n\n4368240\n1323011210311031\n10\n21\n126\n1\n1\nPOLYGON ((121.96472 20.4579, 121.97021 20.4579...\n0.010\n0.021\n\n\n4368240\n1323011210311031\n10\n21\n126\n1\n1\nPOLYGON ((121.96472 20.4579, 121.97021 20.4579...\n0.010\n0.021\n\n\n4368240\n1323011210311031\n10\n21\n126\n1\n1\nPOLYGON ((121.96472 20.4579, 121.97021 20.4579...\n0.010\n0.021\n\n\n4368241\n1323011210311033\n5931\n10633\n228\n3\n2\nPOLYGON ((121.96472 20.45275, 121.97021 20.452...\n5.931\n10.633\n\n\n\n\n\n\n\n\n\nOSM (Open Street Maps)\nOne source of open data on points of interest is OSM. We’ll use the version of the data provided by Geofabrik vs accessing the OSM Overpass API. This allows us to not be bottlenecked by API calls.\nSimilar to Ookla, we can also use GeoWrangler’s OSM data download utils to download and cache OSM data on your machine. All you have to do is specify the country you want.\nGeofabrik’s OSM data is a zip file containing different files for POIs, waterways, roads, etc. For this demo notebook, we’ll only use the POIs.\n\n# This download can take around 1-2 minutes.\nph_osm_zip_path = geofabrik.download_geofabrik_region(\"philippines\")\n\n# This line unzips the zip file if we haven't done so yet.\n!echo 'None' | unzip $ph_osm_zip_path -d data/ph_osm/\n\n2024-08-12 22:32:49.191 | INFO     | geowrangler.datasets.utils:urlretrieve:25 - Retrieving https://download.geofabrik.de/asia/philippines-latest-free.shp.zip into data/philippines-latest-free.shp.zip\n\n\n\n\n\n\n\n    \n      \n      100.00% [1287127040/1287122270 06:08&lt;00:00]\n    \n    \n\n\nArchive:  data/philippines-latest-free.shp.zip\n  inflating: data/ph_osm/README      \n extracting: data/ph_osm/gis_osm_buildings_a_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_buildings_a_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_buildings_a_free_1.prj  \n  inflating: data/ph_osm/gis_osm_buildings_a_free_1.shp  \n  inflating: data/ph_osm/gis_osm_buildings_a_free_1.shx  \n extracting: data/ph_osm/gis_osm_landuse_a_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_landuse_a_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_landuse_a_free_1.prj  \n  inflating: data/ph_osm/gis_osm_landuse_a_free_1.shp  \n  inflating: data/ph_osm/gis_osm_landuse_a_free_1.shx  \n extracting: data/ph_osm/gis_osm_natural_a_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_natural_a_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_natural_a_free_1.prj  \n  inflating: data/ph_osm/gis_osm_natural_a_free_1.shp  \n  inflating: data/ph_osm/gis_osm_natural_a_free_1.shx  \n extracting: data/ph_osm/gis_osm_natural_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_natural_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_natural_free_1.prj  \n  inflating: data/ph_osm/gis_osm_natural_free_1.shp  \n  inflating: data/ph_osm/gis_osm_natural_free_1.shx  \n extracting: data/ph_osm/gis_osm_places_a_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_places_a_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_places_a_free_1.prj  \n  inflating: data/ph_osm/gis_osm_places_a_free_1.shp  \n  inflating: data/ph_osm/gis_osm_places_a_free_1.shx  \n extracting: data/ph_osm/gis_osm_places_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_places_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_places_free_1.prj  \n  inflating: data/ph_osm/gis_osm_places_free_1.shp  \n  inflating: data/ph_osm/gis_osm_places_free_1.shx  \n extracting: data/ph_osm/gis_osm_pofw_a_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_pofw_a_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_pofw_a_free_1.prj  \n  inflating: data/ph_osm/gis_osm_pofw_a_free_1.shp  \n  inflating: data/ph_osm/gis_osm_pofw_a_free_1.shx  \n extracting: data/ph_osm/gis_osm_pofw_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_pofw_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_pofw_free_1.prj  \n  inflating: data/ph_osm/gis_osm_pofw_free_1.shp  \n  inflating: data/ph_osm/gis_osm_pofw_free_1.shx  \n extracting: data/ph_osm/gis_osm_pois_a_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_pois_a_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_pois_a_free_1.prj  \n  inflating: data/ph_osm/gis_osm_pois_a_free_1.shp  \n  inflating: data/ph_osm/gis_osm_pois_a_free_1.shx  \n extracting: data/ph_osm/gis_osm_pois_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_pois_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_pois_free_1.prj  \n  inflating: data/ph_osm/gis_osm_pois_free_1.shp  \n  inflating: data/ph_osm/gis_osm_pois_free_1.shx  \n extracting: data/ph_osm/gis_osm_railways_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_railways_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_railways_free_1.prj  \n  inflating: data/ph_osm/gis_osm_railways_free_1.shp  \n  inflating: data/ph_osm/gis_osm_railways_free_1.shx  \n extracting: data/ph_osm/gis_osm_roads_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_roads_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_roads_free_1.prj  \n  inflating: data/ph_osm/gis_osm_roads_free_1.shp  \n  inflating: data/ph_osm/gis_osm_roads_free_1.shx  \n extracting: data/ph_osm/gis_osm_traffic_a_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_traffic_a_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_traffic_a_free_1.prj  \n  inflating: data/ph_osm/gis_osm_traffic_a_free_1.shp  \n  inflating: data/ph_osm/gis_osm_traffic_a_free_1.shx  \n extracting: data/ph_osm/gis_osm_traffic_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_traffic_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_traffic_free_1.prj  \n  inflating: data/ph_osm/gis_osm_traffic_free_1.shp  \n  inflating: data/ph_osm/gis_osm_traffic_free_1.shx  \n extracting: data/ph_osm/gis_osm_transport_a_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_transport_a_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_transport_a_free_1.prj  \n  inflating: data/ph_osm/gis_osm_transport_a_free_1.shp  \n  inflating: data/ph_osm/gis_osm_transport_a_free_1.shx  \n extracting: data/ph_osm/gis_osm_transport_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_transport_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_transport_free_1.prj  \n  inflating: data/ph_osm/gis_osm_transport_free_1.shp  \n  inflating: data/ph_osm/gis_osm_transport_free_1.shx  \n extracting: data/ph_osm/gis_osm_water_a_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_water_a_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_water_a_free_1.prj  \n  inflating: data/ph_osm/gis_osm_water_a_free_1.shp  \n  inflating: data/ph_osm/gis_osm_water_a_free_1.shx  \n extracting: data/ph_osm/gis_osm_waterways_free_1.cpg  \n  inflating: data/ph_osm/gis_osm_waterways_free_1.dbf  \n  inflating: data/ph_osm/gis_osm_waterways_free_1.prj  \n  inflating: data/ph_osm/gis_osm_waterways_free_1.shp  \n  inflating: data/ph_osm/gis_osm_waterways_free_1.shx  \n\n\n\n# Uncomment the ff line to see all the available OSM files aside from POIs.\n# !ls data/ph_osm\n\n\nph_osm_pois_filepath = \"data/ph_osm/gis_osm_pois_free_1.shp\"\nph_osm = gpd.read_file(ph_osm_pois_filepath)\n\n\nprint(f\"There are {len(ph_osm)} OSM POIs.\")\nph_osm.head()\n\nThere are 150311 OSM POIs.\n\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\ngeometry\n\n\n\n\n0\n21717820\n2907\ncamera_surveillance\nNone\nPOINT (121.0212 14.57608)\n\n\n1\n21717872\n2722\nmuseum\nAyala Museum\nPOINT (121.02324 14.55358)\n\n\n2\n24078959\n2907\ncamera_surveillance\nNone\nPOINT (121.05945 14.60098)\n\n\n3\n24797511\n2542\nbicycle_shop\nChristine Sports Cycle Marketing\nPOINT (120.99506 14.55224)\n\n\n4\n24797535\n2518\nbeverages\nG and K wine\nPOINT (120.99267 14.55285)",
    "crumbs": [
      "Use Case Demos",
      "Explore Poverty Mapping Machine Learning Models"
    ]
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#feature-engineering",
    "href": "overview.poverty_mapping_demo.html#feature-engineering",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Feature Engineering",
    "text": "Feature Engineering\nNow that we’ve prepared the DHS data and loaded Ookla and OSM data into memory, we’re ready to generate some neighborhood features for our ML model.\nFor convenience, we’re wrapping all the feature engineering code in functions so we can re-use them later when we apply the model to the whole country.\nNote: if you are modifying the feature engineering portions, it is recommended to run the whole section end-to-end. This ensures you’re starting fresh from a new copy of the DHS clusters GeoDataFrame. This also ensures the function definitions are up-to-date, and can be re-used properly later for model rollout.\n\n# We'll make a copy of the GDF to avoid overwriting the original DHS GeoDataFrame.\ngdf_with_features = gdf.copy()\n\n\nOSM\nOur goal with OSM data is to generate neighborhood characteristics based on counts and distance to certain POIs, such as schools, hospitals, etc.\nTo do this, we utilize GeoWrangler’s vector zonal stats and distance zonal stats features.\n\n# Uncomment the ff. line if you want to see the different POI classes available\n# ph_osm.fclass.sort_values().unique()\n\n\ndef generate_osm_features(aoi, osm, metric_crs=\"epsg:3123\"):\n\n    aoi = aoi.copy()\n\n    # GeoWrangler: Count number of all POIs per tile\n    aoi = vzs.create_zonal_stats(\n        aoi,\n        osm,\n        overlap_method=\"intersects\",\n        aggregations=[{\"func\": \"count\", \"output\": \"poi_count\", \"fillna\": True}],\n    )\n\n    # Count specific aoi types\n    poi_types = [\"restaurant\", \"school\", \"bank\", \"supermarket\", \"mall\", \"atm\"]\n\n    for poi_type in poi_types:\n        # GeoWrangler: Count with vector zonal stats\n        aoi = vzs.create_zonal_stats(\n            aoi,\n            osm[osm[\"fclass\"] == poi_type],\n            overlap_method=\"intersects\",\n            aggregations=[\n                {\"func\": \"count\", \"output\": f\"{poi_type}_count\", \"fillna\": True}\n            ],\n        )\n\n        # GeoWrangler: Distance with distance zonal stats\n        col_name = f\"{poi_type}_nearest\"\n        aoi = dzs.create_distance_zonal_stats(\n            aoi.to_crs(metric_crs),\n            osm[osm[\"fclass\"] == poi_type].to_crs(metric_crs),\n            max_distance=10_000,\n            aggregations=[],\n            distance_col=col_name,\n        ).to_crs(\"epsg:4326\")\n\n        # If no POI was found within the distance limit, set the distance to a really high value\n        aoi[col_name] = aoi[col_name].fillna(value=999999)\n\n    return aoi\n\n\ngdf_with_features = generate_osm_features(gdf_with_features, ph_osm)\n\nCPU times: user 746 ms, sys: 29.4 ms, total: 775 ms\nWall time: 793 ms\n\n\n\ngdf_with_features.head()\n\n\n\n\n\n\n\n\nDHSCLUST\nWealth Index\nDHSID\nlongitude\nlatitude\ngeometry\npoi_count\nrestaurant_count\nrestaurant_nearest\nschool_count\nschool_nearest\nbank_count\nbank_nearest\nsupermarket_count\nsupermarket_nearest\nmall_count\nmall_nearest\natm_count\natm_nearest\n\n\n\n\n0\n1\n-31881.60870\nPH201700000001\n122.109807\n6.674652\nPOLYGON ((122.12789 6.67461, 122.1278 6.67284,...\n0.0\n0.0\n3152.996430\n0.0\n1392.503631\n0.0\n1764.736950\n0.0\n999999.0\n0.0\n999999.0\n0.0\n999999.000000\n\n\n1\n2\n-2855.37500\nPH201700000002\n122.132027\n6.662256\nPOLYGON ((122.15011 6.66221, 122.15002 6.66044...\n6.0\n0.0\n5788.165918\n0.0\n3601.132502\n1.0\n0.000000\n0.0\n999999.0\n0.0\n999999.0\n0.0\n999999.000000\n\n\n2\n3\n-57647.04762\nPH201700000003\n122.179496\n6.621822\nPOLYGON ((122.19758 6.62178, 122.19749 6.62001...\n0.0\n0.0\n999999.000000\n0.0\n642.871037\n0.0\n4026.300327\n0.0\n999999.0\n0.0\n999999.0\n0.0\n999999.000000\n\n\n3\n4\n-54952.66667\nPH201700000004\n122.137965\n6.485298\nPOLYGON ((122.15604 6.48526, 122.15595 6.48349...\n0.0\n0.0\n999999.000000\n0.0\n2287.839903\n0.0\n999999.000000\n0.0\n999999.0\n0.0\n999999.0\n0.0\n999999.000000\n\n\n5\n6\n-80701.69565\nPH201700000006\n121.916094\n6.629457\nPOLYGON ((121.93418 6.62942, 121.93409 6.62765...\n0.0\n0.0\n8408.925995\n0.0\n3930.606257\n0.0\n8332.324084\n0.0\n999999.0\n0.0\n999999.0\n0.0\n8311.332736\n\n\n\n\n\n\n\n\n\nOokla\nOur goal with Ookla data is to generate neighborhood characteristics based on internet speeds (download, upload, latency).\nTo do this, we utilize GeoWrangler’s area zonal stats feature.\n\ndef generate_ookla_features(aoi, ookla_gdf, metric_crs=\"epsg:3123\"):\n\n    aoi = aoi.copy()\n\n    orig_aoi_crs = aoi.crs\n    aoi = aoi.to_crs(metric_crs)\n    ookla_gdf = ookla_gdf.to_crs(metric_crs)\n\n    # For better formatting, rename some columns\n    ookla_gdf = ookla_gdf.rename(\n        columns={\"avg_d_mbps\": \"d_mbps\", \"avg_u_mbps\": \"u_mbps\", \"avg_lat_ms\": \"lat_ms\"}\n    )\n\n    # GeoWrangler: Compute stats on the various columns\n    aoi = azs.create_area_zonal_stats(\n        aoi,\n        ookla_gdf,\n        aggregations=[\n            # Count number of devices in the area\n            dict(column=\"devices\", func=[\"raw_sum\"], fillna=True),\n            # Get stats on the download speeds\n            dict(\n                column=\"d_mbps\",\n                func=[\"imputed_mean\", \"max\", \"min\", \"std\"],\n                fillna=[True, True, True, True],\n            ),\n            # Get stats on the upload speeds\n            dict(\n                column=\"u_mbps\",\n                func=[\"imputed_mean\", \"max\", \"min\", \"std\"],\n                fillna=[True, True, True, True],\n            ),\n        ],\n        # Don't include the land area that intersected as a column\n        include_intersect=False,\n        # Don't set minimum values to 0 if the neighborhood's area doesn't fully intersect with Ookla tiles.\n        fix_min=False,\n    )\n\n    aoi = aoi.fillna(value=\"0\")\n    aoi = aoi.to_crs(orig_aoi_crs)\n\n    return aoi\n\n\ngdf_with_features = generate_ookla_features(gdf_with_features, ookla_gdf)\n\nCPU times: user 1.01 s, sys: 27.6 ms, total: 1.04 s\nWall time: 1.05 s\n\n\n\ngdf_with_features.head()\n\n\n\n\n\n\n\n\nDHSCLUST\nWealth Index\nDHSID\nlongitude\nlatitude\ngeometry\npoi_count\nrestaurant_count\nrestaurant_nearest\nschool_count\n...\natm_nearest\ndevices_sum\nd_mbps_mean\nd_mbps_max\nd_mbps_min\nd_mbps_std\nu_mbps_mean\nu_mbps_max\nu_mbps_min\nu_mbps_std\n\n\n\n\n0\n1\n-31881.60870\nPH201700000001\n122.109807\n6.674652\nPOLYGON ((122.12789 6.67461, 122.1278 6.67284,...\n0.0\n0.0\n3152.996430\n0.0\n...\n999999.000000\n0.0\n0.000000\n0.000\n0.000\n0.000000\n0.000000\n0.000\n0.000\n0.000000\n\n\n1\n2\n-2855.37500\nPH201700000002\n122.132027\n6.662256\nPOLYGON ((122.15011 6.66221, 122.15002 6.66044...\n6.0\n0.0\n5788.165918\n0.0\n...\n999999.000000\n38.0\n0.401851\n14.628\n2.177\n4.982053\n0.255031\n6.867\n1.866\n1.753667\n\n\n2\n3\n-57647.04762\nPH201700000003\n122.179496\n6.621822\nPOLYGON ((122.19758 6.62178, 122.19749 6.62001...\n0.0\n0.0\n999999.000000\n0.0\n...\n999999.000000\n0.0\n0.000000\n0.000\n0.000\n0.000000\n0.000000\n0.000\n0.000\n0.000000\n\n\n3\n4\n-54952.66667\nPH201700000004\n122.137965\n6.485298\nPOLYGON ((122.15604 6.48526, 122.15595 6.48349...\n0.0\n0.0\n999999.000000\n0.0\n...\n999999.000000\n0.0\n0.000000\n0.000\n0.000\n0.000000\n0.000000\n0.000\n0.000\n0.000000\n\n\n5\n6\n-80701.69565\nPH201700000006\n121.916094\n6.629457\nPOLYGON ((121.93418 6.62942, 121.93409 6.62765...\n0.0\n0.0\n8408.925995\n0.0\n...\n8311.332736\n0.0\n0.000000\n0.000\n0.000\n0.000000\n0.000000\n0.000\n0.000\n0.000000\n\n\n\n\n5 rows × 28 columns\n\n\n\n\n\nNight Time Lights\nLastly, we’ll generate features based on night time lights. GeoWrangler provides a raster zonal stats function that acts as a thin layer on top of rasterio’s rasterstats function. It provides a little convenience in terms of formatting and automatically joins back the features to your input GeoDataFrame.\n\ndef generate_ntl_features(aoi, raster_path):\n    aoi = aoi.copy()\n\n    aoi = rzs.create_raster_zonal_stats(\n        aoi,\n        raster_path,\n        aggregation=dict(\n            func=[\"mean\", \"min\", \"max\", \"std\"],\n            column=\"ntl\",\n        ),\n        extra_args=dict(nodata=0),\n    )\n\n    aoi = aoi.fillna(0)\n\n    return aoi\n\n\ngdf_with_features = generate_ntl_features(gdf_with_features, DATA_DIR / \"phl_ntl.tif\")\n\nCPU times: user 1.24 s, sys: 198 ms, total: 1.44 s\nWall time: 1.57 s\n\n\n\n\nVisualize the final dataset\nFinally, let’s visualize our cluster neighborhoods now with the generated features. Hover over each cluster to see its data.\n\n\n\nDHS Cluster Features (Zoomed)\n\n\n\n# Visualize the clusters with the generated features\n# gdf_with_features.explore()",
    "crumbs": [
      "Use Case Demos",
      "Explore Poverty Mapping Machine Learning Models"
    ]
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#prepare-data-into-x-y-and-generate-traintest-partitions",
    "href": "overview.poverty_mapping_demo.html#prepare-data-into-x-y-and-generate-traintest-partitions",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Prepare data into X, y and generate train/test partitions",
    "text": "Prepare data into X, y and generate train/test partitions\n\n# For convenience, store the list of features in a variable. Remove all extraneous columns.\nfeature_cols = gdf_with_features.drop(\n    columns=[\"DHSCLUST\", \"DHSID\", \"Wealth Index\", \"longitude\", \"latitude\", \"geometry\"]\n).columns\n\n# Separate data (X) and the target (y)\nX = gdf_with_features[feature_cols]\ny = gdf_with_features[\"Wealth Index\"]\n\n# Bin y into 5 buckets for stratification when splitting the dataset\ncat_y = pd.cut(y, bins=5, labels=list(range(1, 6)))\n\n# Generate train and test partitions\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n    X, y, test_size=0.2, random_state=2022, stratify=cat_y\n)\n\n\nX_train.head()\n\n\n\n\n\n\n\n\npoi_count\nrestaurant_count\nrestaurant_nearest\nschool_count\nschool_nearest\nbank_count\nbank_nearest\nsupermarket_count\nsupermarket_nearest\nmall_count\n...\nd_mbps_min\nd_mbps_std\nu_mbps_mean\nu_mbps_max\nu_mbps_min\nu_mbps_std\nntl_mean\nntl_min\nntl_max\nntl_std\n\n\n\n\n944\n1.0\n0.0\n4332.445808\n1.0\n0.000000\n0.0\n999999.000000\n0.0\n5595.357740\n0.0\n...\n0.000\n0.000000\n0.000000\n0.000\n0.000\n0.000000\n0.279636\n0.279636\n0.279636\n0.000000\n\n\n328\n1203.0\n143.0\n0.000000\n23.0\n0.000000\n73.0\n0.000000\n14.0\n0.000000\n1.0\n...\n8.948\n6.519399\n0.033496\n30.564\n2.496\n5.933372\n9.881545\n4.587300\n17.190298\n2.768707\n\n\n696\n0.0\n0.0\n4396.530482\n0.0\n7331.181601\n0.0\n999999.000000\n0.0\n999999.000000\n0.0\n...\n0.000\n0.000000\n0.000000\n0.000\n0.000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n155\n2.0\n0.0\n352.510311\n0.0\n669.141767\n0.0\n2606.478381\n0.0\n2566.227871\n0.0\n...\n1.215\n31.305303\n0.863634\n151.303\n0.106\n35.998549\n0.299591\n0.182455\n0.519110\n0.125637\n\n\n614\n286.0\n12.0\n0.000000\n4.0\n0.000000\n14.0\n0.000000\n8.0\n0.000000\n1.0\n...\n2.986\n6.722738\n0.174738\n32.774\n0.527\n7.027801\n0.335981\n0.216280\n0.543996\n0.084581\n\n\n\n\n5 rows × 26 columns\n\n\n\n\ny_train.head()\n\n944    -27114.20833\n328    175912.44440\n696    -29987.93750\n155     75826.10526\n614     54849.37500\nName: Wealth Index, dtype: float64",
    "crumbs": [
      "Use Case Demos",
      "Explore Poverty Mapping Machine Learning Models"
    ]
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#evaluation-function",
    "href": "overview.poverty_mapping_demo.html#evaluation-function",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Evaluation Function",
    "text": "Evaluation Function\nWe define an evaluation function that computes R^2 and makes a plot of the actual vs predicted values.\n\ndef evaluate(model, X_train, X_test, y_train, y_test):\n\n    # R^2\n    train_predictions = model.predict(X_train)\n    print(\"Train R2 score:\", sklearn.metrics.r2_score(y_train, train_predictions))\n\n    test_predictions = model.predict(X_test)\n    print(\"Test R2 score:\", sklearn.metrics.r2_score(y_test, test_predictions))\n\n    # Plot\n\n    # Train and test predictions vs actual values\n    plt.scatter(train_predictions, y_train, label=\"Train samples\", c=\"#d95f02\")\n    plt.scatter(test_predictions, y_test, label=\"Test samples\", c=\"#7570b3\")\n\n    # Identity line\n    xpoints = ypoints = plt.xlim()\n    plt.plot(\n        xpoints, ypoints, linestyle=\"--\", color=\"k\", lw=3, scalex=False, scaley=False\n    )\n\n    # Labels and legends\n    plt.xlabel(\"Predicted value\")\n    plt.ylabel(\"True value\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()",
    "crumbs": [
      "Use Case Demos",
      "Explore Poverty Mapping Machine Learning Models"
    ]
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#fit-and-evaluate-model",
    "href": "overview.poverty_mapping_demo.html#fit-and-evaluate-model",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Fit and Evaluate Model",
    "text": "Fit and Evaluate Model\nFor ML modelling, let’s fit a simple random forest regressor.\nAs mentioned, we are keeping the ML modelling as simple as possible in this notebook. This is definitely not the best-performing wealth estimation model out there, but should be decent enough for demo purposes.\n\nmodel = RandomForestRegressor()\nmodel.fit(X_train, y_train)\nevaluate(model, X_train, X_test, y_train, y_test)\n\nTrain R2 score: 0.9244278211179482\nTest R2 score: 0.5882081532536176",
    "crumbs": [
      "Use Case Demos",
      "Explore Poverty Mapping Machine Learning Models"
    ]
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#generate-country-wide-tiles",
    "href": "overview.poverty_mapping_demo.html#generate-country-wide-tiles",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Generate country-wide tiles",
    "text": "Generate country-wide tiles\nFirst, we need to split the country up into smaller areas.\nThat usually means generating grid tiles or hex tiles for your area of interest. In this notebook, we’ll generate Bing tiles at zoom level 13 (which has the closest area to our 2km neighborhoods in training).\nGeoWrangler provides various grid generation utilities for these different scenarios.\n\n# Read in the admin boundary for PHL.\n# This file is a simplified version of the admin boundary to make the file size smaller and load times faster.\nphl_adm = gpd.read_file(f\"{DATA_DIR}/phl_adm0.geojson\")\n\n# Uncomment this line if you want to visualize it\n# phl_adm.explore()\n\nThe generation can take around 1-2 minutes.\n\nphl_tiles = grids.BingTileGridGenerator(13).generate_grid(phl_adm)\nprint(f\"There are {len(phl_tiles):,} tiles.\")\nphl_tiles.head()\n\nThere are 16,257 tiles.\nCPU times: user 7.34 s, sys: 57.5 ms, total: 7.39 s\nWall time: 7.5 s\n\n\n\n\n\n\n\n\n\nquadkey\ngeometry\n\n\n\n\n0\n1323230031202\nPOLYGON ((119.17969 4.65308, 119.17969 4.69688...\n\n\n1\n1323230030300\nPOLYGON ((119.00391 4.69688, 119.00391 4.74068...\n\n\n2\n1323230030311\nPOLYGON ((119.13574 4.69688, 119.13574 4.74068...\n\n\n3\n1323230031201\nPOLYGON ((119.22363 4.69688, 119.22363 4.74068...\n\n\n4\n1323212220302\nPOLYGON ((118.30078 6.05316, 118.30078 6.09686...",
    "crumbs": [
      "Use Case Demos",
      "Explore Poverty Mapping Machine Learning Models"
    ]
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#feature-engineering-1",
    "href": "overview.poverty_mapping_demo.html#feature-engineering-1",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Feature Engineering",
    "text": "Feature Engineering\nThis part is simpler, as we’re just re-using the feature engineering functions we previously created. Note though that we are generating features for a bigger area, so the runtime is a little longer (in total should be within 2 minutes).\n\nphl_tiles_with_features = phl_tiles.copy()\n\n\nphl_tiles_with_features = generate_osm_features(phl_tiles_with_features, ph_osm)\n\nCPU times: user 1.17 s, sys: 39.2 ms, total: 1.21 s\nWall time: 1.24 s\n\n\n\nphl_tiles_with_features = generate_ookla_features(phl_tiles_with_features, ookla_gdf)\n\nCPU times: user 465 ms, sys: 16.3 ms, total: 481 ms\nWall time: 485 ms\n\n\n\nphl_tiles_with_features = generate_ntl_features(\n    phl_tiles_with_features, f\"{DATA_DIR}/phl_ntl.tif\"\n)\n\nCPU times: user 13.4 s, sys: 1.8 s, total: 15.2 s\nWall time: 15.4 s",
    "crumbs": [
      "Use Case Demos",
      "Explore Poverty Mapping Machine Learning Models"
    ]
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#make-predictions-and-viz-output",
    "href": "overview.poverty_mapping_demo.html#make-predictions-and-viz-output",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Make predictions and viz output",
    "text": "Make predictions and viz output\nFinally, we are ready to apply the model and make predictions throughout the whole country. We can also visualize it on a Cholorpleth map.\n\nphl_tiles_with_features[\"predicted_wealth_index\"] = model.predict(\n    phl_tiles_with_features[feature_cols]\n)\n\n\ndef viz_chloropleth(gdf, target_feature=\"predicted_wealth_index\"):\n\n    m = folium.Map(location=[14.6091, 121.0223], width=1000, height=800, zoom_start=7)\n    subset = gdf.copy()\n    subset[\"id\"] = list(range(len(subset)))\n\n    folium.Choropleth(\n        geo_data=subset,\n        data=subset,\n        name=\"Wealth Predictions\",\n        columns=[\"id\", target_feature],\n        key_on=\"feature.properties.id\",\n        fill_color=\"Spectral\",\n        legend_name=target_feature,\n    ).add_to(m)\n\n    return m\n\nVisualize the output\n\n\n\nPredicted Wealth Index Rollout (Philippines)\n\n\n\n# Uncomment the line below to visualize rollout\n# viz_chloropleth(phl_tiles_with_features)",
    "crumbs": [
      "Use Case Demos",
      "Explore Poverty Mapping Machine Learning Models"
    ]
  },
  {
    "objectID": "raster_zonal_stats.html",
    "href": "raster_zonal_stats.html",
    "title": "Raster Zonal Stats",
    "section": "",
    "text": "Note: This module is a thin layer on top of the rasterstats and exactextract packages to make its interface more compatible with the other geowrangler modules (e.g. vector zonal stats)\nsource",
    "crumbs": [
      "Module Reference",
      "Raster Zonal Stats"
    ]
  },
  {
    "objectID": "raster_zonal_stats.html#exactextract-zonal-stats",
    "href": "raster_zonal_stats.html#exactextract-zonal-stats",
    "title": "Raster Zonal Stats",
    "section": "Exactextract Zonal Stats",
    "text": "Exactextract Zonal Stats\nThe next section provides an alternative implementation of raster zonal statistics using the exactextract package. This package promises more exact zonal statistics by taking into account pixel fractions vs rasterstats that assigns the pixels to a polygon based on their centroid locations.\n\nexactextract provides a fast and accurate algorithm for summarizing values in the portion of a raster dataset that is covered by a polygon, often referred to as zonal statistics. Unlike other zonal statistics implementations, it takes into account raster cells that are partially covered by the polygon.\n\n\nAdvantages\n\nResults from exactextract are more precise than rasterstats due to handling pixel fractions in its calculations\nexactextract is faster to run than rasterstats for the same input AOI and raster data\n\n\n\nDisadvantages\n\nnodata value handling is not yet supported by the create_exactextract_zonal_stats() method. To handle NODATA, it is recommended to create a raster file with a properly-set NODATA value, i.e.\n\nimport rasterio as rio\n\nexisting_raster = 'path/to/existing_raster.tif'\nnew_raster = 'path/to/new_raster.tif'\nuser_defined_nodata = -9999\n\nwith rio.open(existing_raster) as src:\n    profile = src.profile\n    profile.update(nodata=user_defined_nodata)\n    data = src.read()\n    \n    # Write the new raster with the updated profile with nodata\n    with rio.open(output_raster_path, 'w', **profile) as dst:\n        dst.write(data)\n/opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: potentially wrong underline length... \nExample usage \n-------- in \nComputes zonal statistics from raster data sources using vector areas of interest (AOI).\n...\n  else: warn(msg)\n\nsource\n\n\ncreate_exactextract_zonal_stats\n\n create_exactextract_zonal_stats\n                                  (aoi:Union[str,pathlib.Path,geopandas.ge\n                                  odataframe.GeoDataFrame],\n                                  data:Union[str,pathlib.Path], aggregatio\n                                  n:Union[Dict,List[Dict[str,Any]]],\n                                  include_cols:List[str]=None,\n                                  include_geom:bool=True,\n                                  extra_args:dict={'strategy': 'feature-\n                                  sequential', 'max_cells_in_memory':\n                                  30000000})\n\n*Computes zonal statistics from raster data sources using vector areas of interest (AOI).\nThis function is a wrapper over the exact_extract method from the exactextract Python package, designed for compatibility with other geowrangler modules. It takes a list of agg specs, with each agg spec applied to a specific band. See https://github.com/isciences/exactextract/blob/master/python/README.md for more details.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\naoi\nUnion\n\nA GeoDataframe specifying geometries.\n\n\ndata\nUnion\n\nThe path to the raster data file\n\n\naggregation\nUnion\n\nDictionary or list of dictionaries specifying the aggregation\n\n\ninclude_cols\nList\nNone\nIf not None, list of columns from input AOI to include in output\n\n\ninclude_geom\nbool\nTrue\nIf false, drop geometry column. include_cols takes priority.\n\n\nextra_args\ndict\n{‘strategy’: ‘feature-sequential’, ‘max_cells_in_memory’: 30000000}\nExtra arguments to pass to exactextract.exact_extract(). “include_cols”, “include_geom”, and “output” arguments are ignored.\n\n\nReturns\nGeoDataFrame\n\nExtra arguments to pass to `exactextract.exact_extract(). Ignores output, include_geom, and include_cols.\n\n\n\n\n\nUsage Examples of create_exactextract_zonal_stats()\n\n# Single band with single aggregation\nresults = create_exactextract_zonal_stats(\n    simple_aoi.to_crs(\"EPSG:3857\"),\n    terrain_file,\n    aggregation=dict(band=1, func=[\"sum\", \"max\", \"min\", \"stdev\"], output=\"elevation\")\n)\nresults\n\nCPU times: user 10.2 ms, sys: 2.27 ms, total: 12.4 ms\nWall time: 13.7 ms\n\n\n\n\n\n\n\n\n\ncol1\nlat0\nlon0\nlat1\nlon1\nlat2\nlon2\nlat3\nlon3\ngeometry\nelevation_sum\nelevation_max\nelevation_min\nelevation_stdev\n\n\n\n\n0\n1\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n417459.46875\n1444.722213\n1232.164947\n63.263985\n\n\n1\n2\n1.0\n0.0\n1.0\n1.0\n2.0\n1.0\n2.0\n0.0\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n409081.15625\n1425.920852\n1213.356474\n50.523487\n\n\n2\n3\n2.0\n0.0\n2.0\n1.0\n3.0\n1.0\n3.0\n0.0\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n411552.87500\n1402.859628\n1220.031795\n44.781490\n\n\n\n\n\n\n\n\n# Single band with multiple aggregations\nresults = create_exactextract_zonal_stats(\n    simple_aoi.to_crs(\"EPSG:3857\"),\n    terrain_file,\n    aggregation=[\n        dict(band=1, func=[\"max\", \"min\"], output=[\"highest_elevation\", \"lowest_elevation\"]),\n        dict(band=1, func=[\"mean\"], output=\"elevation\") # output will be elevation_mean\n    ],    \n)\nresults\n\nCPU times: user 9.15 ms, sys: 1.12 ms, total: 10.3 ms\nWall time: 9.59 ms\n\n\n\n\n\n\n\n\n\ncol1\nlat0\nlon0\nlat1\nlon1\nlat2\nlon2\nlat3\nlon3\ngeometry\nhighest_elevation\nlowest_elevation\nelevation_mean\n\n\n\n\n0\n1\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n1444.722213\n1232.164947\n1335.873047\n\n\n1\n2\n1.0\n0.0\n1.0\n1.0\n2.0\n1.0\n2.0\n0.0\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n1425.920852\n1213.356474\n1309.062378\n\n\n2\n3\n2.0\n0.0\n2.0\n1.0\n3.0\n1.0\n3.0\n0.0\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n1402.859628\n1220.031795\n1316.971924\n\n\n\n\n\n\n\n\n# Multiple band \ngrid_exactextract_aoi_results = create_exactextract_zonal_stats(\n    phl_adm,\n    \"../data/ph_s5p_AER_AI_340_380.tiff\",\n    aggregation=[\n        dict(band=1, func=[\"mean\", \"sum\"], nodata_val=-9999), # default - band1_mean, band1_sum\n        dict(band=2, func=[\"mean\", \"sum\"]), # default - band2_mean, band2_sum\n        dict(band=2, func=[\"mean\", \"sum\"], output=\"prefix\"), # prefix_mean, prefix_sum\n        dict(band=1, func=[\"mean\", \"sum\", \"count\"], output=[\"aer_ai_mean\", \"aer_ai_sum\", \"aer_ai_count\"]),\n    ]\n)\ndisplay(grid_exactextract_aoi_results)\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\nband_1_mean\nband_1_sum\nband_2_mean\nband_2_sum\nprefix_mean\nprefix_sum\naer_ai_mean\naer_ai_sum\naer_ai_count\n\n\n\n\n0\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n0.000279\n0.12919\n0.015252\n7.070237\n0.015252\n7.070237\n0.000279\n0.12919\n463.568115\n\n\n\n\n\n\n\nCPU times: user 423 ms, sys: 34.9 ms, total: 458 ms\nWall time: 468 ms\n\n\n\n# Multiple band test -&gt; include_cols\ngrid_exactextract_aoi_results = create_exactextract_zonal_stats(\n    phl_adm,\n    \"../data/ph_s5p_AER_AI_340_380.tiff\",\n    aggregation=[\n        dict(band=1, func=[\"mean\", \"sum\"], nodata_val=-9999), # default - band1_mean, band1_sum\n        dict(band=2, func=[\"mean\", \"sum\"]), # default - band2_mean, band2_sum\n        dict(band=2, func=[\"mean\", \"sum\"], output=\"prefix\"), # prefix_mean, prefix_sum\n        dict(band=1, func=[\"mean\", \"sum\", \"count\"], output=[\"aer_ai_mean\", \"aer_ai_sum\", \"aer_ai_count\"]),\n    ],\n    include_cols=[\"Reg_Code\"],\n)\ndisplay(grid_exactextract_aoi_results)\n\n\n\n\n\n\n\n\nReg_Code\nband_1_mean\nband_1_sum\nband_2_mean\nband_2_sum\nprefix_mean\nprefix_sum\naer_ai_mean\naer_ai_sum\naer_ai_count\n\n\n\n\n0\n030000000\n0.000279\n0.12919\n0.015252\n7.070237\n0.015252\n7.070237\n0.000279\n0.12919\n463.568115\n\n\n\n\n\n\n\nCPU times: user 353 ms, sys: 27.5 ms, total: 381 ms\nWall time: 383 ms\n\n\n\n# Using include_geom\ngrid_exactextract_aoi_results = create_exactextract_zonal_stats(\n    phl_adm,\n    \"../data/ph_s5p_AER_AI_340_380.tiff\",\n    aggregation=[\n        dict(band=1, func=[\"mean\", \"sum\"], nodata_val=-9999), # default - band1_mean, band1_sum\n        dict(band=2, func=[\"mean\", \"sum\"]), # default - band2_mean, band2_sum\n        dict(band=2, func=[\"mean\", \"sum\"], output=\"prefix\"), # prefix_mean, prefix_sum\n        dict(band=1, func=[\"mean\", \"sum\", \"count\"], output=[\"aer_ai_mean\", \"aer_ai_sum\", \"aer_ai_count\"]),\n    ],\n    include_geom=False\n)\ndisplay(grid_exactextract_aoi_results)\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\nband_1_mean\nband_1_sum\nband_2_mean\nband_2_sum\nprefix_mean\nprefix_sum\naer_ai_mean\naer_ai_sum\naer_ai_count\n\n\n\n\n0\n030000000\nRegion III\nCentral Luzon\n0.000279\n0.12919\n0.015252\n7.070237\n0.015252\n7.070237\n0.000279\n0.12919\n463.568115\n\n\n\n\n\n\n\nCPU times: user 364 ms, sys: 30.1 ms, total: 394 ms\nWall time: 418 ms\n\n\n\n# Using include_geom\ngrid_exactextract_aoi_results = create_exactextract_zonal_stats(\n    phl_adm,\n    \"../data/ph_s5p_AER_AI_340_380.tiff\",\n    aggregation=[\n        dict(band=1, func=[\"mean\", \"sum\"], nodata_val=-9999), # default - band1_mean, band1_sum\n        dict(band=2, func=[\"mean\", \"sum\"]), # default - band2_mean, band2_sum\n        dict(band=2, func=[\"mean\", \"sum\"], output=\"prefix\"), # prefix_mean, prefix_sum\n        dict(band=1, func=[\"mean\", \"sum\", \"count\"], output=[\"aer_ai_mean\", \"aer_ai_sum\", \"aer_ai_count\"]),\n    ],\n    include_cols=[\"Reg_Code\"]\n)\ndisplay(grid_exactextract_aoi_results, type(grid_exactextract_aoi_results))\n\n\n\n\n\n\n\n\nReg_Code\nband_1_mean\nband_1_sum\nband_2_mean\nband_2_sum\nprefix_mean\nprefix_sum\naer_ai_mean\naer_ai_sum\naer_ai_count\n\n\n\n\n0\n030000000\n0.000279\n0.12919\n0.015252\n7.070237\n0.015252\n7.070237\n0.000279\n0.12919\n463.568115\n\n\n\n\n\n\n\npandas.core.frame.DataFrame\n\n\nCPU times: user 357 ms, sys: 28.6 ms, total: 385 ms\nWall time: 390 ms\n\n\n\n# Using include_geom and include_cols\n# As geometry is not in include_cols, it is prioritzed over include_geom=True\ngrid_exactextract_aoi_results = create_exactextract_zonal_stats(\n    phl_adm,\n    \"../data/ph_s5p_AER_AI_340_380.tiff\",\n    aggregation=[\n        dict(band=1, func=[\"mean\", \"sum\"], nodata_val=-9999), # default - band1_mean, band1_sum\n        dict(band=2, func=[\"mean\", \"sum\"]), # default - band2_mean, band2_sum\n        dict(band=2, func=[\"mean\", \"sum\"], output=\"prefix\"), # prefix_mean, prefix_sum\n        dict(band=1, func=[\"mean\", \"sum\", \"count\"], output=[\"aer_ai_mean\", \"aer_ai_sum\", \"aer_ai_count\"]),\n    ],\n    include_cols=[\"Reg_Code\"],\n    include_geom=True\n)\ndisplay(grid_exactextract_aoi_results, type(grid_exactextract_aoi_results))\n\n\n\n\n\n\n\n\nReg_Code\nband_1_mean\nband_1_sum\nband_2_mean\nband_2_sum\nprefix_mean\nprefix_sum\naer_ai_mean\naer_ai_sum\naer_ai_count\n\n\n\n\n0\n030000000\n0.000279\n0.12919\n0.015252\n7.070237\n0.015252\n7.070237\n0.000279\n0.12919\n463.568115\n\n\n\n\n\n\n\npandas.core.frame.DataFrame\n\n\nCPU times: user 357 ms, sys: 30.6 ms, total: 388 ms\nWall time: 391 ms\n\n\n\n# Multiple band test - from file\ngrid_exactextract_aoi_results = create_exactextract_zonal_stats(\n    \"../data/region3_admin.geojson\",\n    \"../data/ph_s5p_AER_AI_340_380.tiff\",\n    aggregation=[\n        dict(band=1, func=[\"mean\", \"sum\"], nodata_val=-9999), # default - band1_mean, band1_sum\n        dict(band=2, func=[\"mean\", \"sum\"]), # default - band2_mean, band2_sum\n        dict(band=2, func=[\"mean\", \"sum\"], output=\"prefix\"), # prefix_mean, prefix_sum\n        dict(band=1, func=[\"mean\", \"sum\", \"count\"], output=[\"aer_ai_mean\", \"aer_ai_sum\", \"aer_ai_count\"]),\n    ],\n)\ndisplay(grid_exactextract_aoi_results)\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\nband_1_mean\nband_1_sum\nband_2_mean\nband_2_sum\nprefix_mean\nprefix_sum\naer_ai_mean\naer_ai_sum\naer_ai_count\n\n\n\n\n0\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n0.000279\n0.12919\n0.015252\n7.070237\n0.015252\n7.070237\n0.000279\n0.12919\n463.568115\n\n\n\n\n\n\n\nCPU times: user 651 ms, sys: 46.8 ms, total: 697 ms\nWall time: 703 ms\n\n\n\n\n\n\n\n\nWarning\n\n\n\ncreate_exactextract_zonal_stats() will always return a geopandas.GeoDataFrame. A warning is returned if output (e.g. gdal, geojson) is specified in extra_args.\n\n# Multiple band test - gdal -&gt; UNSUPPORTED\ngrid_exactextract_aoi_results = create_exactextract_zonal_stats(\n    phl_adm,\n    \"../data/ph_s5p_AER_AI_340_380.tiff\",\n    aggregation=[\n        dict(band=1, func=[\"mean\", \"sum\"], nodata_val=-9999), # default - band1_mean, band1_sum\n        dict(band=2, func=[\"mean\", \"sum\"]), # default - band2_mean, band2_sum\n        dict(band=2, func=[\"mean\", \"sum\"], output=\"prefix\"), # prefix_mean, prefix_sum\n        dict(band=1, func=[\"mean\", \"sum\", \"count\"], output=[\"aer_ai_mean\", \"aer_ai_sum\", \"aer_ai_count\"]),\n    ],\n    extra_args = dict(output=\"gdal\")\n)\ndisplay(grid_exactextract_aoi_results)\n\n/var/folders/f4/9fptcl253fldfv71r9tdfyzc0000gn/T/ipykernel_35790/1525768804.py:74: UserWarning: output in `extra_args` is ignored. Output is set to 'pandas'. Refer to `exactextract.exact_extract()` to use other output options.\n  warnings.warn(\"output in `extra_args` is ignored. Output is set to 'pandas'. Refer to `exactextract.exact_extract()` to use other output options.\")\n\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\nband_1_mean\nband_1_sum\nband_2_mean\nband_2_sum\nprefix_mean\nprefix_sum\naer_ai_mean\naer_ai_sum\naer_ai_count\n\n\n\n\n0\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n0.000279\n0.12919\n0.015252\n7.070237\n0.015252\n7.070237\n0.000279\n0.12919\n463.568115\n\n\n\n\n\n\n\nCPU times: user 430 ms, sys: 40.3 ms, total: 470 ms\nWall time: 482 ms",
    "crumbs": [
      "Module Reference",
      "Raster Zonal Stats"
    ]
  },
  {
    "objectID": "tutorial.distance_zonal_stats.html",
    "href": "tutorial.distance_zonal_stats.html",
    "title": "Vector Distance Zonal Stats Tutorial",
    "section": "",
    "text": "A basic introduction to vector distance zonal stats",
    "crumbs": [
      "Tutorials",
      "Vector Distance Zonal Stats Tutorial"
    ]
  },
  {
    "objectID": "tutorial.distance_zonal_stats.html#basic-usage",
    "href": "tutorial.distance_zonal_stats.html#basic-usage",
    "title": "Vector Distance Zonal Stats Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nGenerate area zonal stats for a GeoDataframe containing areas of interest with a vector data source with the nearest distance.\n\n\n\n\n\n\nNote\n\n\n\nThe data geometries can be points, lines or areas with distance computed from the closest points on both the aoi and the data source. Both the aoi and the data source must be projected using a “planar” CRS.\n\n\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import Point\n\nimport geowrangler.distance_zonal_stats as dzs\n\n\nSimple Grid AOIs and Nearby POI/Area Data Example\n\nsimple_aoi = gpd.read_file(\"../data/simple_planar_aoi.geojson\")\nsimple_data = gpd.read_file(\"../data/simple_planar_data.geojson\")\n\n\nsimple_point_data = make_point_df(3, 5, offset_x=0.5, offset_y=3.0)\n\nGiven an aoi (simple_aoi), a sample area data source (simple_data), and a sample point data source\n\nsimple_aoi\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n\n\n\n\n\n\n\n\nsimple_data\n\n\n\n\n\n\n\n\npopulation\ninternet_speed\ngeometry\n\n\n\n\n0\n100\n20.0\nPOLYGON ((0.25 0, 0.25 1, 1.25 1, 1.25 0, 0.25...\n\n\n1\n200\n10.0\nPOLYGON ((1.25 0, 1.25 1, 2.25 1, 2.25 0, 1.25...\n\n\n2\n300\n5.0\nPOLYGON ((2.25 0, 2.25 1, 3.25 1, 3.25 0, 2.25...\n\n\n\n\n\n\n\n\nsimple_point_data\n\n\n\n\n\n\n\n\ngeometry\npopulation\ninternet_speed\n\n\n\n\n0\nPOINT (0.5 3)\n100\n20.0\n\n\n1\nPOINT (0.5 4)\n600\n120.0\n\n\n2\nPOINT (0.5 5)\n1100\n220.0\n\n\n3\nPOINT (0.5 6)\n1600\n320.0\n\n\n4\nPOINT (0.5 7)\n2100\n420.0\n\n\n5\nPOINT (1.5 3)\n200\n10.0\n\n\n6\nPOINT (1.5 4)\n700\n110.0\n\n\n7\nPOINT (1.5 5)\n1200\n210.0\n\n\n8\nPOINT (1.5 6)\n1700\n310.0\n\n\n9\nPOINT (1.5 7)\n2200\n410.0\n\n\n10\nPOINT (2.5 3)\n300\n5.0\n\n\n11\nPOINT (2.5 4)\n800\n105.0\n\n\n12\nPOINT (2.5 5)\n1300\n205.0\n\n\n13\nPOINT (2.5 6)\n1800\n305.0\n\n\n14\nPOINT (2.5 7)\n2300\n405.0\n\n\n\n\n\n\n\nIn order correctly compute distances from the aoi to the data sources, we need to make sure that the aoi, data and point data geodataframes are using a planar CRS (i.e. gdf.crs.is_geographic == False)\n\nsimple_aoi.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nsimple_data.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nsimple_point_data.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\nWe have an aoi (simple_aoi) and geodataframe containing sample data (simple_data) that overlaps the aoi. We also have simple point data which do not intersect with our AOIs.\n\nax = plt.axes()\nax = simple_data.plot(\n    ax=ax, color=[\"orange\", \"brown\", \"purple\"], edgecolor=\"yellow\", alpha=0.4\n)\nax = simple_aoi.plot(ax=ax, facecolor=\"none\", edgecolor=[\"r\", \"g\", \"b\"])\nax = simple_point_data.plot(ax=ax)\n\n\n\n\n\n\n\n\nThe red,green,blue outlines are the 3 regions of interest (aoi) while the orange,brown, purple areas are the data areas.The blue dots are data which do not intersect our AOIs.\n\nresults = dzs.create_distance_zonal_stats(\n    simple_aoi,\n    simple_point_data,\n    max_distance=7,\n    aggregations=[\n        dict(func=\"count\"),\n        dict(func=\"sum\", column=\"population\"),\n        dict(func=\"mean\", column=\"internet_speed\"),\n    ],\n)\n\nCPU times: user 6.01 ms, sys: 1.4 ms, total: 7.41 ms\nWall time: 9.12 ms\n\n\nThe zonal stats computed for the point data only includes those points nearest to each aoi. The data geometries within nearest distance (within 7.0 m) are the only ones considered.\n\n\n\n\n\n\nNote\n\n\n\nSetting the max_distance to None or a large value can cause a possible slowdown for large datasets. See this Geopandas reference for more details.\n\n\n\nresults\n\n\n\n\n\n\n\n\ngeometry\nindex_count\npopulation_sum\ninternet_speed_mean\nnearest\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n1\n100\n20.0\n2.0\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n1\n200\n10.0\n2.0\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n1\n300\n5.0\n2.0\n\n\n\n\n\n\n\nData areas and geometries which overlap the aoi areas have a distance of 0.0 and are always the nearest geometries.\n\nresults2 = dzs.create_distance_zonal_stats(\n    simple_aoi,\n    simple_data,\n    max_distance=1,\n    aggregations=[\n        dict(func=\"count\"),\n        dict(func=\"sum\", column=\"population\"),\n        dict(func=\"mean\", column=\"internet_speed\"),\n    ],\n)\n\nCPU times: user 5.63 ms, sys: 576 µs, total: 6.2 ms\nWall time: 5.9 ms\n\n\n\nresults2\n\n\n\n\n\n\n\n\ngeometry\nindex_count\npopulation_sum\ninternet_speed_mean\nnearest\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n1\n100\n20.0\n0.0\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n2\n300\n15.0\n0.0\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n2\n500\n7.5\n0.0\n\n\n\n\n\n\n\n\n\nCustom Grids and POIs Example\n\nregion3_admin_grids = gpd.read_file(\"../data/region3_admin_grids.geojson\")\n\nCPU times: user 15.2 ms, sys: 626 µs, total: 15.8 ms\nWall time: 16.4 ms\n\n\n\nregion34ncr_osm_pois = gpd.read_file(\"../data/region34ncr_osm_pois.geojson\")\n\nCPU times: user 29.4 ms, sys: 1.06 ms, total: 30.4 ms\nWall time: 30.8 ms\n\n\n\nax = plt.axes()\nax = region34ncr_osm_pois.plot(ax=ax)\nax = region3_admin_grids.plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\")\n\n\n\n\n\n\n\n\n\nregion3_admin_grids = region3_admin_grids.to_crs(\"EPSG:3857\")  # convert to planar\nregion34ncr_osm_pois = region34ncr_osm_pois.to_crs(\"EPSG:3857\")\n\n\nregion34ncr_osm_pois\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nBARANGAY_CODE\ngeometry\n\n\n\n\n0\n311568428\n2701\ntourist_info\nManila American Cemetery and Memorial Visitor ...\n137602022\nPOINT (13475059.129 1636701.151)\n\n\n1\n672565496\n2701\ntourist_info\necopark paging and first aid station\n137404141\nPOINT (13477983.748 1656000.058)\n\n\n2\n672565498\n2701\ntourist_info\nEcopark ticket counter\n137404141\nPOINT (13477813.318 1656135.868)\n\n\n3\n1585389544\n2701\ntourist_info\nArea Formerly Occupied by Fort Bonifacio Museum\n137602021\nPOINT (13476156.594 1637474.593)\n\n\n4\n1834855424\n2701\ntourist_info\nLotto Booth\n137601020\nPOINT (13468786.053 1622805.175)\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n2829\n1282790636\n2723\nmonument\nRizal Monument\n030808004\nPOINT (13387876.843 1652143.344)\n\n\n2830\n1430752967\n2723\nmonument\nRizal Monument\n034903092\nPOINT (13464327.852 1743609.163)\n\n\n2831\n2280492117\n2723\nmonument\nRizal Monument\n031421037\nPOINT (13467118.142 1705384.453)\n\n\n2832\n4898774223\n2723\nmonument\nRizal Monument\n035414009\nPOINT (13434387.128 1685457.796)\n\n\n2833\n3087522557\n2724\nmemorial\nRizal Monument\n031410015\nPOINT (13448861.946 1672777.772)\n\n\n\n\n2834 rows × 6 columns\n\n\n\n\nresults3 = dzs.create_distance_zonal_stats(\n    region3_admin_grids,\n    region34ncr_osm_pois,\n    max_distance=10_000,  # within 10km\n    aggregations=[dict(func=\"count\", output=\"pois_count\", fillna=[True])],\n)\n\nCPU times: user 16.5 ms, sys: 1.13 ms, total: 17.7 ms\nWall time: 17.7 ms\n\n\n\nlen(results3[results3.pois_count == 0.0])\n\n165\n\n\n\nresults3\n\n\n\n\n\n\n\n\nx\ny\ngeometry\npois_count\nnearest\n\n\n\n\n0\n0\n30\nPOLYGON ((13334497.956 1771012.807, 13339497.9...\n1.0\n8849.591855\n\n\n1\n0\n31\nPOLYGON ((13334497.956 1776012.807, 13339497.9...\n1.0\n8844.448848\n\n\n2\n0\n32\nPOLYGON ((13334497.956 1781012.807, 13339497.9...\n0.0\nNaN\n\n\n3\n1\n30\nPOLYGON ((13339497.956 1771012.807, 13344497.9...\n1.0\n3856.266007\n\n\n4\n1\n32\nPOLYGON ((13339497.956 1781012.807, 13344497.9...\n1.0\n6070.762498\n\n\n...\n...\n...\n...\n...\n...\n\n\n1069\n54\n44\nPOLYGON ((13604497.956 1841012.807, 13609497.9...\n1.0\n674.134053\n\n\n1070\n54\n45\nPOLYGON ((13604497.956 1846012.807, 13609497.9...\n2.0\n0.000000\n\n\n1071\n54\n46\nPOLYGON ((13604497.956 1851012.807, 13609497.9...\n1.0\n4237.158313\n\n\n1072\n54\n47\nPOLYGON ((13604497.956 1856012.807, 13609497.9...\n1.0\n9237.158313\n\n\n1073\n54\n48\nPOLYGON ((13604497.956 1861012.807, 13609497.9...\n0.0\nNaN\n\n\n\n\n1074 rows × 5 columns",
    "crumbs": [
      "Tutorials",
      "Vector Distance Zonal Stats Tutorial"
    ]
  },
  {
    "objectID": "dhs.html",
    "href": "dhs.html",
    "title": "DHS Utilities",
    "section": "",
    "text": "source\n\nload_column_config\n\n load_column_config (country:str)\n\nGet predined column mapping for some countries. The following countries area supported: - ph Philippines - tl East Timor - mm Myanmar - kh Cambodia\n\n\n\n\nType\nDetails\n\n\n\n\ncountry\nstr\n2 letter character representing the country\n\n\nReturns\ndict\n\n\n\n\n\nsource\n\n\nload_dhs_file\n\n load_dhs_file (household_data:str)\n\nLoads household data and renames columns based on variable labels of the file\n\n\n\n\nType\nDetails\n\n\n\n\nhousehold_data\nstr\nstr or pathlike object to the household data\n\n\nReturns\nDataFrame\n\n\n\n\n\nsource\n\n\napply_threshold\n\n apply_threshold (df:pandas.core.frame.DataFrame, columns:List[str],\n                  config:dict)\n\nApplies a threshold to a list of columns\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nDataframe\n\n\ncolumns\nList\nList of columns to apply the threshold\n\n\nconfig\ndict\nConfig containing the min and max of each columns\n\n\nReturns\nDataFrame\n\n\n\n\n\nsource\n\n\nassign_wealth_index\n\n assign_wealth_index (asset_df:pandas.core.frame.DataFrame, use_pca=True)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nasset_df\nDataFrame\n\nDataframe containg only the features to apply wealth index\n\n\nuse_pca\nbool\nTrue\nif calculating wealth index should be done via PCA or via Sigular Value Decomposition",
    "crumbs": [
      "Module Reference",
      "DHS Utilities"
    ]
  },
  {
    "objectID": "tutorial.raster_to_df.html",
    "href": "tutorial.raster_to_df.html",
    "title": "Raster to Dataframe Tutorial",
    "section": "",
    "text": "A basic introduction to generating a vector-to-raster mask and converting rasters to Dataframes.",
    "crumbs": [
      "Tutorials",
      "Raster to Dataframe Tutorial"
    ]
  },
  {
    "objectID": "tutorial.raster_to_df.html#basic-usage",
    "href": "tutorial.raster_to_df.html#basic-usage",
    "title": "Raster to Dataframe Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nGenerate a raster mask from a reference TIF image based on the labels assigned to certain regions of the area. The generated raster mask can also be used to convert the raster to a dataframe with respect to their assigned labels.\nTerms: * raster mask - processed image wherein some parts of it are set to no value or in other words hidden * labels - parts of an area within the satellite image are categorized as such. Examples are mining, agriculture, etc.\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport geowrangler.raster_to_dataframe as rdf\n\n\nfrom rasterio import features\nfrom rasterio.plot import show\nfrom rasterio.windows import Window, transform\n\n\nLoad reference raster image and shape file\nThe shape file that should be loaded should contain a column that consists of labels.\n\ntiff_file = \"../data/vector_to_raster_mask_sample/cabanglasan.tif\"\nshape_file = \"../data/vector_to_raster_mask_sample/labels_20220816.gpkg\"\ntarget_file = shape_file.replace(\"gpkg\", \"tiff\")\n\nWe create a dictionary of our target labels that we want to create a raster mask for.\n\nlabels = {\n    \"mining\": 1,\n    \"neg\": 2,\n    \"agriculture\": 3,\n    \"product_extraction\": 4,\n    \"kaingin\": 5,\n    \"biophysical\": 6,\n}\n\n\n\nGenerate raster mask\nTo create the mask we input the reference raster image, shape file with labels, and the dictionary with our target labels into the function.\n\n# Generate masks for a file\nmasks, grids, values = rdf.generate_mask(\n    tiff_file=tiff_file,\n    shape_file=shape_file,\n    output_file=target_file,\n    labels_column=\"label\",\n    labels_dict=labels,\n    plot=True,\n)\n\n\n\n\n\n\n\n\n\n\nLoad rasters and the outputed raster mask\n\ntiff_files = [\n    \"../data/vector_to_raster_mask_sample/cabanglasan.tif\",\n]\nmask_file = \"../data/vector_to_raster_mask_sample/labels_20220816.tiff\"\n\n\n\nConvert raster to dataframe\nTo convert raster/s to a dataframe, we just need to input the images into the function and add the mask file. The mask file will be used to create the last column label in the dataframe. The result is a tabular dataset that contains the Band values per raster image and their labels.\n\ndata = rdf.read_bands(tiff_files, mask_file)\n\n\ndata\n\n\n\n\n\n\n\n\nB1_0\nB2_0\nB3_0\nB4_0\nB5_0\nB6_0\nB7_0\nB8_0\nB9_0\nB10_0\nB11_0\nB12_0\nlabel\n\n\n\n\n0\n0.1198\n0.09635\n0.09330\n0.0698\n0.10665\n0.20250\n0.2490\n0.23525\n0.28125\n0.0377\n0.19925\n0.1002\n0\n\n\n1\n0.1198\n0.09580\n0.09245\n0.0708\n0.10665\n0.20250\n0.2490\n0.23925\n0.28125\n0.0377\n0.19925\n0.1002\n0\n\n\n2\n0.1148\n0.09420\n0.09460\n0.0707\n0.10380\n0.20395\n0.2478\n0.23150\n0.27165\n0.0385\n0.18240\n0.0902\n0\n\n\n3\n0.1148\n0.09190\n0.08850\n0.0631\n0.10380\n0.20395\n0.2478\n0.23300\n0.27165\n0.0385\n0.18240\n0.0902\n0\n\n\n4\n0.1148\n0.09350\n0.09080\n0.0643\n0.10565\n0.20830\n0.2466\n0.24205\n0.26990\n0.0385\n0.18050\n0.0894\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n775824\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n775825\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n775826\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n775827\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n775828\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n\n\n775829 rows × 13 columns\n\n\n\nChecking the label column we can see that the TIF image that we converted does not contain the desired labels.\n\ndata[\"label\"].unique()\n\narray([0], dtype=uint16)",
    "crumbs": [
      "Tutorials",
      "Raster to Dataframe Tutorial"
    ]
  },
  {
    "objectID": "vector_to_raster_mask.html",
    "href": "vector_to_raster_mask.html",
    "title": "Vector to Raster mask",
    "section": "",
    "text": "from rasterio import features\nfrom rasterio.plot import show\nfrom rasterio.windows import Window, transform\nsource",
    "crumbs": [
      "Module Reference",
      "Vector to Raster mask"
    ]
  },
  {
    "objectID": "vector_to_raster_mask.html#test-data",
    "href": "vector_to_raster_mask.html#test-data",
    "title": "Vector to Raster mask",
    "section": "Test data",
    "text": "Test data\n\nGenerating a raster mask\n\n# Get filepaths\ntiff_file = \"../data/vector_to_raster_mask_sample/cabanglasan.tif\"\nshape_file = \"../data/vector_to_raster_mask_sample/labels_20220816.gpkg\"\ntarget_file = shape_file.replace(\"gpkg\", \"tiff\")\n\nGiven a raster image of a certain area that will be masked to use as a reference and a shape file that contains that area. Note that the shape file must include a column that contains labels/categories.\n\ngpd.read_file(shape_file).head(3)\n\n\n\n\n\n\n\n\nyear\nlabel\nuid\nADM3_EN\nADM3_PCODE\nADM2_EN\nADM2_PCODE\nADM1_EN\nADM1_PCODE\ngeometry\n\n\n\n\n0\n2017.0\nmining\n72_2017_mining\nSofronio Española\nPH175324000\nPalawan\nPH175300000\nRegion IV-B\nPH170000000\nMULTIPOLYGON Z (((117.95961 9.03303 0, 117.959...\n\n\n1\n2017.0\nmining\n71_2017_mining\nSofronio Española\nPH175324000\nPalawan\nPH175300000\nRegion IV-B\nPH170000000\nMULTIPOLYGON Z (((117.95507 9.03809 0, 117.955...\n\n\n2\n2017.0\nmining\n70_2017_mining\nSofronio Española\nPH175324000\nPalawan\nPH175300000\nRegion IV-B\nPH170000000\nMULTIPOLYGON Z (((117.95663 9.03869 0, 117.956...\n\n\n\n\n\n\n\nAnd a dictionary with the labels and assigned values to be used in creating a mask\n\nlabels = {\n    \"mining\": 1,\n    \"neg\": 2,\n    \"agriculture\": 3,\n    \"product_extraction\": 4,\n    \"kaingin\": 5,\n    \"biophysical\": 6,\n}\n\nInput them in the generate_mask function to create a raster mask of the same dimension as the reference raster image\n\n# Generate masks for a file\nmasks, grids, values = generate_mask(\n    tiff_file=tiff_file,\n    shape_file=shape_file,\n    output_file=target_file,\n    labels_column=\"label\",\n    labels_dict=labels,\n    plot=True,\n)\n\n\n\n\n\n\n\n\n\nmasks\n\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint16)\n\n\n\ngrids\n\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint16)\n\n\n\nvalues\n\n{'mining': 1,\n 'neg': 2,\n 'agriculture': 3,\n 'product_extraction': 4,\n 'kaingin': 5,\n 'biophysical': 6}",
    "crumbs": [
      "Module Reference",
      "Vector to Raster mask"
    ]
  },
  {
    "objectID": "tutorial.dhs.html",
    "href": "tutorial.dhs.html",
    "title": "DHS Wealth Index",
    "section": "",
    "text": "Basic introduction to processing DHS data",
    "crumbs": [
      "Tutorials",
      "DHS Wealth Index"
    ]
  },
  {
    "objectID": "tutorial.dhs.html#loading-dhs-data",
    "href": "tutorial.dhs.html#loading-dhs-data",
    "title": "DHS Wealth Index",
    "section": "Loading DHS Data",
    "text": "Loading DHS Data\nNote: This data is mocked data. Request official data from their available datasets through their website.\n\nimport geopandas as gpd\nimport pandas as pd\n\nfrom geowrangler import dhs\n\n\ndhs_household_data_path = \"../data/ph.DTA\"\ndhs_gps_coordinates = \"../data/ph_gps.shp\"\n\n\ndhs_df = dhs.load_dhs_file(dhs_household_data_path)\n\nCPU times: user 11.2 ms, sys: 583 µs, total: 11.8 ms\nWall time: 10.6 ms\n\n\n\ndhs_df.head()\n\n\n\n\n\n\n\n\n\ncountry code and phase\ncluster number\nsource of drinking water\ntype of toilet facility\nhas electricity\nhas radio\nhas television\nhas refrigerator\nhas motorcycle/scooter\nhas car/truck\nmain floor material\nnumber of rooms used for sleeping\nhas mobile telephone\nwealth index factor score combined (5 decimals)\n\n\n\n\n0\n0\nPH7\n725\n80\n61\n0\n1\n0\n1\n1\n1\n74\n20\n0\n-168581\n\n\n1\n1\nPH7\n1009\n19\n92\n1\n1\n1\n1\n1\n0\n51\n15\n1\n127550\n\n\n2\n2\nPH7\n1072\n91\n58\n1\n1\n0\n1\n1\n1\n26\n5\n0\n32616\n\n\n3\n3\nPH7\n242\n39\n93\n0\n1\n0\n0\n0\n1\n76\n11\n0\n80338\n\n\n4\n4\nPH7\n102\n11\n27\n0\n0\n1\n1\n1\n0\n56\n15\n0\n-178758",
    "crumbs": [
      "Tutorials",
      "DHS Wealth Index"
    ]
  },
  {
    "objectID": "tutorial.dhs.html#renaming-columns-to-match",
    "href": "tutorial.dhs.html#renaming-columns-to-match",
    "title": "DHS Wealth Index",
    "section": "Renaming columns to match",
    "text": "Renaming columns to match\nDHS files do not have uniform column names. To make analysis easier, we rename commonnly ones. Feel free to extend the config to your usecase.\n\nph_config = dhs.load_column_config(\"ph\")\nph_config\n\n{'cluster number': 'DHSCLUST',\n 'wealth index factor score combined (5 decimals)': 'Wealth Index',\n 'country code and phase': 'country code and phase',\n 'number of rooms used for sleeping': 'rooms',\n 'has electricity': 'electric',\n 'has mobile telephone': 'mobile telephone',\n 'has radio': 'radio',\n 'has television': 'television',\n 'has car/truck': 'car/truck',\n 'has refrigerator': 'refrigerator',\n 'has motorcycle/scooter': 'motorcycle',\n 'main floor material': 'floor',\n 'type of toilet facility': 'toilet',\n 'source of drinking water': 'drinking water'}\n\n\n\nrenamed_dhs_df = dhs_df.rename(columns=ph_config)\n\n\nrenamed_dhs_df.head()\n\n\n\n\n\n\n\n\n\ncountry code and phase\nDHSCLUST\ndrinking water\ntoilet\nelectric\nradio\ntelevision\nrefrigerator\nmotorcycle\ncar/truck\nfloor\nrooms\nmobile telephone\nWealth Index\n\n\n\n\n0\n0\nPH7\n725\n80\n61\n0\n1\n0\n1\n1\n1\n74\n20\n0\n-168581\n\n\n1\n1\nPH7\n1009\n19\n92\n1\n1\n1\n1\n1\n0\n51\n15\n1\n127550\n\n\n2\n2\nPH7\n1072\n91\n58\n1\n1\n0\n1\n1\n1\n26\n5\n0\n32616\n\n\n3\n3\nPH7\n242\n39\n93\n0\n1\n0\n0\n0\n1\n76\n11\n0\n80338\n\n\n4\n4\nPH7\n102\n11\n27\n0\n0\n1\n1\n1\n0\n56\n15\n0\n-178758",
    "crumbs": [
      "Tutorials",
      "DHS Wealth Index"
    ]
  },
  {
    "objectID": "tutorial.dhs.html#cluster-summaries",
    "href": "tutorial.dhs.html#cluster-summaries",
    "title": "DHS Wealth Index",
    "section": "Cluster Summaries",
    "text": "Cluster Summaries\n\nwealth_col_name = \"Wealth Index\"\ncluster_col_name = \"DHSCLUST\"\n\n\nsummarized = (\n    renamed_dhs_df[[wealth_col_name, cluster_col_name]].groupby(cluster_col_name).mean()\n)\nsummarized = summarized.reset_index()\n\n\nsummarized.head()\n\n\n\n\n\n\n\n\nDHSCLUST\nWealth Index\n\n\n\n\n0\n3\n-232188.0\n\n\n1\n4\n228860.0\n\n\n2\n5\n157620.0\n\n\n3\n6\n40308.5\n\n\n4\n7\n-37595.5\n\n\n\n\n\n\n\n\nlen(summarized)\n\n679\n\n\n\nsummarized.DHSCLUST.isna().sum()\n\n0\n\n\n\nsummarized.DHSCLUST.isna().sum()\n\n0\n\n\n\ndhs_shp = gpd.read_file(dhs_gps_coordinates)\n\n\ndhs_shp.head()\n\n\n\n\n\n\n\n\nDHSID\nDHSCC\nDHSYEAR\nDHSCLUST\nLATNUM\nLONGNUM\ngeometry\n\n\n\n\n0\nPH20XX725\nPH\n0\n725\n0.409441\n0.220510\nPOINT (0.22051 0.40944)\n\n\n1\nPH20XX1009\nPH\n0\n1009\n0.333693\n0.332499\nPOINT (0.33250 0.33369)\n\n\n2\nPH20XX1072\nPH\n0\n1072\n0.378053\n0.089852\nPOINT (0.08985 0.37805)\n\n\n3\nPH20XX242\nPH\n0\n242\n0.306277\n0.431677\nPOINT (0.43168 0.30628)\n\n\n4\nPH20XX102\nPH\n0\n102\n0.535456\n0.716025\nPOINT (0.71602 0.53546)\n\n\n\n\n\n\n\n\nsurvey_geo = pd.merge(summarized, dhs_shp, on=\"DHSCLUST\")\nsurvey_geo\n\n\n\n\n\n\n\n\nDHSCLUST\nWealth Index\nDHSID\nDHSCC\nDHSYEAR\nLATNUM\nLONGNUM\ngeometry\n\n\n\n\n0\n3\n-232188.000000\nPH20XX003\nPH\n0\n0.609945\n0.350830\nPOINT (0.35083 0.60995)\n\n\n1\n4\n228860.000000\nPH20XX004\nPH\n0\n0.363843\n0.281563\nPOINT (0.28156 0.36384)\n\n\n2\n5\n157620.000000\nPH20XX005\nPH\n0\n0.715438\n0.145014\nPOINT (0.14501 0.71544)\n\n\n3\n6\n40308.500000\nPH20XX006\nPH\n0\n0.758501\n0.628373\nPOINT (0.62837 0.75850)\n\n\n4\n6\n40308.500000\nPH20XX006\nPH\n0\n0.669415\n0.479379\nPOINT (0.47938 0.66942)\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n995\n1247\n90273.333333\nPH20XX1247\nPH\n0\n0.214682\n0.419448\nPOINT (0.41945 0.21468)\n\n\n996\n1248\n212729.500000\nPH20XX1248\nPH\n0\n0.189401\n0.152806\nPOINT (0.15281 0.18940)\n\n\n997\n1248\n212729.500000\nPH20XX1248\nPH\n0\n0.563460\n0.023900\nPOINT (0.02390 0.56346)\n\n\n998\n1250\n101508.500000\nPH20XX1250\nPH\n0\n0.166465\n0.617584\nPOINT (0.61758 0.16646)\n\n\n999\n1250\n101508.500000\nPH20XX1250\nPH\n0\n0.252438\n0.668243\nPOINT (0.66824 0.25244)\n\n\n\n\n1000 rows × 8 columns",
    "crumbs": [
      "Tutorials",
      "DHS Wealth Index"
    ]
  },
  {
    "objectID": "tutorial.dhs.html#recalculating-wealth-index-for-a-single-country",
    "href": "tutorial.dhs.html#recalculating-wealth-index-for-a-single-country",
    "title": "DHS Wealth Index",
    "section": "Recalculating wealth index for a single country",
    "text": "Recalculating wealth index for a single country\n\nfeatures = [\n    \"rooms\",\n    \"electric\",\n    \"mobile telephone\",\n    \"radio\",\n    \"television\",\n    \"car/truck\",\n    \"refrigerator\",\n    \"motorcycle\",\n    \"floor\",\n    \"toilet\",\n    \"drinking water\",\n]\n\n\n# apply a threshold\ndhs.apply_threshold(renamed_dhs_df, columns=features, config={\"rooms\": [0, 25]})\n\n\n\n\n\n\n\n\n\ncountry code and phase\nDHSCLUST\ndrinking water\ntoilet\nelectric\nradio\ntelevision\nrefrigerator\nmotorcycle\ncar/truck\nfloor\nrooms\nmobile telephone\nWealth Index\n\n\n\n\n0\n0\nPH7\n725\n80\n61\n0\n1\n0\n1\n1\n1\n74\n20\n0\n-168581\n\n\n1\n1\nPH7\n1009\n19\n92\n1\n1\n1\n1\n1\n0\n51\n15\n1\n127550\n\n\n2\n2\nPH7\n1072\n91\n58\n1\n1\n0\n1\n1\n1\n26\n5\n0\n32616\n\n\n3\n3\nPH7\n242\n39\n93\n0\n1\n0\n0\n0\n1\n76\n11\n0\n80338\n\n\n4\n4\nPH7\n102\n11\n27\n0\n0\n1\n1\n1\n0\n56\n15\n0\n-178758\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n995\n995\nPH7\n834\n63\n83\n0\n1\n1\n1\n1\n1\n28\n10\n0\n241846\n\n\n996\n996\nPH7\n1170\n74\n78\n1\n0\n1\n1\n1\n0\n34\n17\n1\n106424\n\n\n997\n997\nPH7\n762\n81\n14\n1\n1\n0\n1\n1\n0\n83\n12\n1\n246898\n\n\n998\n998\nPH7\n63\n40\n21\n0\n1\n1\n1\n1\n1\n12\n2\n1\n-212590\n\n\n999\n999\nPH7\n748\n56\n38\n1\n1\n1\n0\n1\n1\n69\n7\n1\n-10774\n\n\n\n\n1000 rows × 15 columns\n\n\n\n\nrenamed_dhs_df[\"Recomputed Wealth Index\"] = dhs.assign_wealth_index(\n    renamed_dhs_df[features], features\n)\nrenamed_dhs_df.head()\n\n\n\n\n\n\n\n\n\ncountry code and phase\nDHSCLUST\ndrinking water\ntoilet\nelectric\nradio\ntelevision\nrefrigerator\nmotorcycle\ncar/truck\nfloor\nrooms\nmobile telephone\nWealth Index\nRecomputed Wealth Index\n\n\n\n\n0\n0\nPH7\n725\n80\n61\n0\n1\n0\n1\n1\n1\n74\n20\n0\n-168581\n-63.515731\n\n\n1\n1\nPH7\n1009\n19\n92\n1\n1\n1\n1\n1\n0\n51\n15\n1\n127550\n8.730482\n\n\n2\n2\nPH7\n1072\n91\n58\n1\n1\n0\n1\n1\n1\n26\n5\n0\n32616\n-60.121255\n\n\n3\n3\nPH7\n242\n39\n93\n0\n1\n0\n0\n0\n1\n76\n11\n0\n80338\n-14.959946\n\n\n4\n4\nPH7\n102\n11\n27\n0\n0\n1\n1\n1\n0\n56\n15\n0\n-178758\n-14.060453",
    "crumbs": [
      "Tutorials",
      "DHS Wealth Index"
    ]
  },
  {
    "objectID": "tutorial.dhs.html#recalculating-wealth-index-for-multiple-countries",
    "href": "tutorial.dhs.html#recalculating-wealth-index-for-multiple-countries",
    "title": "DHS Wealth Index",
    "section": "Recalculating wealth index for multiple countries",
    "text": "Recalculating wealth index for multiple countries\n\ndhs_ph_path = \"../data/ph.DTA\"\ndhs_kh_path = \"../data/kh.DTA\"\ndhs_mm_path = \"../data/mm.DTA\"\ndhs_tl_path = \"../data/tl.DTA\"\nph_config = dhs.load_column_config(\"ph\")\nkh_config = dhs.load_column_config(\"kh\")\nmm_config = dhs.load_column_config(\"mm\")\ntl_config = dhs.load_column_config(\"tl\")\ndhs_ph_df = dhs.load_dhs_file(dhs_ph_path).rename(columns=ph_config)\ndhs_kh_df = dhs.load_dhs_file(dhs_kh_path).rename(columns=kh_config)\ndhs_mm_df = dhs.load_dhs_file(dhs_mm_path).rename(columns=mm_config)\ndhs_tl_df = dhs.load_dhs_file(dhs_tl_path).rename(columns=tl_config)\n\n\ncols = list(ph_config.values()) + [\"country code and phase\"]\nmerged_df = pd.concat(\n    [\n        dhs_ph_df[cols],\n        dhs_kh_df[cols],\n        dhs_mm_df[cols],\n        dhs_tl_df[cols],\n    ]\n)\nmerged_df = merged_df.fillna(0)\n\n\nmerged_df[\"Recomputed Wealth Index\"] = dhs.assign_wealth_index(merged_df[features])\nmerged_df.head()\n\n\n\n\n\n\n\n\nDHSCLUST\nWealth Index\ncountry code and phase\nrooms\nelectric\nmobile telephone\nradio\ntelevision\ncar/truck\nrefrigerator\nmotorcycle\nfloor\ntoilet\ndrinking water\ncountry code and phase\nRecomputed Wealth Index\n\n\n\n\n0\n725\n-168581\nPH7\n20\n0\n0\n1\n0\n1\n1\n1\n74\n61\n80.0\nPH7\n122.888238\n\n\n1\n1009\n127550\nPH7\n15\n1\n1\n1\n1\n0\n1\n1\n51\n92\n19.0\nPH7\n78.430888\n\n\n2\n1072\n32616\nPH7\n5\n1\n0\n1\n0\n1\n1\n1\n26\n58\n91.0\nPH7\n108.113989\n\n\n3\n242\n80338\nPH7\n11\n0\n0\n1\n0\n1\n0\n0\n76\n93\n39.0\nPH7\n105.464687\n\n\n4\n102\n-178758\nPH7\n15\n0\n0\n0\n1\n0\n1\n1\n56\n27\n11.0\nPH7\n45.993876\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt  # noqa\n\n\nmerged_df.hist(\"Recomputed Wealth Index\")\n\narray([[&lt;Axes: title={'center': 'Recomputed Wealth Index'}&gt;]],\n      dtype=object)\n\n\n\n\n\n\n\n\n\n\nmerged_df[\"Recomputed Wealth Index Not PCA\"] = dhs.assign_wealth_index(\n    merged_df[features], use_pca=False\n)\nmerged_df.head()\n\n\n\n\n\n\n\n\nDHSCLUST\nWealth Index\ncountry code and phase\nrooms\nelectric\nmobile telephone\nradio\ntelevision\ncar/truck\nrefrigerator\nmotorcycle\nfloor\ntoilet\ndrinking water\ncountry code and phase\nRecomputed Wealth Index\nRecomputed Wealth Index Not PCA\n\n\n\n\n0\n725\n-168581\nPH7\n20\n0\n0\n1\n0\n1\n1\n1\n74\n61\n80.0\nPH7\n122.888238\n-10730.578127\n\n\n1\n1009\n127550\nPH7\n15\n1\n1\n1\n1\n0\n1\n1\n51\n92\n19.0\nPH7\n78.430888\n-57116.290440\n\n\n2\n1072\n32616\nPH7\n5\n1\n0\n1\n0\n1\n1\n1\n26\n58\n91.0\nPH7\n108.113989\n30004.584457\n\n\n3\n242\n80338\nPH7\n11\n0\n0\n1\n0\n1\n0\n0\n76\n93\n39.0\nPH7\n105.464687\n-48966.528484\n\n\n4\n102\n-178758\nPH7\n15\n0\n0\n0\n1\n0\n1\n1\n56\n27\n11.0\nPH7\n45.993876\n-39722.455483\n\n\n\n\n\n\n\n\nmerged_df.hist(\"Recomputed Wealth Index Not PCA\")\n\narray([[&lt;Axes: title={'center': 'Recomputed Wealth Index Not PCA'}&gt;]],\n      dtype=object)",
    "crumbs": [
      "Tutorials",
      "DHS Wealth Index"
    ]
  },
  {
    "objectID": "spatialjoin_highest_intersection.html",
    "href": "spatialjoin_highest_intersection.html",
    "title": "Spatial Join Highest Intersection",
    "section": "",
    "text": "Import\n\n\nGenerate Test Data\n\n\nLoad a sample admin boundary file using geopandas\n\nadmin_bounds_gdf = gpd.read_file(\"../data/geoboundary.geojson\")\n\n\nadmin_bounds_gdf.head(3)\n\n\n\n\n\n\n\n\nshapeName\nshapeISO\nshapeID\nshapeGroup\nshapeType\ngeometry\n\n\n\n\n0\nAbra\nNone\nPHL-ADM2-3_0_0-B1\nPHL\nADM2\nMULTIPOLYGON (((120.96795 17.95706, 120.97803 ...\n\n\n1\nAgusan del Norte\nNone\nPHL-ADM2-3_0_0-B2\nPHL\nADM2\nMULTIPOLYGON (((125.57724 9.45679, 125.59687 9...\n\n\n2\nAgusan del Sur\nNone\nPHL-ADM2-3_0_0-B3\nPHL\nADM2\nMULTIPOLYGON (((125.91087 8.85625, 125.91461 8...\n\n\n\n\n\n\n\n\nadmin_bounds_gdf.dtypes\n\nshapeName       object\nshapeISO        object\nshapeID         object\nshapeGroup      object\nshapeType       object\ngeometry      geometry\ndtype: object\n\n\n\n# admin_bounds_gdf.explore()\n\n\n\nGenerate a sample grid\n\ngrid_generator5k = grids.SquareGridGenerator(50_000)  # 5 km x 5 km square cells\n\n\ngrid_gdf = grid_generator5k.generate_grid(admin_bounds_gdf)\n\nCPU times: user 2.38 s, sys: 112 ms, total: 2.49 s\nWall time: 2.65 s\n\n\n\ngrid_gdf.plot();\n\n\n\n\n\n\n\n\n\nax = admin_bounds_gdf.plot(facecolor=\"grey\", edgecolor=\"grey\", alpha=0.2)\nax = grid_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\n\n\n\ngrid_gdf.describe()\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\ncount\n323.000000\n323.000000\n\n\nmean\n11.773994\n15.018576\n\n\nstd\n4.861594\n8.791210\n\n\nmin\n0.000000\n0.000000\n\n\n25%\n8.000000\n8.000000\n\n\n50%\n11.000000\n14.000000\n\n\n75%\n16.000000\n21.000000\n\n\nmax\n21.000000\n37.000000\n\n\n\n\n\n\n\n\ngrid_gdf.head(3)\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n3\n3\nPOLYGON ((118.27581 5.92871, 118.72497 5.92871...\n\n\n1\n2\n3\nPOLYGON ((117.82665 5.92871, 118.27581 5.92871...\n\n\n2\n3\n4\nPOLYGON ((118.27581 6.37528, 118.72497 6.37528...\n\n\n\n\n\n\n\n\ngrid_gdf.dtypes\n\nx              int64\ny              int64\ngeometry    geometry\ndtype: object\n\n\n\n\nSpatial join with highest intersection\n\nsource\n\nget_highest_intersection\n\n get_highest_intersection (gdf1:geopandas.geodataframe.GeoDataFrame,\n                           gdf2:geopandas.geodataframe.GeoDataFrame,\n                           proj_crs:str)\n\nGets the intersection based on the largest area joined\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ngdf1\nGeoDataFrame\ngdf1 will be the basis of output geometry\n\n\ngdf2\nGeoDataFrame\ngdf2 data will all be included during intersection\n\n\nproj_crs\nstr\nmetric CRS (e.g., Philippines uses EPSG:32651)\n\n\nReturns\nGeoDataFrame\n\n\n\n\n\nget_highest_intersection(grid_gdf, admin_bounds_gdf, \"EPSG:32651\")\n\n\n\n\n\n\n\n\ngeometry\nx\ny\nshapeName\nshapeISO\nshapeID\nshapeGroup\nshapeType\n\n\n\n\n0\nPOLYGON ((118.27581 5.92871, 118.72497 5.92871...\n3\n3\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n1\nPOLYGON ((117.82665 5.92871, 118.27581 5.92871...\n2\n3\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n2\nPOLYGON ((118.27581 6.37528, 118.72497 6.37528...\n3\n4\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n3\nPOLYGON ((118.27581 6.82146, 118.72497 6.82146...\n3\n5\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n4\nPOLYGON ((116.92834 7.26723, 117.37749 7.26723...\n0\n6\nPalawan\nNone\nPHL-ADM2-3_0_0-B59\nPHL\nADM2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n318\nPOLYGON ((125.46233 5.03451, 125.91149 5.03451...\n19\n1\nDavao del Sur\nNone\nPHL-ADM2-3_0_0-B28\nPHL\nADM2\n\n\n319\nPOLYGON ((125.46233 9.93163, 125.91149 9.93163...\n19\n12\nDinagat Islands\nNone\nPHL-ADM2-3_0_0-B30\nPHL\nADM2\n\n\n320\nPOLYGON ((125.46233 10.37375, 125.91149 10.373...\n19\n13\nEastern Samar\nNone\nPHL-ADM2-3_0_0-B31\nPHL\nADM2\n\n\n321\nPOLYGON ((125.91149 9.93163, 126.36065 9.93163...\n20\n12\nSurigao del Norte\nNone\nPHL-ADM2-3_0_0-B74\nPHL\nADM2\n\n\n322\nPOLYGON ((125.91149 10.37375, 126.36065 10.373...\n20\n13\nEastern Samar\nNone\nPHL-ADM2-3_0_0-B31\nPHL\nADM2\n\n\n\n\n323 rows × 8 columns\n\n\n\n\n\n\nCheck plot of output\n\noutput = get_highest_intersection(grid_gdf, admin_bounds_gdf, \"EPSG:32651\")\n\n\noutput.plot()\n\n\n\n\n\n\n\n\n\n# output.explore()",
    "crumbs": [
      "Module Reference",
      "Spatial Join Highest Intersection"
    ]
  },
  {
    "objectID": "datasets_ookla.html",
    "href": "datasets_ookla.html",
    "title": "Datasets Ookla",
    "section": "",
    "text": "source\n\nlist_ookla_files\n\n list_ookla_files ()\n\nGet list of ookla data\n\nookla_files = list_ookla_files()\nassert ookla_files.get(OoklaFile(\"fixed\", \"2021\", \"2\"), None) is not None\n\n\nsource\n\n\ndownload_ookla_file\n\n download_ookla_file (type_:str, year:str, quarter:str,\n                      directory:str='data/', overwrite:bool=False,\n                      show_progress=True, chunksize=8192, reporthook=None)\n\nDownload ookla file to path\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntype_\nstr\n\nInternet connection type: ‘fixed’ or ‘mobile’\n\n\nyear\nstr\n\nYear (e.g. ‘2020’)\n\n\nquarter\nstr\n\nQuarter (valid values: ‘1’,‘2’,‘3’,‘4’)\n\n\ndirectory\nstr\ndata/\nDownload directory\n\n\noverwrite\nbool\nFalse\nOverwrite if existing\n\n\nshow_progress\nbool\nTrue\nshow progres bar\n\n\nchunksize\nint\n8192\nDownload chunksize\n\n\nreporthook\nNoneType\nNone\nUse custom progress bar\n\n\nReturns\nOptional\n\n\n\n\n\n\nsource\n\n\nparallel_download\n\n parallel_download (item)\n\n\nsource\n\n\ndownload_ookla_parallel\n\n download_ookla_parallel (num_expected_ookla_files, type_, year,\n                          directory, overwrite, show_progress, chunksize,\n                          reporthook)\n\n\nsource\n\n\ndownload_ookla_year_data\n\n download_ookla_year_data (type_, year, cache_dir, use_cache=True,\n                           show_progress=True, chunksize=8192,\n                           reporthook=None)\n\nDownload ookla data for a specifed type (fixed or mobile) and year. Data for all 4 quarters will be downloaded.\n\nsource\n\n\nlookup_ookla_file\n\n lookup_ookla_file (filename)\n\nGet OoklaFile for the given filename\n\nassert lookup_ookla_file(\"2021-04-01_performance_fixed_tiles.parquet\") == OoklaFile(\n    \"fixed\", \"2021\", \"2\"\n)\n\n\nsource\n\n\ncompute_datakey\n\n compute_datakey (aoi_bounds, type_, year, return_geometry)\n\n\nsource\n\n\nwrite_ookla_metajson\n\n write_ookla_metajson (cache_dir, data_key, total_bounds, type_, year,\n                       return_geometry)\n\n\nsource\n\n\nOoklaDataManager\n\n OoklaDataManager (cache_dir='~/.cache/geowrangler')\n\nAn instance of this class provides convenience functoins for loading and caching Ookla data\n\nsource\n\n\nOoklaDataManager.reinitialize_processed_cache\n\n OoklaDataManager.reinitialize_processed_cache ()\n\nReinitialize processed_cache_dir to start over from scratch.\n\nsource\n\n\nOoklaDataManager.reinitialize_aggregated_cache\n\n OoklaDataManager.reinitialize_aggregated_cache ()\n\nReinitialize aggregated_cache_dir to start over from scratch.\n\nsource\n\n\nOoklaDataManager.load_type_year_data\n\n OoklaDataManager.load_type_year_data\n                                       (aoi:geopandas.geodataframe.GeoData\n                                       Frame, type_:str, year:str,\n                                       use_cache=True,\n                                       return_geometry=False,\n                                       show_progress=True, chunksize=8192,\n                                       reporthook=None)\n\nLoad Ookla data across all quarters for a specified aoi, type (fixed, mobile) and year\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\naoi\nGeoDataFrame\n\narea of interest\n\n\ntype_\nstr\n\nookla data type: fixed or mobile\n\n\nyear\nstr\n\nyear\n\n\nuse_cache\nbool\nTrue\nuse cache dir\n\n\nreturn_geometry\nbool\nFalse\ninclude geometry in returned values\n\n\nshow_progress\nbool\nTrue\ndisplay progress bar\n\n\nchunksize\nint\n8192\ndownload buffer size\n\n\nreporthook\nNoneType\nNone\ncustom progress bar\n\n\n\n\nsource\n\n\nOoklaDataManager.aggregate_ookla_features\n\n OoklaDataManager.aggregate_ookla_features\n                                            (aoi:geopandas.geodataframe.Ge\n                                            oDataFrame, type_:str,\n                                            year:str, use_cache=True,\n                                            return_geometry=False,\n                                            output_crs='epsg:4326', aggreg\n                                            ations:Dict[str,Any]={'mean_av\n                                            g_d_kbps': ('avg_d_kbps',\n                                            'mean'), 'mean_avg_u_kbps':\n                                            ('avg_u_kbps', 'mean'),\n                                            'mean_avg_lat_ms':\n                                            ('avg_lat_ms', 'mean'),\n                                            'mean_num_tests': ('tests',\n                                            'mean'), 'mean_num_devices':\n                                            ('devices', 'mean')},\n                                            show_progress=True,\n                                            chunksize=8192,\n                                            reporthook=None)\n\nGenerates yearly aggregate features for the AOI based on Ookla data for a given type (fixed, mobile) and year.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\naoi\nGeoDataFrame\n\nArea of interest\n\n\ntype_\nstr\n\nOokla speed type: ’fixedormobile`\n\n\nyear\nstr\n\nYear to aggregate (over 4 quarters)\n\n\nuse_cache\nbool\nTrue\nUse cached data in cache dir as specified in ookla_data_manager\n\n\nreturn_geometry\nbool\nFalse\nSave aggregated data as geojson\n\n\noutput_crs\nstr\nepsg:4326\ncrs to use in creating aggregated geodataframe\n\n\naggregations\nDict\n{‘mean_avg_d_kbps’: (‘avg_d_kbps’, ‘mean’), ‘mean_avg_u_kbps’: (‘avg_u_kbps’, ‘mean’), ‘mean_avg_lat_ms’: (‘avg_lat_ms’, ‘mean’), ‘mean_num_tests’: (‘tests’, ‘mean’), ‘mean_num_devices’: (‘devices’, ‘mean’)}\nAggregation functions on ookla data (see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html)\n\n\nshow_progress\nbool\nTrue\ndisplay progress bar\n\n\nchunksize\nint\n8192\ndownload buffer size\n\n\nreporthook\nNoneType\nNone\ncustom progress bar",
    "crumbs": [
      "Module Reference",
      "Datasets Ookla"
    ]
  },
  {
    "objectID": "tutorial.grids.html",
    "href": "tutorial.grids.html",
    "title": "Grid Generation Tutorial",
    "section": "",
    "text": "A basic introduction to geospatial grids",
    "crumbs": [
      "Tutorials",
      "Grid Generation Tutorial"
    ]
  },
  {
    "objectID": "tutorial.grids.html#basic-usage",
    "href": "tutorial.grids.html#basic-usage",
    "title": "Grid Generation Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nCreating a grid from a geojson file\n\nImport geopandas and the geowrangler.grids module\n\nimport geopandas as gpd\nimport pandas as pd\n\nfrom geowrangler import grids\n\n\n\nLoad a sample geojson file into pandas\nIn our case, we are loading the Region 3 (Central Luzon Administrative Region) of the Philippines.\n\nregion3_gdf = gpd.read_file(\"../data/region3_admin.geojson\")\n\nThis geopandas dataframe has the size:\n\n\nlength of region3_gdf: 1 row(s)\n\n\n\nregion3_gdf\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\n\n\n\n\n0\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n\n\n\n\n\n\n\nShow the original plot\n\nimport matplotlib.pyplot as plt\n\n\nax = region3_gdf.plot(ax=plt.axes())\n\n\n\n\n\n\n\n\n\nregion3_gdf.crs  # CRS info\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n\nReprojecting Before Gridding\nIf you’re going to use a custom boundary for SquareGridGenerator and FastSquareGridGenerator, it is good practice to use the buffered boundary of the reprojected AOI instead of using just the boundary of the original AOI. This ensures that we don’t miss out on any grid cells.\nWe will use EPSG:3857 which is the default projection for both square grid genreator variants.\nNote: The 13km buffer here was chosen because it is the minimum buffer size (rounded to the nearest km) where the boundary fully encloses the AOI.\n\naoi_total_bounds = region3_gdf.to_crs(\"EPSG:3857\").buffer(13_000).total_bounds\naoi_total_bounds\n\narray([13321499.12819502,  1608018.14989316, 13621027.63361816,\n        1876773.06126797])",
    "crumbs": [
      "Tutorials",
      "Grid Generation Tutorial"
    ]
  },
  {
    "objectID": "tutorial.grids.html#square-grid-generator",
    "href": "tutorial.grids.html#square-grid-generator",
    "title": "Grid Generation Tutorial",
    "section": "Square Grid Generator",
    "text": "Square Grid Generator\n\nGenerating Grids\nCreate a grid generator with a size of 5,000 m. The units of the grid size are dependent on the projection parameter\nof the grid generator. In this case, the default is EPSG:3857.\n\ngrids.SquareGridGenerator?\n\n\nInit signature:\ngrids.SquareGridGenerator(\n    cell_size: float,\n    grid_projection: str = 'EPSG:3857',\n    boundary: Union[geowrangler.grids.SquareGridBoundary, List[float], Tuple[float]] = None,\n)\nDocstring:      &lt;no docstring&gt;\nFile:           ~/github-repos/geowrangler/geowrangler/grids.py\nType:           type\nSubclasses:     \n\n\n\n\ngrid_generator5k = grids.SquareGridGenerator(5_000)  # 5 km x 5 km square cells\n\nGenerate square grids &gt; Notice the time taken to grid the multi polygon at 5K resolution\n\ngrid_gdf5k = grid_generator5k.generate_grid(region3_gdf)\n\nCPU times: user 340 ms, sys: 35.8 ms, total: 376 ms\nWall time: 376 ms\n\n\n\ngrid_gdf5k.plot()\n\n\n\n\n\n\n\n\nShow gridded version of sample geojson file at 5K resolution\n\n\nlength of grid_gdf5k: 1074 row(s)\n\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = grid_gdf5k.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\n\n\nIn addition to the grid cells, there are 2 extra columns x and y when combined are unique per grid. It can also tell us which grids are adjacent to each other.\n\ngrid_gdf5k.head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n\n\n3\n2\n24\nPOLYGON ((119.87566 15.4491, 119.92058 15.4491...\n\n\n4\n2\n25\nPOLYGON ((119.87566 15.49239, 119.92058 15.492...\n\n\n\n\n\n\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = grid_gdf5k[grid_gdf5k[\"x\"] == 10].plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\n\n\n\n\nGridding at a coarser resolution\nLet’s try the same process but with a bigger grid (15K)\n\ngrid_generator15k = grids.SquareGridGenerator(15_000)  # 15 km x 15 km grids\n\nGenerate square grids &gt; Notice the time taken to grid the multi polygon at 15K resolution (compared to 5K resolution)\n\ngrid_gdf15k = grid_generator15k.generate_grid(region3_gdf)\n\nCPU times: user 306 ms, sys: 33.7 ms, total: 340 ms\nWall time: 339 ms\n\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\ngrid_gdf15k.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\n\n\nShow gridded version of sample geojson file at 15K resolution\n\n\nlength of grid_gdf15k: 154 row(s)\n\n\n\n\nReusing boundaries\nIf you have 2 polygons that are far from each other but wish to have them follow the reference same reference x and y, you can use pass in custom boudaries.\nLet’s load some grids that are from each other\n\ncell1 = grid_gdf15k.head(1)\ncell2 = grid_gdf15k.tail(1)\n\n\npd.concat([cell1, cell2])\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n2\n2\nPOLYGON ((120.05533 14.66839, 120.19008 14.668...\n\n\n153\n18\n16\nPOLYGON ((122.21128 16.48548, 122.34603 16.485...\n\n\n\n\n\n\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"red\")\nax = grid_gdf15k.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\nax = pd.concat([cell1, cell2]).plot(ax=ax)\n\n\n\n\n\n\n\n\n\ngrid_generator1k = grids.SquareGridGenerator(1_000, boundary=aoi_total_bounds)\n\nWe reproject cell1 and cell2 to EPSG:3857 before passing them in generate_grid since aoi_total_bounds is already reprojected. The projection of the AOI and the boundary should be the same.\nWe reproject back to EPSG:4326 after the grids are generated.\n\ncell1 = cell1.to_crs(\"EPSG:3857\")\ncell2 = cell2.to_crs(\"EPSG:3857\")\n\n\ngridcell1 = grid_generator1k.generate_grid(cell1)\ngridcell1 = gridcell1.to_crs(\"EPSG:4326\")\n\nCPU times: user 10.3 ms, sys: 1.19 ms, total: 11.5 ms\nWall time: 11.9 ms\n\n\n\nlen(gridcell1)\n\n256\n\n\n\ngridcell1.head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n42\n42\nPOLYGON ((120.04636 14.65975, 120.05534 14.659...\n\n\n1\n42\n43\nPOLYGON ((120.04636 14.66844, 120.05534 14.668...\n\n\n2\n42\n44\nPOLYGON ((120.04636 14.67713, 120.05534 14.677...\n\n\n3\n42\n45\nPOLYGON ((120.04636 14.68582, 120.05534 14.685...\n\n\n4\n42\n46\nPOLYGON ((120.04636 14.69451, 120.05534 14.694...\n\n\n\n\n\n\n\n\nax = gridcell1.plot(facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\n\n\nNote: We pass in the reprojected cell2 in generate_grid since aoi_total_bounds is already reprojected\n\ngridcell2 = grid_generator1k.generate_grid(cell2)\ngridcell2 = gridcell2.to_crs(\"EPSG:4326\")\n\nCPU times: user 11 ms, sys: 1.86 ms, total: 12.8 ms\nWall time: 11.8 ms\n\n\n\nlen(gridcell2)\n\n256\n\n\n\ngridcell2.head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n282\n252\nPOLYGON ((122.20231 16.47691, 122.21129 16.476...\n\n\n1\n282\n253\nPOLYGON ((122.20231 16.48552, 122.21129 16.485...\n\n\n2\n282\n254\nPOLYGON ((122.20231 16.49414, 122.21129 16.494...\n\n\n3\n282\n255\nPOLYGON ((122.20231 16.50275, 122.21129 16.502...\n\n\n4\n282\n256\nPOLYGON ((122.20231 16.51136, 122.21129 16.511...\n\n\n\n\n\n\n\n\nax = gridcell2.plot(facecolor=\"none\", edgecolor=\"red\")\n\n\n\n\n\n\n\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = gridcell1.plot(ax=ax, color=\"green\")\nax = gridcell2.plot(ax=ax, color=\"red\")\n\n\n\n\n\n\n\n\n\n\nGenerating grids for multiple distant areas\nIf you are using AOIs that are vary far from each other, Grid Generator already optmizes the implementation for you\nNote: We also reproject sparse_aois to EPSG:3857 since the grid_generator1k boundary is based on EPSG:3857\n\nsparse_aois = grid_gdf15k.iloc[\n    0:1000:3,\n]  # Get areas that far from each other\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = sparse_aois.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\n\n\n\nsparse_aois = sparse_aois.to_crs(\"EPSG:3857\")\n\n\nsparse_grid = grid_generator1k.generate_grid(sparse_aois)\nsparse_grid = sparse_grid.to_crs(\"EPSG:4326\")\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = sparse_grid.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\n\n\nIt is a bit hard to see the grids so, we get a subset to verify.\n\nax = sparse_grid.head(1000).plot(facecolor=\"none\", edgecolor=\"green\")",
    "crumbs": [
      "Tutorials",
      "Grid Generation Tutorial"
    ]
  },
  {
    "objectID": "tutorial.grids.html#fast-square-grid-generator",
    "href": "tutorial.grids.html#fast-square-grid-generator",
    "title": "Grid Generation Tutorial",
    "section": "Fast Square Grid Generator",
    "text": "Fast Square Grid Generator\n\nGenerating grids\nWe can use FastSquareGridGenerator for significantly faster grid generation.\n\nfast_grid_generator5k = grids.FastSquareGridGenerator(5_000)  # 5 km x 5 km square cells\n\n\nfast_grid_gdf5k = fast_grid_generator5k.generate_grid(region3_gdf)\nfast_grid_gdf5k.head()\n\nCPU times: user 178 ms, sys: 46 ms, total: 224 ms\nWall time: 180 ms\n\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n26\n21\nPOLYGON ((120.99856 15.31919, 120.99856 15.362...\n\n\n1\n18\n17\nPOLYGON ((120.63923 15.14583, 120.63923 15.189...\n\n\n2\n15\n30\nPOLYGON ((120.50449 15.7087, 120.50449 15.7519...\n\n\n3\n7\n26\nPOLYGON ((120.14516 15.53567, 120.14516 15.578...\n\n\n4\n26\n39\nPOLYGON ((120.99856 16.09747, 120.99856 16.140...\n\n\n\n\n\n\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = fast_grid_gdf5k.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\n\n\nWe check that SquareGridGenerator and FastSquareGridGenerator have an exact match in tiles. Since they use different underlying algorithms, it isn’t a 100% guarantee that they will always have the exact same match in tiles due to floating point differences, but they should be extremely close most of the time.\n\ngrid_gdf5k.shape[0], fast_grid_gdf5k.shape[0]\n\n(1074, 1074)\n\n\n\ngrid_gdf5k[\"xy_key\"] = grid_gdf5k.apply(lambda row: f\"{row['x']}-{row['y']}\", axis=1)\nfast_grid_gdf5k[\"xy_key\"] = fast_grid_gdf5k.apply(lambda row: f\"{row['x']}-{row['y']}\", axis=1)\n\nbool_mask = grid_gdf5k[\"xy_key\"].isin(fast_grid_gdf5k[\"xy_key\"])\nassert bool_mask.all()\n\nbool_mask = fast_grid_gdf5k[\"xy_key\"].isin(grid_gdf5k[\"xy_key\"])\nassert bool_mask.all()\n\nWe can even use a more granular cell_size, say 500m, and FastSquareGridGenerator will still run for around the same time as SquareGridGenerator at 5000m cell_size despite the former having ~88 times more grid tiles.\nWe can also pass in a column name to unique_id_col so that the grids can preserve the ID from the AOI. This makes it convenient so you don’t have to do another spatial intersection between the tiles gdf and the AOI gdf to get the AOI IDs.\n\nfast_grid_generator500 = grids.FastSquareGridGenerator(500)  # 500 m x 500 m square cells\n\n\nfast_grid_gdf500 = fast_grid_generator500.generate_grid(region3_gdf, unique_id_col=\"Reg_Name\")\nfast_grid_gdf500.head()\n\nCPU times: user 1.06 s, sys: 64.3 ms, total: 1.13 s\nWall time: 1.08 s\n\n\n\n\n\n\n\n\n\nx\ny\nReg_Name\ngeometry\n\n\n\n\n0\n332\n102\nRegion III\nPOLYGON ((121.28153 14.85081, 121.28153 14.855...\n\n\n1\n191\n180\nRegion III\nPOLYGON ((120.64822 15.18919, 120.64822 15.193...\n\n\n2\n208\n210\nRegion III\nPOLYGON ((120.72457 15.31919, 120.72457 15.323...\n\n\n3\n94\n246\nRegion III\nPOLYGON ((120.21253 15.47508, 120.21253 15.479...\n\n\n4\n202\n224\nRegion III\nPOLYGON ((120.69762 15.37982, 120.69762 15.384...\n\n\n\n\n\n\n\n\nfast_grid_gdf500.shape[0]\n\n94133\n\n\n\n# computes how many more tiles there are in FastSquareGridGenerator 500m vs SquareGridGenerator 5000m\nfast_grid_gdf500.shape[0]/grid_gdf5k.shape[0]\n\n87.64711359404097",
    "crumbs": [
      "Tutorials",
      "Grid Generation Tutorial"
    ]
  },
  {
    "objectID": "tutorial.grids.html#h3-grid-generator",
    "href": "tutorial.grids.html#h3-grid-generator",
    "title": "Grid Generation Tutorial",
    "section": "H3 Grid Generator",
    "text": "H3 Grid Generator\n\nGenerating grids\nLet us generate grids of resolution 5. To learn more about the different resolution, visit: https://h3geo.org/docs/core-library/restable/\n\nh3_generator = grids.H3GridGenerator(resolution=5)\n\n\nh3_5_gdf = h3_generator.generate_grid(region3_gdf)\n\nCPU times: user 1.17 s, sys: 47.8 ms, total: 1.22 s\nWall time: 1.23 s\n\n\n\nax = region3_gdf.plot(aspect=\"equal\")\nax = h3_5_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\", aspect=\"equal\")\n\n\n\n\n\n\n\n\n\n\nNot exporting geometry\nIf you do not plan to use use geometry, you can pass return_geometry=False to just get a normal pandas DataFrame with the ids.\n\nh3_generator_no_geom = grids.H3GridGenerator(resolution=5, return_geometry=False)\n\n\nh3_region3_no_geom = h3_generator_no_geom.generate_grid(region3_gdf)\n\nCPU times: user 1.16 s, sys: 56.5 ms, total: 1.22 s\nWall time: 1.22 s\n\n\n\nlen(h3_region3_no_geom)\n\n84\n\n\n\nh3_region3_no_geom.head()\n\n\n\n\n\n\n\n\nhex_id\n\n\n\n\n0\n85694c5bfffffff\n\n\n1\n8569413bfffffff\n\n\n2\n85694113fffffff\n\n\n3\n85696b7bfffffff\n\n\n4\n856941abfffffff",
    "crumbs": [
      "Tutorials",
      "Grid Generation Tutorial"
    ]
  },
  {
    "objectID": "tutorial.grids.html#bing-tile-grid-generator",
    "href": "tutorial.grids.html#bing-tile-grid-generator",
    "title": "Grid Generation Tutorial",
    "section": "Bing Tile Grid Generator",
    "text": "Bing Tile Grid Generator\n\nGenerating grids\nLet us generate grids of zoom_level 12. To learn more about the different resolution, visit: https://docs.microsoft.com/en-us/bingmaps/articles/bing-maps-tile-system\n\nbing_tile_grid_generator = grids.BingTileGridGenerator(12)\n\n\n# slow\nbing_tile_gdf = bing_tile_grid_generator.generate_grid(region3_gdf)\n\nCPU times: user 3.18 s, sys: 52.6 ms, total: 3.23 s\nWall time: 3.24 s\n\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = bing_tile_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\n\n\n\n\nNot exporting geometry\nIf you do not plan to use use geometry, you can pass return_geometry=False to just get a normal pandas DataFrame with the ids.\n\nbing_tile_grid_generator_no_geom = grids.BingTileGridGenerator(\n    12, return_geometry=False\n)\n\n\n# slow\nbing_region3_keys = bing_tile_grid_generator_no_geom.generate_grid(region3_gdf)\n\nCPU times: user 3.18 s, sys: 45.8 ms, total: 3.22 s\nWall time: 3.22 s\n\n\n\nbing_region3_keys.head()\n\n\n\n\n\n\n\n\nquadkey\n\n\n\n\n0\n132303030330\n\n\n1\n132303030331\n\n\n2\n132303030313\n\n\n3\n132303012302\n\n\n4\n132303012031\n\n\n\n\n\n\n\n\n\nConverting quadkey to x,y,z format\nIf you need to convert the quadkey to x,y format, you can pass add_xyz_cols=True to add the x and y columns to the returned dataframe.\n\nbing_tile_grid_generator_add_xyz = grids.BingTileGridGenerator(12, add_xyz_cols=True)\n\n\n# slow\nbing_region3_keys = bing_tile_grid_generator_add_xyz.generate_grid(region3_gdf)\n\nCPU times: user 3.18 s, sys: 40.6 ms, total: 3.22 s\nWall time: 3.22 s\n\n\n\nbing_region3_keys.head()\n\n\n\n\n\n\n\n\nquadkey\nx\ny\nz\ngeometry\n\n\n\n\n0\n132303030330\n3414\n1878\n12\nPOLYGON ((120.05859 14.68988, 120.05859 14.774...\n\n\n1\n132303030331\n3415\n1878\n12\nPOLYGON ((120.14648 14.68988, 120.14648 14.774...\n\n\n2\n132303030313\n3415\n1877\n12\nPOLYGON ((120.14648 14.77488, 120.14648 14.859...\n\n\n3\n132303012302\n3412\n1869\n12\nPOLYGON ((119.88281 15.45368, 119.88281 15.538...\n\n\n4\n132303012031\n3411\n1866\n12\nPOLYGON ((119.79492 15.70766, 119.79492 15.792...",
    "crumbs": [
      "Tutorials",
      "Grid Generation Tutorial"
    ]
  },
  {
    "objectID": "tutorial.grids.html#fast-bing-tile-grid-generator",
    "href": "tutorial.grids.html#fast-bing-tile-grid-generator",
    "title": "Grid Generation Tutorial",
    "section": "Fast Bing Tile Grid Generator",
    "text": "Fast Bing Tile Grid Generator\n\nGenerating grids\nLet us generate grids of zoom_level 12 using the FastBingTileGridGenerator. This should run significantly faster than BingTileGridGenerator\n\nfast_bing_tile_grid_generator = grids.FastBingTileGridGenerator(12)\n\n\nfast_bing_tile_gdf = fast_bing_tile_grid_generator.generate_grid(region3_gdf)\n\nCPU times: user 126 ms, sys: 41.9 ms, total: 168 ms\nWall time: 128 ms\n\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = fast_bing_tile_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\n\n\nWe check that BingTileGridGenerator and FastBingTileGridGenerator have an exact match in tiles. Since they use different underlying algorithms, it isn’t a 100% guarantee that they will always have the exact same match in tiles due to floating point differences, but they should be extremely close most of the time.\n\nbing_tile_gdf.shape[0], fast_bing_tile_gdf.shape[0]\n\n(319, 319)\n\n\n\nbool_mask = bing_tile_gdf[\"quadkey\"].isin(fast_bing_tile_gdf[\"quadkey\"])\nassert bool_mask.all()\n\nbool_mask = fast_bing_tile_gdf[\"quadkey\"].isin(bing_tile_gdf[\"quadkey\"])\nassert bool_mask.all()\n\nWe can even use a higher zoom_level, say 17, and FastBingTileGridGenerator will still run significantly faster than BingTileGridGenerator at zoom_level 12 despite the former having ~783 times more grid tiles.\nWe can also pass in a column name to unique_id_col so that the grids can preserve the ID from the AOI. This makes it convenient so you don’t have to do another spatial intersection between the tiles gdf and the AOI gdf to get the AOI IDs.\n\nfast_bing_tile_grid_generator = grids.FastBingTileGridGenerator(17)\n\n\nfast_bing_tile_gdf = fast_bing_tile_grid_generator.generate_grid(region3_gdf, unique_id_col = \"Reg_Name\")\nfast_bing_tile_gdf.head()\n\nCPU times: user 1.82 s, sys: 109 ms, total: 1.93 s\nWall time: 1.86 s\n\n\n\n\n\n\n\n\n\nReg_Name\nquadkey\ngeometry\n\n\n\n\n0\nRegion III\n13230301313023130\nPOLYGON ((120.80292 15.72088, 120.80292 15.723...\n\n\n1\nRegion III\n13230301313233111\nPOLYGON ((120.84961 15.64155, 120.84961 15.644...\n\n\n2\nRegion III\n13230301331132213\nPOLYGON ((120.90454 15.54367, 120.90454 15.546...\n\n\n3\nRegion III\n13230301332000003\nPOLYGON ((120.59143 15.44839, 120.59143 15.451...\n\n\n4\nRegion III\n13230310112103320\nPOLYGON ((122.11578 16.42818, 122.11578 16.430...\n\n\n\n\n\n\n\n\nfast_bing_tile_gdf.shape[0]\n\n249818\n\n\n\n# computes how many more tiles there are in FastBingTileGridGenerator zoom 17 vs BingTileGridGenerator zoom 12\nfast_bing_tile_gdf.shape[0]/bing_region3_keys.shape[0]\n\n783.128526645768",
    "crumbs": [
      "Tutorials",
      "Grid Generation Tutorial"
    ]
  },
  {
    "objectID": "grids.html",
    "href": "grids.html",
    "title": "Grids",
    "section": "",
    "text": "SquareGridGenerator\nThis gridding approach creates equally spaced grids relative to the bounding box of the AOI. The grid spacing is defined by cell_size\n\nsource\n\nSquareGridGenerator\n\n SquareGridGenerator (cell_size:float, grid_projection:str='EPSG:3857', bo\n                      undary:Union[__main__.SquareGridBoundary,List[float]\n                      ,Tuple[float]]=None)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncell_size\nfloat\n\nheight and width of a square cell in meters\n\n\ngrid_projection\nstr\nEPSG:3857\nprojection of grid output\n\n\nboundary\nUnion\nNone\noriginal boundary\n\n\n\n\nsource\n\n\nSquareGridGenerator.create_cell\n\n SquareGridGenerator.create_cell (x:float, y:float)\n\nCreate a square cell based on the bottom left coordinates and cell_size\n\n\n\n\nType\nDetails\n\n\n\n\nx\nfloat\nx coord of bottom left\n\n\ny\nfloat\ny coord of bottom left\n\n\nReturns\nPolygon\n\n\n\n\n\nsource\n\n\nSquareGridGenerator.create_grid_for_polygon\n\n SquareGridGenerator.create_grid_for_polygon (boundary, geometry)\n\n\nsource\n\n\nSquareGridGenerator.generate_grid\n\n SquareGridGenerator.generate_grid\n                                    (aoi_gdf:geopandas.geodataframe.GeoDat\n                                    aFrame)\n\n\n\n\nFastSquareGridGenerator\nThis gridding approach creates equally spaced grids relative to the bounding box of the AOI. The grid spacing is defined by cell_size\nThis is significantly faster than SquareGridGenerator\nThis uses these optimizations to speed up grid generation:\n\nVectorized Translation Functions: Functions that translate between lat,lon and x,y are written in polars.\nVoxel Traversal and Scanline Fill Algorithms: Faster alternative to finding all pixels within a polygon without using polygon intersection operations. These are implemented in polygon_fill.fast_polygon_fill()\n\nThis also does error correction on the polygon boundary using off-boundary pixels. Read more in the polygon fill module reference\n\nsource\n\nFastSquareGridGenerator\n\n FastSquareGridGenerator (cell_size:float,\n                          grid_projection:str='EPSG:3857', boundary:Union[\n                          __main__.SquareGridBoundary,Iterable[float]]=Non\n                          e)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncell_size\nfloat\n\nheight and width of a square cell in meters\n\n\ngrid_projection\nstr\nEPSG:3857\nplanar projection of grid\n\n\nboundary\nUnion\nNone\noriginal boundary\n\n\n\n\nsource\n\n\nFastSquareGridGenerator.generate_grid\n\n FastSquareGridGenerator.generate_grid\n                                        (aoi_gdf:geopandas.geodataframe.Ge\n                                        oDataFrame,\n                                        unique_id_col:Optional[str]=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\naoi_gdf\nGeoDataFrame\n\n\n\n\nunique_id_col\nOptional\nNone\nthe ids under this column will be preserved in the output tiles\n\n\nReturns\nUnion\n\n\n\n\n\n\n\n\nH3GridGenerator\n\nsource\n\nH3GridGenerator\n\n H3GridGenerator (resolution:int, return_geometry:bool=True)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nresolution\nint\n\nResolution of hexagon. See: https://h3geo.org/docs/core-library/restable/ for more info\n\n\nreturn_geometry\nbool\nTrue\nIf geometry should be returned. Setting this to false will only return hex_ids\n\n\n\n\nsource\n\n\nH3GridGenerator.get_hexes_for_polygon\n\n H3GridGenerator.get_hexes_for_polygon\n                                        (poly:shapely.geometry.polygon.Pol\n                                        ygon)\n\n\nsource\n\n\nH3GridGenerator.generate_grid\n\n H3GridGenerator.generate_grid\n                                (aoi_gdf:geopandas.geodataframe.GeoDataFra\n                                me)\n\n\n\n\nBingTileGridGenerator\n\nsource\n\nBingTileGridGenerator\n\n BingTileGridGenerator (zoom_level:int, return_geometry:bool=True,\n                        add_xyz_cols:bool=False)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nzoom_level\nint\n\nZoom level of tile. See: https://docs.microsoft.com/en-us/bingmaps/articles/bing-maps-tile-system for more info\n\n\nreturn_geometry\nbool\nTrue\nIf geometry should be returned. Setting this to false will only return quadkeys\n\n\nadd_xyz_cols\nbool\nFalse\nIf quadkey should be converted to their xyz values.\n\n\n\n\nsource\n\n\nBingTileGridGenerator.get_all_tiles_for_polygon\n\n BingTileGridGenerator.get_all_tiles_for_polygon\n                                                  (polygon:shapely.geometr\n                                                  y.polygon.Polygon)\n\nGet the interseting tiles with polygon for a zoom level. Polygon should be in EPSG:4326\n\nsource\n\n\nBingTileGridGenerator.generate_grid\n\n BingTileGridGenerator.generate_grid\n                                      (aoi_gdf:geopandas.geodataframe.GeoD\n                                      ataFrame)\n\n\nsource\n\n\nBingTileGridGenerator.generate_grid_join\n\n BingTileGridGenerator.generate_grid_join\n                                           (aoi_gdf:geopandas.geodataframe\n                                           .GeoDataFrame,\n                                           filter:bool=True, n_workers=4,\n                                           progress=True)\n\n\n\n\nFastBingTileGridGenerator\nThis is significantly faster than BingTileGridGenerator\nThis uses these optimizations to speed up grid generation:\n\nVectorized Translation Functions: Functions that translate between lat,lon and x,y are written in polars.\nVoxel Traversal and Scanline Fill Algorithms: Faster alternative to finding all pixels within a polygon without using polygon intersection operations. These are implemented in polygon_fill.fast_polygon_fill()\n\nThis also does error correction on the polygon boundary using off-boundary pixels. Read more in the polygon fill module reference\n\nsource\n\nFastBingTileGridGenerator\n\n FastBingTileGridGenerator (zoom_level:int, return_geometry:bool=True,\n                            add_xyz_cols:bool=False)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nzoom_level\nint\n\nZoom level of tile. See: https://docs.microsoft.com/en-us/bingmaps/articles/bing-maps-tile-system for more info\n\n\nreturn_geometry\nbool\nTrue\nIf geometry should be returned. Setting this to false will only return quadkeys\n\n\nadd_xyz_cols\nbool\nFalse\nIf xyz columns should be returned. Unlike BingTileGridGenerator, choosing to return xyz columns doesn’t substantionally add compute time.\n\n\n\n\nsource\n\n\nFastBingTileGridGenerator.generate_grid\n\n FastBingTileGridGenerator.generate_grid\n                                          (aoi_gdf:geopandas.geodataframe.\n                                          GeoDataFrame, unique_id_col:Opti\n                                          onal[str]=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\naoi_gdf\nGeoDataFrame\n\n\n\n\nunique_id_col\nOptional\nNone\nthe ids under this column will be preserved in the output tiles\n\n\nReturns\nUnion",
    "crumbs": [
      "Module Reference",
      "Grids"
    ]
  },
  {
    "objectID": "tutorial.area_zonal_stats.html",
    "href": "tutorial.area_zonal_stats.html",
    "title": "Vector Area Zonal Stats Tutorial",
    "section": "",
    "text": "A basic introduction to vector area zonal stats",
    "crumbs": [
      "Tutorials",
      "Vector Area Zonal Stats Tutorial"
    ]
  },
  {
    "objectID": "tutorial.area_zonal_stats.html#basic-usage",
    "href": "tutorial.area_zonal_stats.html#basic-usage",
    "title": "Vector Area Zonal Stats Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nGenerate area zonal stats for a GeoDataframe containing areas of interest with a vector data source containing areas associated with statistics.\n\n\n\n\n\n\nNote\n\n\n\nThe assumption for the data is that the statistics are uniformly distributed over the entire area for each row in the data source.\n\n\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport geowrangler.area_zonal_stats as azs\n\n\nSimple Grid AOIs and Data\n\nsimple_aoi = gpd.read_file(\"../data/simple_planar_aoi.geojson\")\nsimple_data = gpd.read_file(\"../data/simple_planar_data.geojson\")\n\nGiven an AOI (simple_aoi) and geodataframe containing sample data (simple_data)\n\nsimple_aoi\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n\n\n\n\n\n\n\n\nsimple_data\n\n\n\n\n\n\n\n\npopulation\ninternet_speed\ngeometry\n\n\n\n\n0\n100\n20.0\nPOLYGON ((0.25 0, 0.25 1, 1.25 1, 1.25 0, 0.25...\n\n\n1\n200\n10.0\nPOLYGON ((1.25 0, 1.25 1, 2.25 1, 2.25 0, 1.25...\n\n\n2\n300\n5.0\nPOLYGON ((2.25 0, 2.25 1, 3.25 1, 3.25 0, 2.25...\n\n\n\n\n\n\n\nIn order correctly apportion the statistic, we need to make sure that the AOI and data geodataframes are using a planar CRS (i.e., gdf.crs.is_geographic == False)\n\nsimple_aoi.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nsimple_data.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nax = plt.axes()\nax = simple_data.plot(\n    ax=ax, color=[\"orange\", \"brown\", \"purple\"], edgecolor=\"yellow\", alpha=0.4\n)\nax = simple_aoi.plot(ax=ax, facecolor=\"none\", edgecolor=[\"r\", \"g\", \"b\"])\n\n\n\n\n\n\n\n\nThe red, green, and blue outlines are the 3 regions of interest (AOI) while the orange, brown, and purple areas are the data areas.\n\nempty_aoi_results = azs.create_area_zonal_stats(simple_aoi, simple_data)\n\nIf no aggregations are specified, the include_intersect=True arg specifies that the sum of the data areas intersecting our AOI is computed in the column intersect_area_sum.\n\nempty_aoi_results\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n0.75\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n1.00\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n1.00\n\n\n\n\n\n\n\n\nApportioning aggregated statistics\nTo aggregate statistics over the AOI areas intersecting with the data areas, the default behavior of “apportioning” the statistic over the intersection of the data area overlapping the AOI area depends on the statistic.\n\nFor sum it apportions the total value of the statistic over the proportion of the data area overlapping the AOI area divided by the total area of the data.\nFor mean it apportions the total value of the statistic over the proportion of the data area overlapping the AOI area divided by the total area of the aoi.\nFor other statistics, there is no apportioning done and uses the raw statistics from the data areas overlapping the AOI area.\n\n\n\n\n\n\n\nNote\n\n\n\nThis default behavior can be overridden by specifying a prefix (e.g., raw_, data_, and aoi_) to the statistic (i.e., func) – e.g. if you wish the apportion the sum as a proportion of the aoi area instead of the data area, specify the func as aoi_sum instead of sum.\n\n\n\nsimple_aoi_results = azs.create_area_zonal_stats(\n    simple_aoi,\n    simple_data,\n    [\n        dict(func=[\"sum\", \"count\"], column=\"population\"),\n        dict(func=[\"mean\", \"max\", \"min\", \"std\"], column=\"internet_speed\"),\n    ],\n)\n\nCPU times: user 10.9 ms, sys: 1.13 ms, total: 12 ms\nWall time: 11.3 ms\n\n\n\nsimple_aoi_results\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\npopulation_sum\npopulation_count\ninternet_speed_mean\ninternet_speed_max\ninternet_speed_min\ninternet_speed_std\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n0.75\n75.0\n1\n15.000\n20.0\n0.0\nNaN\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n1.00\n175.0\n2\n6.250\n20.0\n10.0\n7.071068\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n1.00\n275.0\n2\n3.125\n10.0\n5.0\n3.535534\n\n\n\n\n\n\n\n\nsimple_aoi_results.population_sum.sum(axis=None)\n\nnp.float64(525.0)\n\n\nNote the value of the mean of the internet speed for the 1st area above.\nWhile there is one data area overlapping with an internet speed of 20.0 the computed aggregate statistic for the mean is 15.0 due to the apportioning which only accounts for 0.75 (the total AOI area is 1.0) – meaning it assigns a value of 0.0 for the 0.25 area with no overlapping data area.\nIf you wish to override this behavior and impute the value of the statistic as the means of all the overlapping areas (in proportion to the overlap of their area over the total area of the AOI), you can additionally add a prefix of imputed_ as shown in the next example. Note that adding a prefix doesn’t change the default output column name, which is why we explicitly specified an output column name (internet_speed_imputed_mean in order to differentiate it from the original internet_speed_mean column.\nNotice as well that adding a raw_ prefix to the min,max,std statistics doesn’t change their values since by default these statistics don’t use any apportioning (so specifying raw_ is redundant in this case).\nLastly, check the effect of setting of the fix_min arg to False (the default value is True) – since it uses the raw column to compute the min, it is not aware that there are areas in the AOI that have no overlapping data areas and uses the min value from the overlapping areas (in this case, since there is only 1 partially overlapping area, it uses that as the min value). The fix_min arg “fixes” this by checking if the data areas completely overlap the AOI area and sets the minimum to 0 if there is a portion of the AOI area that is not completely intersected by a data area.\n\ncorrected_aoi_results = azs.create_area_zonal_stats(\n    simple_aoi,\n    simple_data,\n    [\n        dict(func=[\"sum\", \"count\"], column=\"population\"),\n        dict(\n            func=[\"mean\", \"imputed_mean\", \"raw_max\", \"raw_min\", \"raw_std\"],\n            column=\"internet_speed\",\n            output=[\n                \"internet_speed_mean\",\n                \"internet_speed_imputed_mean\",\n                \"internet_speed_max\",\n                \"internet_speed_min\",\n                \"internet_speed_std\",\n            ],\n        ),\n    ],\n    fix_min=False,\n)\n\nCPU times: user 12.6 ms, sys: 908 µs, total: 13.5 ms\nWall time: 13.5 ms\n\n\n\ncorrected_aoi_results\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\npopulation_sum\npopulation_count\ninternet_speed_mean\ninternet_speed_imputed_mean\ninternet_speed_max\ninternet_speed_min\ninternet_speed_std\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n0.75\n75.0\n1\n15.000\n20.000\n20.0\n20.0\nNaN\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n1.00\n175.0\n2\n6.250\n6.250\n20.0\n10.0\n7.071068\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n1.00\n275.0\n2\n3.125\n3.125\n10.0\n5.0\n3.535534\n\n\n\n\n\n\n\n\n\n\nCustom Grids over admin area data\n\nAnother example using aggregated statistics over admin areas (barangay level) that are apportioned into grid areas by their overlap.\n\n\nNotice that since the grid areas does not completely overlap the admin areas (and vice versa) , the sum of their total populations and land areas are not equal.\n\n\nregion3_admin_grids = gpd.read_file(\"../data/region3_admin_grids.geojson\")\nregion3_admin_grids = region3_admin_grids.to_crs(\"EPSG:3857\")  # convert to planar\n\nCPU times: user 18.8 ms, sys: 1.53 ms, total: 20.4 ms\nWall time: 20.5 ms\n\n\n\nregion3_pop_bgy_level = gpd.read_file(\"../data/region3_population_bgy_level.geojson\")\n\nCPU times: user 139 ms, sys: 2.86 ms, total: 142 ms\nWall time: 142 ms\n\n\n\naoi_result = azs.create_area_zonal_stats(\n    region3_admin_grids,\n    region3_pop_bgy_level,\n    [\n        dict(func=[\"sum\", \"count\"], column=\"population\"),\n    ],\n)\n\nCPU times: user 270 ms, sys: 3.53 ms, total: 274 ms\nWall time: 275 ms\n\n\n\naoi_result\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nintersect_area_sum\npopulation_sum\npopulation_count\n\n\n\n\n0\n0\n30\nPOLYGON ((13334497.956 1771012.807, 13339497.9...\n1.213773e+06\n687.832840\n1\n\n\n1\n0\n31\nPOLYGON ((13334497.956 1776012.807, 13339497.9...\n2.471924e+06\n986.890853\n1\n\n\n2\n0\n32\nPOLYGON ((13334497.956 1781012.807, 13339497.9...\n2.748813e+06\n1097.435840\n1\n\n\n3\n1\n30\nPOLYGON ((13339497.956 1771012.807, 13344497.9...\n1.081669e+06\n468.368614\n2\n\n\n4\n1\n32\nPOLYGON ((13339497.956 1781012.807, 13344497.9...\n8.941593e+04\n8.570604\n2\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n1069\n54\n44\nPOLYGON ((13604497.956 1841012.807, 13609497.9...\n1.976718e+05\n15.398162\n1\n\n\n1070\n54\n45\nPOLYGON ((13604497.956 1846012.807, 13609497.9...\n1.019141e+07\n1613.913393\n3\n\n\n1071\n54\n46\nPOLYGON ((13604497.956 1851012.807, 13609497.9...\n3.129991e+06\n1033.997979\n2\n\n\n1072\n54\n47\nPOLYGON ((13604497.956 1856012.807, 13609497.9...\n8.106461e+06\n250.893691\n2\n\n\n1073\n54\n48\nPOLYGON ((13604497.956 1861012.807, 13609497.9...\n1.928818e+07\n299.377987\n3\n\n\n\n\n1074 rows × 6 columns\n\n\n\n\n(\n    aoi_result.geometry.area.sum(),\n    aoi_result.intersect_area_sum.sum(),\n    aoi_result.population_sum.sum(),\n)\n\n(np.float64(26850000000.000042),\n np.float64(24548891899.414997),\n np.float64(12136959.090018272))\n\n\n\n(region3_pop_bgy_level.geometry.area.sum(), region3_pop_bgy_level.population.sum())\n\n(np.float64(27658006631.682587), np.int64(13139695))\n\n\n\ngdf = region3_admin_grids\ngdf2 = region3_pop_bgy_level\n\n\nax = plt.axes()\nax = gdf2.plot(ax=ax, column=\"population\", alpha=0.4)\nax = gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\", alpha=0.4)\n\n\n\n\n\n\n\n\n\nax = plt.axes()\nax = gdf2.plot(ax=ax, facecolor=\"none\", alpha=0.4, edgecolor=\"red\")\nax = aoi_result.plot(column=\"population_sum\", ax=ax, alpha=0.4, edgecolor=\"blue\")\n\n\n\n\n\n\n\n\n\nax = plt.axes()\nax = gdf2.plot(ax=ax, column=\"population\", alpha=0.4, edgecolor=\"red\")\nax = aoi_result.plot(column=\"intersect_area_sum\", ax=ax, alpha=0.4, edgecolor=\"blue\")",
    "crumbs": [
      "Tutorials",
      "Vector Area Zonal Stats Tutorial"
    ]
  },
  {
    "objectID": "datasets_nightlights.html",
    "href": "datasets_nightlights.html",
    "title": "Night Lights",
    "section": "",
    "text": "source\n\nget_eog_access_token\n\n get_eog_access_token (username, password, save_token=False,\n                       save_path='~/.eog_creds/eog_access_token',\n                       set_env=True, env_token_var='EOG_ACCESS_TOKEN')\n\n\nsource\n\n\nclear_eog_access_token\n\n clear_eog_access_token (save_file='~/.eog_creds/eog_access_token',\n                         env_var='EOG_ACCESS_TOKEN', clear_file=True,\n                         clear_env=True)\n\n\nsource\n\n\nsetup_eog_auth_headers\n\n setup_eog_auth_headers (headers, access_token, env_var, creds_file)\n\n\nsource\n\n\ndownload_url\n\n download_url (url, dest=None, access_token=None, headers=None,\n               timeout=None, show_progress=True, chunksize=1048576,\n               env_var='EOG_ACCESS_TOKEN',\n               creds_file='~/.eog_creds/eog_access_token')\n\nDownload url to dest and show progress\n\nsource\n\n\nunzip_eog_gzip\n\n unzip_eog_gzip (gz_file, dest=None, delete_src=False)\n\n\nsource\n\n\nclip_raster\n\n clip_raster (input_raster_file, dest, bounds, buffer=None)\n\n\nsource\n\n\nmake_url\n\n make_url (year, viirs_data_type='average',\n           ntlights_base_url='https://eogdata.mines.edu/nighttime_light',\n           version='v21', product='annual', coverage='global',\n           process_suffix='c202205302300', vcmcfg='vcmslcfg')\n\n\nsource\n\n\nmake_clip_hash\n\n make_clip_hash (year, bounds, viirs_data_type='average', version='v21',\n                 product='annual', coverage='global',\n                 process_suffix='c202205302300', vcmcfg='vcmslcfg')\n\n\nsource\n\n\ngenerate_clipped_raster\n\n generate_clipped_raster (year, bounds, dest, viirs_data_type='average',\n                          version='v21', product='annual',\n                          coverage='global',\n                          cache_dir='~/.cache/geowrangler/nightlights',\n                          process_suffix='c202205302300',\n                          vcmcfg='vcmslcfg')\n\n\nsource\n\n\ngenerate_clipped_metadata\n\n generate_clipped_metadata (year, bounds, viirs_data_type, version,\n                            product, coverage, clip_cache_dir,\n                            process_suffix, vcmcfg)\n\n\nsource\n\n\nget_clipped_raster\n\n get_clipped_raster (year, bounds, viirs_data_type='average',\n                     version='v21', product='annual', coverage='global',\n                     cache_dir='~/.cache/geowrangler/nightlights',\n                     process_suffix='c202205302300', vcmcfg='vcmslcfg')",
    "crumbs": [
      "Module Reference",
      "Night Lights"
    ]
  },
  {
    "objectID": "raster_process.html",
    "href": "raster_process.html",
    "title": "Raster Processing",
    "section": "",
    "text": "source",
    "crumbs": [
      "Module Reference",
      "Raster Processing"
    ]
  },
  {
    "objectID": "raster_process.html#download-raster",
    "href": "raster_process.html#download-raster",
    "title": "Raster Processing",
    "section": "Download raster",
    "text": "Download raster\n\ninput_image = \"../data/phl_ppp_2020_constrained.tif\"\n\n\nraster = rio.open(input_image)\nraster.meta\n\n{'driver': 'GTiff',\n 'dtype': 'float32',\n 'nodata': -99999.0,\n 'width': 11613,\n 'height': 19781,\n 'count': 1,\n 'crs': CRS.from_epsg(4326),\n 'transform': Affine(0.0008333333299750276, 0.0, 116.927916214,\n        0.0, -0.0008333333300136493, 21.070416784)}\n\n\n\nshow(raster.read(1), cmap=\"plasma\", transform=raster.transform)",
    "crumbs": [
      "Module Reference",
      "Raster Processing"
    ]
  },
  {
    "objectID": "raster_process.html#define-bounding-box",
    "href": "raster_process.html#define-bounding-box",
    "title": "Raster Processing",
    "section": "Define bounding box",
    "text": "Define bounding box\n\nbbox = (120.888062, 14.394778, 121.199112, 14.705822)\n\n\ncircle_gdf\n\n\n\n\n\n\n\n\nlat\nlon\ngeometry\n\n\n\n\n0\n14.599512\n120.984222\nPOLYGON ((121.98422 14.59951, 121.97941 14.501...\n\n\n\n\n\n\n\n\nprint(circle_gdf.crs)\n\nepsg:4326\n\n\n\nfig, ax = plt.subplots(1, 1, figsize=(4, 8))\nshow(raster.read(1), cmap=\"viridis\", ax=ax, transform=raster.transform)\ncircle_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"yellow\")\n\nax",
    "crumbs": [
      "Module Reference",
      "Raster Processing"
    ]
  },
  {
    "objectID": "raster_process.html#crop-a-raster-without-masking",
    "href": "raster_process.html#crop-a-raster-without-masking",
    "title": "Raster Processing",
    "section": "Crop a raster without masking",
    "text": "Crop a raster without masking\n\noutput_folder = Path(\"../data\")\n\n\nquery_window_by_gdf(input_image, output_folder, circle_gdf, mask=False)\n\n../data/output_0.tif\n\n\n\nwith rio.open(output_folder / \"output_0.tif\") as dst:\n    fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n\n    show(dst.read(1), cmap=\"viridis\", ax=ax, transform=dst.transform)\n    circle_gdf.plot(facecolor=\"none\", edgecolor=\"yellow\", ax=ax)\n    print(dst.read(1))\nax\n\n[[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n ...\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]]",
    "crumbs": [
      "Module Reference",
      "Raster Processing"
    ]
  },
  {
    "objectID": "raster_process.html#crop-a-raster-with-masking",
    "href": "raster_process.html#crop-a-raster-with-masking",
    "title": "Raster Processing",
    "section": "Crop a raster with masking",
    "text": "Crop a raster with masking",
    "crumbs": [
      "Module Reference",
      "Raster Processing"
    ]
  },
  {
    "objectID": "raster_process.html#crop-on-multiple-geometries-at-once",
    "href": "raster_process.html#crop-on-multiple-geometries-at-once",
    "title": "Raster Processing",
    "section": "Crop on multiple geometries at once",
    "text": "Crop on multiple geometries at once\n\ngrid_generator = grids.SquareGridGenerator(100_000)\n\n\ngrid_gdf = grid_generator.generate_grid(circle_gdf)\ngrid_gdf[\"name\"] = (\n    \"gridxy-\" + grid_gdf[\"x\"].astype(str) + \"-\" + grid_gdf[\"y\"].astype(str)\n)\n\n\ngrid_gdf\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nname\n\n\n\n\n0\n0\n0\nPOLYGON ((119.98422 13.59951, 120.88254 13.599...\ngridxy-0-0\n\n\n1\n0\n1\nPOLYGON ((119.98422 14.47100, 120.88254 14.471...\ngridxy-0-1\n\n\n2\n0\n2\nPOLYGON ((119.98422 15.33908, 120.88254 15.339...\ngridxy-0-2\n\n\n3\n1\n0\nPOLYGON ((120.88254 13.59951, 121.78085 13.599...\ngridxy-1-0\n\n\n4\n1\n1\nPOLYGON ((120.88254 14.47100, 121.78085 14.471...\ngridxy-1-1\n\n\n5\n1\n2\nPOLYGON ((120.88254 15.33908, 121.78085 15.339...\ngridxy-1-2\n\n\n6\n2\n0\nPOLYGON ((121.78085 13.59951, 122.67917 13.599...\ngridxy-2-0\n\n\n7\n2\n1\nPOLYGON ((121.78085 14.47100, 122.67917 14.471...\ngridxy-2-1\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(1, 1, figsize=(4, 8))\nshow(raster.read(1), cmap=\"viridis\", ax=ax, transform=raster.transform)\ngrid_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"yellow\")\n\nax\n\n\n\n\n\n\n\n\n\nquery_window_by_gdf(input_image, output_folder, grid_gdf, name_col=\"name\", mask=False)\n\n../data/gridxy-0-0.tif\n../data/gridxy-0-1.tif\n../data/gridxy-0-2.tif\n../data/gridxy-1-0.tif\n../data/gridxy-1-1.tif\n../data/gridxy-1-2.tif\n../data/gridxy-2-0.tif\n../data/gridxy-2-1.tif\n\n\n\nfor name in grid_gdf[\"name\"]:\n    image_path = output_folder / (name + \".tif\")\n    with rio.open(image_path) as dst:\n        fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n        ax.set_title(image_path)\n        show(dst.read(1), cmap=\"viridis\", ax=ax, transform=dst.transform)",
    "crumbs": [
      "Module Reference",
      "Raster Processing"
    ]
  },
  {
    "objectID": "validation.html",
    "href": "validation.html",
    "title": "Geometry Validation",
    "section": "",
    "text": "source\n\nValidationError\nCommon base class for all non-exit exceptions.\n\nsource\n\n\nBaseValidator\n\n BaseValidator (add_new_column:bool=True, apply_fix:bool=True)\n\nAbstract Base Class for single validator\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_new_column\nbool\nTrue\nAdd new column to show errors\n\n\napply_fix\nbool\nTrue\nUpdate geometry\n\n\n\n\nsource\n\n\nBaseValidator.validate\n\n BaseValidator.validate (gdf:geopandas.geodataframe.GeoDataFrame,\n                         clone=True)\n\nMethod that checks the validity of a each geometry and applies a fix to these geometries or raise a warning\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngdf\nGeoDataFrame\n\nGeoDataFrame to validate\n\n\nclone\nbool\nTrue\nApply validation to copy\n\n\nReturns\nGeoDataFrame\n\n\n\n\n\n\nsource\n\n\nOrientationValidator\n\n OrientationValidator (add_new_column:bool=True, apply_fix:bool=True)\n\nChecks and fixes Orientation of the geometry to ensure it follows a counter-clockwise orientation\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_new_column\nbool\nTrue\nAdd new column to show errors\n\n\napply_fix\nbool\nTrue\nUpdate geometry\n\n\n\n\nsource\n\n\nOrientationValidator.check\n\n OrientationValidator.check (geometry:shapely.geometry.base.BaseGeometry)\n\nChecks if orientation is counter clockwise\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to validate\n\n\nReturns\nbool\n\n\n\n\n\nsource\n\n\nOrientationValidator.fix\n\n OrientationValidator.fix (geometry:shapely.geometry.base.BaseGeometry)\n\nFixes orientation if orientation is clockwise\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to fix\n\n\nReturns\nBaseGeometry\n\n\n\n\n\nsource\n\n\nCrsBoundsValidator\n\n CrsBoundsValidator (add_new_column:bool=True, apply_fix:bool=True)\n\nChecks bounds of the geometry to ensure it is within bounds of the crs\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_new_column\nbool\nTrue\nAdd new column to show errors\n\n\napply_fix\nbool\nTrue\nUpdate geometry\n\n\n\n\nsource\n\n\nCrsBoundsValidator.get_check_arguments\n\n CrsBoundsValidator.get_check_arguments\n                                         (gdf:geopandas.geodataframe.GeoDa\n                                         taFrame)\n\nReturn check arguments\n\n\n\n\nType\nDetails\n\n\n\n\ngdf\nGeoDataFrame\nGeoDataFrame to check\n\n\nReturns\ndict\n\n\n\n\n\nsource\n\n\nCrsBoundsValidator.check\n\n CrsBoundsValidator.check (geometry:shapely.geometry.base.BaseGeometry,\n                           gdf:geopandas.geodataframe.GeoDataFrame)\n\nChecks if polygon is within bounds of crs.\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to validate\n\n\ngdf\nGeoDataFrame\nGeoDataframe to check\n\n\nReturns\nbool\n\n\n\n\n\nsource\n\n\nCrsBoundsValidator.fix\n\n CrsBoundsValidator.fix (geometry:shapely.geometry.base.BaseGeometry)\n\nNo fix available\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to fix\n\n\nReturns\nBaseGeometry\npragma: no cover\n\n\n\n\nsource\n\n\nSelfIntersectingValidator\n\n SelfIntersectingValidator (add_new_column:bool=True, apply_fix:bool=True)\n\nChecks bounds of the geometry to ensure it is within bounds or crs\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_new_column\nbool\nTrue\nAdd new column to show errors\n\n\napply_fix\nbool\nTrue\nUpdate geometry\n\n\n\n\nsource\n\n\nSelfIntersectingValidator.check\n\n SelfIntersectingValidator.check\n                                  (geometry:shapely.geometry.base.BaseGeom\n                                  etry)\n\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to check\n\n\nReturns\nbool\n\n\n\n\n\nsource\n\n\nSelfIntersectingValidator.fix\n\n SelfIntersectingValidator.fix\n                                (geometry:shapely.geometry.base.BaseGeomet\n                                ry)\n\nFix intersection geometry by applying shapely.validation.make_valid\n\nsource\n\n\nNullValidator\n\n NullValidator (add_new_column:bool=True, apply_fix:bool=True)\n\nChecks bounds of the geometry to ensure it is within bounds or crs\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_new_column\nbool\nTrue\nAdd new column to show errors\n\n\napply_fix\nbool\nTrue\nUpdate geometry\n\n\n\n\nsource\n\n\nNullValidator.check\n\n NullValidator.check (geometry:shapely.geometry.base.BaseGeometry)\n\nChecks if polygon is null\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\n\n\n\nReturns\nbool\nGeometry to check\n\n\n\n\nsource\n\n\nNullValidator.fix\n\n NullValidator.fix (geometry:shapely.geometry.base.BaseGeometry)\n\nNo fix available\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to fix\n\n\nReturns\nBaseGeometry\npragma: no cover\n\n\n\n\nsource\n\n\nAreaValidator\n\n AreaValidator (add_new_column:bool=True, apply_fix:bool=True)\n\nChecks area of the geometry to ensure it greater than 0\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_new_column\nbool\nTrue\nAdd new column to show errors\n\n\napply_fix\nbool\nTrue\nUpdate geometry\n\n\n\n\nsource\n\n\nAreaValidator.check\n\n AreaValidator.check (geometry:shapely.geometry.base.BaseGeometry)\n\nChecks if area is greater than 0\n\nsource\n\n\nAreaValidator.fix\n\n AreaValidator.fix (geometry:shapely.geometry.base.BaseGeometry)\n\nNo fix available\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to fix\n\n\nReturns\nBaseGeometry\npragma: no cover\n\n\n\n\nsource\n\n\nGeometryValidation\n\n GeometryValidation (gdf:geopandas.geodataframe.GeoDataFrame,\n                     validators:Sequence[Union[str,__main__.BaseValidator]\n                     ]=('null', 'self_intersecting', 'orientation',\n                     'crs_bounds', 'area'),\n                     add_validation_columns:bool=True,\n                     apply_fixes:bool=True)\n\nApplies a list of validation checks and tries to fix them\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngdf\nGeoDataFrame\n\nGeoDataFrame to validate\n\n\nvalidators\nSequence\n(‘null’, ‘self_intersecting’, ‘orientation’, ‘crs_bounds’, ‘area’)\nValidators to apply\n\n\nadd_validation_columns\nbool\nTrue\nAdd column to show errors\n\n\napply_fixes\nbool\nTrue\nUpdate geometry\n\n\nReturns\nGeoDataFrame\n\n\n\n\n\n\nsource\n\n\nGeometryValidation.validate_all\n\n GeometryValidation.validate_all ()\n\nSequentially run validators",
    "crumbs": [
      "Module Reference",
      "Geometry Validation"
    ]
  },
  {
    "objectID": "datasets_geofabrik.html",
    "href": "datasets_geofabrik.html",
    "title": "Datasets Geofabrik",
    "section": "",
    "text": "source\n\nlist_geofabrik_regions\n\n list_geofabrik_regions ()\n\nGet list of regions from geofabrik index\n\nsource\n\n\nget_osm_download_url\n\n get_osm_download_url (region, year=None)\n\n\nsource\n\n\nget_download_filepath\n\n get_download_filepath (url, directory)\n\n\nsource\n\n\ndownload_geofabrik_region\n\n download_geofabrik_region (region:str, directory:str='data/',\n                            overwrite=False, year=None,\n                            show_progress=True, chunksize=8192)\n\nDownload geofabrik region to path\n\nsource\n\n\ndownload_osm_region_data\n\n download_osm_region_data (region, year=None,\n                           cache_dir='~/.cache/geowrangler',\n                           use_cache=True, chunksize=8192,\n                           show_progress=True)\n\n\nsource\n\n\nOsmDataManager\n\n OsmDataManager (cache_dir='~/.cache/geowrangler')\n\nAn instance of this class provides convenience functions for loading and caching OSM data\n\nsource\n\n\nOsmDataManager.load_pois\n\n OsmDataManager.load_pois (region, year=None, use_cache=True,\n                           chunksize=1048576, show_progress=True)\n\n\nsource\n\n\nOsmDataManager.load_roads\n\n OsmDataManager.load_roads (region, year=None, use_cache=True,\n                            chunksize=1048576, show_progress=True)",
    "crumbs": [
      "Module Reference",
      "Datasets Geofabrik"
    ]
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Geowrangler",
    "section": "",
    "text": "Overview\n  \nGeowrangler is a Python package for geodata wrangling. It helps you build data transformation workflows that have no out-of-the-box solutions from other geospatial libraries.\nWe surveyed our past geospatial projects to extract these solutions for our work and hope that these will be useful for others as well.\nOur audience are researchers, analysts, and engineers delivering geospatial projects.\nWe welcome your comments, suggestions, bug reports, and code contributions to make Geowrangler better.\n\n\nInstallation\npip install geowrangler\n\n\nDocumentation\nPlease visit our Documentation site to give you an introduction to Geowrangler.\n\n\nDevelopment and Contributing\nPlease checkout the DEVELOPMENT and the CONTRIBUTING sections to learn how to contribute, enhance, and fix Geowrangler."
  },
  {
    "objectID": "tutorial.spatialjoin_highest_intersection.html",
    "href": "tutorial.spatialjoin_highest_intersection.html",
    "title": "Spatial Join Using Highest Intersection Tutorial",
    "section": "",
    "text": "A basic introduction to using spatial join using highest intersection",
    "crumbs": [
      "Tutorials",
      "Spatial Join Using Highest Intersection Tutorial"
    ]
  },
  {
    "objectID": "tutorial.spatialjoin_highest_intersection.html#summary",
    "href": "tutorial.spatialjoin_highest_intersection.html#summary",
    "title": "Spatial Join Using Highest Intersection Tutorial",
    "section": "Summary",
    "text": "Summary\nJoins attributes of two tables based on largest area of overlap. Usage of this function assumes that the two datasets are both vector polygon data.",
    "crumbs": [
      "Tutorials",
      "Spatial Join Using Highest Intersection Tutorial"
    ]
  },
  {
    "objectID": "tutorial.spatialjoin_highest_intersection.html#how-does-it-work",
    "href": "tutorial.spatialjoin_highest_intersection.html#how-does-it-work",
    "title": "Spatial Join Using Highest Intersection Tutorial",
    "section": "How does it work?",
    "text": "How does it work?\nSpatial join using highest intersection works by assigning a unique ID to the first dataframe (gdf1) and using its geometry as basis for the intersection. Data from the second dataframe (gdf2), apart from its geometry, is retained in the output.\n\nget_highest_intersection (gdf1, gdf2, proj_crs)\n\n\n\n\n\n\n\n\n\n\n\ntype\ndefault\noptional/ required\ndetails\n\n\n\n\ngdf1\nGeoDataFrame\nnone\nrequired\nbasis of output geometry\n\n\ngdf2\nGeoDataFrame\nnone\nrequired\ndata to be included during intersection\n\n\nproj_crs\nString\nnone\nrequired\nmetric CRS (e.g., Philippines uses EPSG:32651)\n\n\n\nA technical step-by-step explanation of how get_highest_intersection works is detailed in the cell blocks below. An example on how to use it with its arguments is shown in the sample use case section thereafter.\n\nDefine the function and its arguments.\n\ndef get_highest_intersection(\n    gdf1: gpd.GeoDataFrame,\n    gdf2: gpd.GeoDataFrame,\n    proj_crs: str,\n) -&gt; gpd.GeoDataFrame:\n\nCreate a copy of the two geodataframes.\n\n    gdf1 = gdf1.copy()\n    gdf2 = gdf2.copy()\n\nRename new columns with “__” prefixes and suffixes to prevent overwriting existing columns in the original geodataframes.\n\n    uid_col = \"__uid__\"\n    area_col = \"__area_highest_intersection__\"\n    auxiliary_cols = [uid_col, area_col]\n\nConduct checks to make sure we are not overwriting existing columns.\n\n    for col in auxiliary_cols:\n        if col in gdf1.columns:\n            raise ValueError(f\"Make sure {col} isn't already a column in gdf1\")\n        if col in gdf2.columns:\n            raise ValueError(f\"Make sure {col} isn't already a column in gdf2\")\n\nAssign a unique ID to the first geodataframe. Note that uid_col is also defined in Step 2.\n\n    gdf1[uid_col] = range(len(gdf1))\n\nGet intersection of the geodataframes.\n\n    overlay = gdf1.overlay(gdf2, how=\"intersection\")\n\nAdd a column for overlapping area. Note that area_col is also defined in Step 2.\n\n    overlay[\"geometry\"] = overlay[\"geometry\"].to_crs(proj_crs)\n    overlay[area_col] = (overlay.geometry.area)\n\nSort values by area. Drop duplicates and null values.\n\n    overlay = overlay.sort_values(by=area_col, ascending=True)\n    overlay = overlay.drop_duplicates(subset=[uid_col], keep=\"last\")\n    overlay = overlay.dropna(subset=[uid_col])\n    assert not overlay[uid_col].duplicated().any()\n    overlay = overlay.sort_values(by=[uid_col], ascending=True)\n\nDrop geometry from the overlay dataframe and merge the original geometry from gdf1. Also drop additional columns (uid_col, area_col) used to accomplish calculate overlapping area for the function.\n\n    overlay_merge = overlay.drop(\"geometry\", axis=1)\n\n    output = pd.merge(\n        left=gdf1[[uid_col, \"geometry\"]],\n        right=overlay_merge,\n        on=uid_col,\n        how=\"left\",\n        validate=\"one_to_one\",\n    )\n\n    output = output.drop(columns=auxiliary_cols)\n\nDrop the additional columns (uid_col, area_col) and return the final output.\n\n    return output",
    "crumbs": [
      "Tutorials",
      "Spatial Join Using Highest Intersection Tutorial"
    ]
  },
  {
    "objectID": "tutorial.spatialjoin_highest_intersection.html#sample-use-case---labeling-grid-with-administrative-boundaries",
    "href": "tutorial.spatialjoin_highest_intersection.html#sample-use-case---labeling-grid-with-administrative-boundaries",
    "title": "Spatial Join Using Highest Intersection Tutorial",
    "section": "Sample use case - Labeling grid with administrative boundaries",
    "text": "Sample use case - Labeling grid with administrative boundaries\nInput: - grid - GeoDataFrame that will become the basis of geometries for the output - adm_bounds - GeoDataFrame containing attributes that we want to append to the grid - proj_crs - metric coordinate reference system (e.g., “EPSG:32651” for the Philippines)\nOutput - grid with one province name per cell\n\nStep 1: Import package\n\nimport geopandas as gpd\nimport geowrangler.grids as grids\n\n\nimport geowrangler.spatialjoin_highest_intersection as spatial_join\n\n\n\nStep 2: Load the first dataset (grid)\nThis dataset will become the basis of geometry for the output.\n\ngrid\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n3\n3\nPOLYGON ((118.27581 5.92871, 118.72497 5.92871...\n\n\n1\n2\n3\nPOLYGON ((117.82665 5.92871, 118.27581 5.92871...\n\n\n2\n3\n4\nPOLYGON ((118.27581 6.37528, 118.72497 6.37528...\n\n\n3\n3\n5\nPOLYGON ((118.27581 6.82146, 118.72497 6.82146...\n\n\n4\n0\n6\nPOLYGON ((116.92834 7.26723, 117.37749 7.26723...\n\n\n...\n...\n...\n...\n\n\n318\n19\n1\nPOLYGON ((125.46233 5.03451, 125.91149 5.03451...\n\n\n319\n19\n12\nPOLYGON ((125.46233 9.93163, 125.91149 9.93163...\n\n\n320\n19\n13\nPOLYGON ((125.46233 10.37375, 125.91149 10.373...\n\n\n321\n20\n12\nPOLYGON ((125.91149 9.93163, 126.36065 9.93163...\n\n\n322\n20\n13\nPOLYGON ((125.91149 10.37375, 126.36065 10.373...\n\n\n\n\n323 rows × 3 columns\n\n\n\n\ngrid.plot(facecolor=\"none\", edgecolor=\"blue\");\n\n\n\n\n\n\n\n\n\n# grid.explore()\n\n\n\nStep 3: Load the second dataset (admin_bounds)\nInfo from this dataset (apart from geometry) will be appended to the output based on highest spatial intersection.\n\nadmin_bounds\n\n\n\n\n\n\n\n\nshapeName\nshapeISO\nshapeID\nshapeGroup\nshapeType\ngeometry\n\n\n\n\n0\nAbra\nNone\nPHL-ADM2-3_0_0-B1\nPHL\nADM2\nMULTIPOLYGON (((120.96795 17.95706, 120.97803 ...\n\n\n1\nAgusan del Norte\nNone\nPHL-ADM2-3_0_0-B2\nPHL\nADM2\nMULTIPOLYGON (((125.57724 9.45679, 125.59687 9...\n\n\n2\nAgusan del Sur\nNone\nPHL-ADM2-3_0_0-B3\nPHL\nADM2\nMULTIPOLYGON (((125.91087 8.85625, 125.91461 8...\n\n\n3\nAklan\nNone\nPHL-ADM2-3_0_0-B4\nPHL\nADM2\nMULTIPOLYGON (((122.43667 11.59833, 122.43667 ...\n\n\n4\nAlbay\nNone\nPHL-ADM2-3_0_0-B5\nPHL\nADM2\nMULTIPOLYGON (((123.28764 13.04923, 123.28686 ...\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n76\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\nMULTIPOLYGON (((119.46694 4.58694, 119.46639 4...\n\n\n77\nZambales\nNone\nPHL-ADM2-3_0_0-B78\nPHL\nADM2\nMULTIPOLYGON (((120.08285 14.75048, 120.08222 ...\n\n\n78\nZamboanga del Norte\nNone\nPHL-ADM2-3_0_0-B79\nPHL\nADM2\nMULTIPOLYGON (((122.09467 7.53152, 122.09467 7...\n\n\n79\nZamboanga del Sur\nNone\nPHL-ADM2-3_0_0-B80\nPHL\nADM2\nMULTIPOLYGON (((122.06223 6.87278, 122.0625 6....\n\n\n80\nZamboanga Sibugay\nNone\nPHL-ADM2-3_0_0-B81\nPHL\nADM2\nMULTIPOLYGON (((122.84063 7.27694, 122.84048 7...\n\n\n\n\n81 rows × 6 columns\n\n\n\n\nadmin_bounds.plot(facecolor=\"none\", edgecolor=\"blue\");\n\n\n\n\n\n\n\n\n\n# admin_bounds.explore()\n\n\n\nStep 4: Get spatial join with highest intersection\n\noutput = spatial_join.get_highest_intersection(grid, admin_bounds, \"EPSG:32651\")\n\n\nNote that each grid now has admin bounds columns (shapeName, shapeISO, shapeID, … etc.) based on the intersection with the admin boundaries with the highest overlapping area over each grid.\n\n\noutput\n\n\n\n\n\n\n\n\ngeometry\nx\ny\nshapeName\nshapeISO\nshapeID\nshapeGroup\nshapeType\n\n\n\n\n0\nPOLYGON ((118.27581 5.92871, 118.72497 5.92871...\n3\n3\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n1\nPOLYGON ((117.82665 5.92871, 118.27581 5.92871...\n2\n3\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n2\nPOLYGON ((118.27581 6.37528, 118.72497 6.37528...\n3\n4\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n3\nPOLYGON ((118.27581 6.82146, 118.72497 6.82146...\n3\n5\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n4\nPOLYGON ((116.92834 7.26723, 117.37749 7.26723...\n0\n6\nPalawan\nNone\nPHL-ADM2-3_0_0-B59\nPHL\nADM2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n318\nPOLYGON ((125.46233 5.03451, 125.91149 5.03451...\n19\n1\nDavao del Sur\nNone\nPHL-ADM2-3_0_0-B28\nPHL\nADM2\n\n\n319\nPOLYGON ((125.46233 9.93163, 125.91149 9.93163...\n19\n12\nDinagat Islands\nNone\nPHL-ADM2-3_0_0-B30\nPHL\nADM2\n\n\n320\nPOLYGON ((125.46233 10.37375, 125.91149 10.373...\n19\n13\nEastern Samar\nNone\nPHL-ADM2-3_0_0-B31\nPHL\nADM2\n\n\n321\nPOLYGON ((125.91149 9.93163, 126.36065 9.93163...\n20\n12\nSurigao del Norte\nNone\nPHL-ADM2-3_0_0-B74\nPHL\nADM2\n\n\n322\nPOLYGON ((125.91149 10.37375, 126.36065 10.373...\n20\n13\nEastern Samar\nNone\nPHL-ADM2-3_0_0-B31\nPHL\nADM2\n\n\n\n\n323 rows × 8 columns\n\n\n\n\noutput.plot(facecolor=\"none\", edgecolor=\"blue\");\n\n\n\n\n\n\n\n\n\n# output.explore()",
    "crumbs": [
      "Tutorials",
      "Spatial Join Using Highest Intersection Tutorial"
    ]
  },
  {
    "objectID": "tutorial.raster_zonal_stats.html",
    "href": "tutorial.raster_zonal_stats.html",
    "title": "Raster Zonal Stats Tutorial",
    "section": "",
    "text": "A basic introduction to raster zonal stats",
    "crumbs": [
      "Tutorials",
      "Raster Zonal Stats Tutorial"
    ]
  },
  {
    "objectID": "tutorial.raster_zonal_stats.html#basic-usage",
    "href": "tutorial.raster_zonal_stats.html#basic-usage",
    "title": "Raster Zonal Stats Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nGenerate zonal stats for a GeoDataframe containing areas of interest using raster data\nTerms:\n\naoi - (area of interest) a geodataframe which we are interested in generating zonal statistics for\nraster data - the source raster containing the features which we are interested in collecting zonal stats for our aoi.\n\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport geowrangler.raster_zonal_stats as rzs\nimport numpy as np\n\n\nLoad AOI\nOur areas of interest (AOI) are three (3) Level 1 administration regions (ADM1) of the Philippines located in the island of Luzon.\n\n# area multipolygons for regions 3,4,ncr of the philippines\naoi = gpd.read_file(\"../data/region34ncr_admin.geojson\")\n\nCPU times: user 1.42 s, sys: 118 ms, total: 1.54 s\nWall time: 1.57 s\n\n\n\nax = aoi.plot(\n    ax=plt.axes(),\n    facecolor=\"none\",\n    edgecolor=[\n        \"#C62828\",\n        \"#283593\",\n        \"#FF9800\",\n    ],\n)\n\n\n\n\n\n\n\n\n\naoi\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n\n\n\n\n\n\n\n\n\nDownload Philippine Population Data\n\nsee the Humanitarian Data Exchange World Population Counts - Philippines\n\nWe download our raster Data as GeoTiff files from the Humanitarian Data Exchange site.\n\n\n\n\n\n\nNote\n\n\n\nThis maybe slow as the file is about 180 Mb and depending on your internet download speed may take more than 5 minutes.\n\n\n\n# PHL population HDX links\nphil_pop_link = \"https://data.worldpop.org/GIS/Population/Global_2000_2020/2020/PHL/phl_ppp_2020.tif\"\nphil_pop_dset = \"phl_pop_2020.tif\"\n\n\n![ ! -e ../data/{phil_pop_dset} ] && curl -o ../data/{phil_pop_dset} {phil_pop_link}\n\nCPU times: user 988 µs, sys: 3.26 ms, total: 4.25 ms\nWall time: 287 ms\n\n\nTo create our raster zonal stats, we just need to set the aggregations, as well as some extra arguments, such as the nodata value in the raster.\n\nresults = rzs.create_raster_zonal_stats(\n    aoi,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        column=\"population\",\n        output=[\"population_count\", \"samples\"],\n    ),\n    extra_args=dict(nodata=-99999),  # nodata value is -99999\n)\n\nCPU times: user 6.15 s, sys: 195 ms, total: 6.34 s\nWall time: 6.49 s\n\n\n\nresults\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\nsamples\npopulation_count\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n70786\n13165866.0\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n2558377\n11493727.0\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n1876244\n15952383.0\n\n\n\n\n\n\n\n\n\nUsing Grid Tile AOIs\nWe can also use tile grids as our AOIs.\n\n# note that you don't need to load the aoi first\ngrid_aoi_file = \"../data/region3_admin_grids.geojson\"\n\n\ngrid_aoi_results = rzs.create_raster_zonal_stats(\n    grid_aoi_file,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        column=\"population\",\n        output=[\"population_count\", \"samples\"],\n        fillna=[True, True],\n    ),\n    extra_args=dict(nodata=-99999),  # nodata value is -99999\n)\n\nCPU times: user 5.15 s, sys: 657 ms, total: 5.81 s\nWall time: 5.97 s\n\n\n\ngrid_aoi_results.head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nsamples\npopulation_count\n\n\n\n\n0\n0\n30\nPOLYGON ((119.78583 15.7087, 119.83075 15.7087...\n171\n1171.764038\n\n\n1\n0\n31\nPOLYGON ((119.78583 15.75193, 119.83075 15.751...\n329\n278.567200\n\n\n2\n0\n32\nPOLYGON ((119.78583 15.79516, 119.83075 15.795...\n345\n279.140198\n\n\n3\n1\n30\nPOLYGON ((119.83075 15.7087, 119.87566 15.7087...\n158\n808.681152\n\n\n4\n1\n32\nPOLYGON ((119.83075 15.79516, 119.87566 15.795...\n20\n0.000000\n\n\n\n\n\n\n\n\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"black\"\n)\nax = grid_aoi_results.plot(\n    ax=ax, column=\"population_count\", edgecolor=\"blue\", alpha=0.5\n)\n\n\n\n\n\n\n\n\n\n\nUsing Bing Tile Grid Tile AOIs\nWe can also use pre-existing Bing tile grids as our AOIs.\n\n# note that you don't need to load the aoi first\nbingtile_grid_aoi_file = \"../data/region3_bingtile_grid13.geojson\"\n\n\nbingtile_grid_aoi_results = rzs.create_raster_zonal_stats(\n    bingtile_grid_aoi_file,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        column=\"population\",\n        output=[\"population_count\", \"samples\"],\n        fillna=[True, True],\n    ),\n    extra_args=dict(nodata=-99999),  # nodata value is -99999\n)\n\nCPU times: user 5.17 s, sys: 486 ms, total: 5.65 s\nWall time: 5.71 s\n\n\n\nbingtile_grid_aoi_results.head()\n\n\n\n\n\n\n\n\nquadkey\ngeometry\nsamples\npopulation_count\n\n\n\n\n0\n1323030303301\nPOLYGON ((120.10254 14.73239, 120.10254 14.774...\n737\n196.756744\n\n\n1\n1323030303300\nPOLYGON ((120.05859 14.73239, 120.05859 14.774...\n50\n35.732861\n\n\n2\n1323030303311\nPOLYGON ((120.19043 14.73239, 120.19043 14.774...\n248\n383.338013\n\n\n3\n1323030303133\nPOLYGON ((120.19043 14.77488, 120.19043 14.817...\n901\n5621.879395\n\n\n4\n1323030303131\nPOLYGON ((120.19043 14.81737, 120.19043 14.859...\n1328\n6584.988770\n\n\n\n\n\n\n\n\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"black\"\n)\nax = bingtile_grid_aoi_results.plot(\n    ax=ax, column=\"population_count\", edgecolor=\"blue\", alpha=0.5\n)",
    "crumbs": [
      "Tutorials",
      "Raster Zonal Stats Tutorial"
    ]
  },
  {
    "objectID": "tutorial.raster_zonal_stats.html#exactextract-usage-experimental",
    "href": "tutorial.raster_zonal_stats.html#exactextract-usage-experimental",
    "title": "Raster Zonal Stats Tutorial",
    "section": "Exactextract Usage (experimental)",
    "text": "Exactextract Usage (experimental)\nraster_zonal_stats also includes an experimental method create_exactextract_zonal_stats() which uses the exactextract python package. This method offers the ff. advantages over the basic usage: - Faster and more accurate statistics vs basic method - Support for multi-band rasters - Support for weighted statistics\n\n\n\n\n\n\nWarning\n\n\n\nThe exactextract method is still experimental and is subject to change in future releases. Values between the basic and exactextract method will also differ for the same input AOI and raster.\n\n\n\nReplicate basic usage using exactextract\nIn this section, we demonstrate the zonal statistics performed for the same ff. aois using the create_exactextract_zonal_stats method. 1. Philippines ADM1 regions 2. Grid Tile AOIs 3. Bing Tile Grid Tile AOIs\n\n\n\n\n\n\nNote\n\n\n\nWhile create_raster_zonal_stats() and create_exactextract_zonal_stats() share a similar interface, in for the latter method, it is required to specify a band for each entry for aggregation.\n\n\n\nADM1 AOIs (exactextract)\n\nresults = rzs.create_exactextract_zonal_stats(\n    aoi,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        band=1,\n        output=[\"population_count\", \"samples\"],\n    )\n)\n\nCPU times: user 1.74 s, sys: 135 ms, total: 1.88 s\nWall time: 1.9 s\n\n\n\nresults\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\npopulation_count\nsamples\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n13165218.0\n7.076045e+04\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n11497926.0\n2.558353e+06\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n15954625.0\n1.876141e+06\n\n\n\n\n\n\n\n\n\nGrid Tile AOIs (exactextract)\n\ngrid_aoi_results = rzs.create_exactextract_zonal_stats(\n    grid_aoi_file,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        band=1,\n        output=[\"population_count\", \"samples\"]\n    )\n)\n\nCPU times: user 533 ms, sys: 15.7 ms, total: 549 ms\nWall time: 551 ms\n\n\n\ngrid_aoi_results\n\n\n\n\n\n\n\n\nx\ny\ngeometry\npopulation_count\nsamples\n\n\n\n\n0\n0\n30\nPOLYGON ((119.78583 15.7087, 119.83075 15.7087...\n1212.030518\n173.795197\n\n\n1\n0\n31\nPOLYGON ((119.78583 15.75193, 119.83075 15.751...\n275.465424\n323.370850\n\n\n2\n0\n32\nPOLYGON ((119.78583 15.79516, 119.83075 15.795...\n292.621063\n355.625183\n\n\n3\n1\n30\nPOLYGON ((119.83075 15.7087, 119.87566 15.7087...\n794.559692\n162.660583\n\n\n4\n1\n32\nPOLYGON ((119.83075 15.79516, 119.87566 15.795...\n0.000000\n20.000000\n\n\n...\n...\n...\n...\n...\n...\n\n\n1069\n54\n44\nPOLYGON ((122.21128 16.31312, 122.2562 16.3131...\n328.646301\n43.474117\n\n\n1070\n54\n45\nPOLYGON ((122.21128 16.35623, 122.2562 16.3562...\n2358.856445\n1147.846558\n\n\n1071\n54\n46\nPOLYGON ((122.21128 16.39932, 122.2562 16.3993...\n1703.188232\n493.368500\n\n\n1072\n54\n47\nPOLYGON ((122.21128 16.4424, 122.2562 16.4424,...\n416.854004\n980.471924\n\n\n1073\n54\n48\nPOLYGON ((122.21128 16.48548, 122.2562 16.4854...\n1106.191162\n2172.363037\n\n\n\n\n1074 rows × 5 columns\n\n\n\n\n\nBing Tile Grid Tile AOIs (exactextract)\n\nbingtile_grid_aoi_results = rzs.create_exactextract_zonal_stats(\n    bingtile_grid_aoi_file,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        band=1,\n        output=[\"population_count\", \"samples\"]\n    )\n)\n\nCPU times: user 554 ms, sys: 16.4 ms, total: 570 ms\nWall time: 581 ms\n\n\n\nbingtile_grid_aoi_results\n\n\n\n\n\n\n\n\nquadkey\ngeometry\npopulation_count\nsamples\n\n\n\n\n0\n1323030303301\nPOLYGON ((120.10254 14.73239, 120.10254 14.774...\n201.693375\n756.642822\n\n\n1\n1323030303300\nPOLYGON ((120.05859 14.73239, 120.05859 14.774...\n33.127304\n44.116634\n\n\n2\n1323030303311\nPOLYGON ((120.19043 14.73239, 120.19043 14.774...\n388.166870\n253.282425\n\n\n3\n1323030303133\nPOLYGON ((120.19043 14.77488, 120.19043 14.817...\n5789.487793\n904.081543\n\n\n4\n1323030303131\nPOLYGON ((120.19043 14.81737, 120.19043 14.859...\n6430.809570\n1322.331665\n\n\n...\n...\n...\n...\n...\n\n\n1119\n1323030120123\nPOLYGON ((119.75098 15.79225, 119.75098 15.834...\n155.952072\n227.437897\n\n\n1120\n1323030120301\nPOLYGON ((119.75098 15.74996, 119.75098 15.792...\n109.296829\n128.834396\n\n\n1121\n1323030120132\nPOLYGON ((119.79492 15.79225, 119.79492 15.834...\n177.168594\n193.092102\n\n\n1122\n1323030120310\nPOLYGON ((119.79492 15.74996, 119.79492 15.792...\n136.064529\n134.635620\n\n\n1123\n1323030120133\nPOLYGON ((119.83887 15.79225, 119.83887 15.834...\n0.000000\n25.502230\n\n\n\n\n1124 rows × 4 columns\n\n\n\n\n\n\nMulti-band Usage\ncreate_exactextract_zonal_stats() supports multi-band statistics calculations by specifying a different aggregation per band.\nFor this demo, we use Sentinel-5P aerosol absorbing index, which contains 2 bands for aersols at 340nm and 380nm diameter.\n\nexactextract_multiband_results = rzs.create_exactextract_zonal_stats(\n    grid_aoi_file,\n    \"../data/ph_s5p_AER_AI_340_380.tiff\",\n    aggregation=[\n        dict(band=1, func=[\"mean\", \"sum\"], output=[\"mean absorbing aerosol index (340nm)\", \"sample_count\"]),\n        dict(band=2, func=[\"mean\", \"sum\"], output=\"aer_ai_380nm\"), \n    ]\n)\n\n\nexactextract_multiband_results.sort_values(by=\"sample_count\", ascending=False)\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nmean absorbing aerosol index (340nm)\nsample_count\naer_ai_380nm_mean\naer_ai_380nm_sum\n\n\n\n\n34\n4\n25\nPOLYGON ((119.9655 15.49239, 120.01041 15.4923...\n0.098937\n0.049710\n0.753341\n0.378512\n\n\n33\n4\n24\nPOLYGON ((119.9655 15.4491, 120.01041 15.4491,...\n0.087453\n0.043949\n0.665897\n0.334646\n\n\n56\n5\n25\nPOLYGON ((120.01041 15.49239, 120.05533 15.492...\n0.030743\n0.015447\n0.242179\n0.121682\n\n\n55\n5\n24\nPOLYGON ((120.01041 15.4491, 120.05533 15.4491...\n0.027175\n0.013657\n0.239243\n0.120231\n\n\n20\n3\n25\nPOLYGON ((119.92058 15.49239, 119.9655 15.4923...\n0.009051\n0.004548\n0.068916\n0.034626\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n367\n16\n30\nPOLYGON ((120.50449 15.7087, 120.5494 15.7087,...\n0.000000\n0.000000\n0.000048\n0.000024\n\n\n368\n16\n31\nPOLYGON ((120.50449 15.75193, 120.5494 15.7519...\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n369\n17\n0\nPOLYGON ((120.5494 14.40753, 120.59432 14.4075...\n0.000000\n0.000000\n0.003331\n0.001682\n\n\n370\n17\n1\nPOLYGON ((120.5494 14.45102, 120.59432 14.4510...\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n1073\n54\n48\nPOLYGON ((122.21128 16.48548, 122.2562 16.4854...\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n\n\n1074 rows × 7 columns\n\n\n\n\n\nOther options\nThis section demonstrates other options that you can pass to create_exactextract_zonal_stats()\nIf include_geom=False the result is returned without the active geometry column.\n\nno_geom_results = rzs.create_exactextract_zonal_stats(\n    grid_aoi_file,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        band=1,\n        output=[\"population_count\", \"samples\"]\n    ),\n    include_geom=False\n)\nno_geom_results\n\nCPU times: user 536 ms, sys: 14.8 ms, total: 551 ms\nWall time: 552 ms\n\n\n\n\n\n\n\n\n\nx\ny\npopulation_count\nsamples\n\n\n\n\n0\n0\n30\n1212.030518\n173.795197\n\n\n1\n0\n31\n275.465424\n323.370850\n\n\n2\n0\n32\n292.621063\n355.625183\n\n\n3\n1\n30\n794.559692\n162.660583\n\n\n4\n1\n32\n0.000000\n20.000000\n\n\n...\n...\n...\n...\n...\n\n\n1069\n54\n44\n328.646301\n43.474117\n\n\n1070\n54\n45\n2358.856445\n1147.846558\n\n\n1071\n54\n46\n1703.188232\n493.368500\n\n\n1072\n54\n47\n416.854004\n980.471924\n\n\n1073\n54\n48\n1106.191162\n2172.363037\n\n\n\n\n1074 rows × 4 columns\n\n\n\nBy specifying include_cols, the result will return only the specified columns from the AOI in addition to the aggregation results.\n\ninclude_cols_results = rzs.create_exactextract_zonal_stats(\n    grid_aoi_file,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        band=1,\n        output=[\"population_count\", \"samples\"]\n    ),\n    include_cols=[\"x\"]\n)\ninclude_cols_results\n\nCPU times: user 534 ms, sys: 15.7 ms, total: 550 ms\nWall time: 557 ms\n\n\n\n\n\n\n\n\n\nx\npopulation_count\nsamples\n\n\n\n\n0\n0\n1212.030518\n173.795197\n\n\n1\n0\n275.465424\n323.370850\n\n\n2\n0\n292.621063\n355.625183\n\n\n3\n1\n794.559692\n162.660583\n\n\n4\n1\n0.000000\n20.000000\n\n\n...\n...\n...\n...\n\n\n1069\n54\n328.646301\n43.474117\n\n\n1070\n54\n2358.856445\n1147.846558\n\n\n1071\n54\n1703.188232\n493.368500\n\n\n1072\n54\n416.854004\n980.471924\n\n\n1073\n54\n1106.191162\n2172.363037\n\n\n\n\n1074 rows × 3 columns\n\n\n\n\n\nComparison of exactextract and rasterstats\n\nProcessing time\nThe following section compares the mean processing time of exactextract vs rasterstats over 10 iterations of equivalent function calls.\nAs an example from one notebook run: - rasterstats: 11.6 s ± 1.16 s -&gt; equivalent to 11,600 ms - exactextract: 763 ms ± 46.1 ms - Resulting speed-up: ~15x faster\n\nrasterstats_results = rzs.create_raster_zonal_stats(\n    grid_aoi_file,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        column=\"population\",\n        output=[\"population_count\", \"samples\"]\n    ),\n    extra_args=dict(nodata=-99999),  # nodata value is -99999\n)\n\n5.43 s ± 73.1 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n\n\n\nexactextract_results = rzs.create_exactextract_zonal_stats(\n    grid_aoi_file,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        band=1,\n        output=[\"population_count\", \"samples\"]\n    )\n)\n\n552 ms ± 5.91 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n\n\n\n\nOutput value comparison\nWe also compare the difference in values between the two methods. Output from the two methods may differ significantly because of the way the pixels are distributed to each AOI. The difference also becomes more significant with smaller AOIs and coarser input rasters, as these factors increase the amount of pixels that are located along AOI boundaries.\n\nrasterstats_results = rzs.create_raster_zonal_stats(\n    grid_aoi_file,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\"],\n        column=\"population\",\n        output=[\"population_count\"]\n    ),\n    extra_args=dict(nodata=-99999),  # nodata value is -99999\n)\n\n\nexactextract_results = rzs.create_exactextract_zonal_stats(\n    grid_aoi_file,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\"],\n        band=1,\n        output=[\"population_count\"]\n    )\n)\n\n\npercent_difference = (np.abs(exactextract_results[\"population_count\"] - rasterstats_results[\"population_count\"])/rasterstats_results[\"population_count\"]) * 100\nprint(f\"Mean percent difference between exactextract and rasterstats: {np.mean(percent_difference):.2f}%\")\nprint(f\"Median percent difference: {np.nanmedian(percent_difference):.2f}%\")\nprint(f\"Max percent difference: {np.max(percent_difference):.2f}%\")\nprint(f\"Min percent difference: {np.min(percent_difference):.2f}%\")\n\nMean percent difference between exactextract and rasterstats: 1.33%\nMedian percent difference: 0.80%\nMax percent difference: 25.71%\nMin percent difference: 0.00%\n\n\n\n\nRecommendations\nWe make the following recommendations on when to use each method.\nUse create_raster_zonal_stats() (rasterstats) if: - You are working with kilometer-scale AOIs, where the processing time trade-off is acceptable - You need to set the NODATA value during the function call - You are working with legacy projects using older versions of geowrangler, and/or relying on results previously generated from create_raster_zonal_stats().\nUse create_exactextract_zonal_stats() (exactextract) if: - You are working with meter-scale AOIs, such that the processing time improvement is crucial - Your rasters are well-defined with NODATA properly set in the metadata. The method does not currently support setting NODATA in the function call and only relies on reading the raster metadata. - You are working on a new project with no prior dependencies to create_raster_zonal_stats().",
    "crumbs": [
      "Tutorials",
      "Raster Zonal Stats Tutorial"
    ]
  },
  {
    "objectID": "area_zonal_stats.html",
    "href": "area_zonal_stats.html",
    "title": "Area Zonal Stats",
    "section": "",
    "text": "source",
    "crumbs": [
      "Module Reference",
      "Area Zonal Stats"
    ]
  },
  {
    "objectID": "area_zonal_stats.html#test-data",
    "href": "area_zonal_stats.html#test-data",
    "title": "Area Zonal Stats",
    "section": "Test data",
    "text": "Test data\n\nSimple squares\nGiven an aoi (simple_aoi) and geodataframe containing sample data (simple_data)\n\nsimple_aoi\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n\n\n3\nPOLYGON ((3 0, 3 1, 4 1, 4 0, 3 0))\n\n\n4\nPOLYGON ((4 0, 4 1, 5 1, 5 0, 4 0))\n\n\n\n\n\n\n\n\nsimple_data\n\n\n\n\n\n\n\n\ngeometry\npopulation\ninternet_speed\n\n\n\n\n0\nPOLYGON ((0.25 0, 0.25 1, 1.25 1, 1.25 0, 0.25...\n100\n20.0\n\n\n1\nPOLYGON ((1.25 0, 1.25 1, 2.25 1, 2.25 0, 1.25...\n200\n10.0\n\n\n2\nPOLYGON ((2.25 0, 2.25 1, 3.25 1, 3.25 0, 2.25...\n300\n5.0\n\n\n\n\n\n\n\n\nax = plt.axes()\nax = simple_data.plot(\n    ax=ax, color=[\"orange\", \"brown\", \"purple\"], edgecolor=\"yellow\", alpha=0.4\n)\nax = simple_aoi.plot(\n    ax=ax, facecolor=\"none\", edgecolor=[\"r\", \"g\", \"b\", \"orange\", \"purple\"]\n)\n\n\n\n\n\n\n\n\nThe red,green,blue, orange and purple outlines are the 5 regions of interest (aoi) while the orange,brown, purple areas are the data areas.\n\nempty_aoi_results = create_area_zonal_stats(simple_aoi, simple_data)\n\n\nempty_aoi_results\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n0.75\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n1.00\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n1.00\n\n\n3\nPOLYGON ((3 0, 3 1, 4 1, 4 0, 3 0))\n0.25\n\n\n4\nPOLYGON ((4 0, 4 1, 5 1, 5 0, 4 0))\n0.00\n\n\n\n\n\n\n\n\nsimple_aoi_results = create_area_zonal_stats(\n    simple_aoi,\n    simple_data,\n    [\n        dict(func=\"count\", output=\"sample_count\"),\n        dict(func=[\"sum\", \"count\"], column=\"population\"),\n        dict(func=[\"mean\", \"max\", \"min\", \"std\"], column=\"internet_speed\"),\n    ],\n)\n\nCPU times: user 11.3 ms, sys: 1.23 ms, total: 12.5 ms\nWall time: 12.9 ms\n\n\n\nsimple_aoi_results\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\nsample_count\npopulation_sum\npopulation_count\ninternet_speed_mean\ninternet_speed_max\ninternet_speed_min\ninternet_speed_std\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n0.75\n1.0\n75.0\n1.0\n15.000\n20.0\n0.0\nNaN\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n1.00\n2.0\n175.0\n2.0\n6.250\n20.0\n10.0\n7.071068\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n1.00\n2.0\n275.0\n2.0\n3.125\n10.0\n5.0\n3.535534\n\n\n3\nPOLYGON ((3 0, 3 1, 4 1, 4 0, 3 0))\n0.25\n1.0\n75.0\n1.0\n1.250\n5.0\n0.0\nNaN\n\n\n4\nPOLYGON ((4 0, 4 1, 5 1, 5 0, 4 0))\n0.00\nNaN\nNaN\nNaN\nNaN\nNaN\n0.0\nNaN\n\n\n\n\n\n\n\n\nsimple_aoi_results.population_sum.sum(axis=None)\n\nnp.float64(600.0)\n\n\n\ncorrected_aoi_results = create_area_zonal_stats(\n    simple_aoi,\n    simple_data,\n    [\n        dict(func=[\"sum\", \"count\"], column=\"population\"),\n        dict(\n            func=[\"mean\", \"imputed_mean\", \"raw_max\", \"raw_min\", \"raw_std\"],\n            column=\"internet_speed\",\n            output=[\n                \"internet_speed_mean\",\n                \"internet_speed_imputed_mean\",\n                \"internet_speed_max\",\n                \"internet_speed_min\",\n                \"internet_speed_std\",\n            ],\n        ),\n    ],\n    fix_min=False,\n)\n\nCPU times: user 11.7 ms, sys: 849 µs, total: 12.5 ms\nWall time: 12.1 ms\n\n\n\ncorrected_aoi_results\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\npopulation_sum\npopulation_count\ninternet_speed_mean\ninternet_speed_imputed_mean\ninternet_speed_max\ninternet_speed_min\ninternet_speed_std\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n0.75\n75.0\n1.0\n15.000\n20.000\n20.0\n20.0\nNaN\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n1.00\n175.0\n2.0\n6.250\n6.250\n20.0\n10.0\n7.071068\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n1.00\n275.0\n2.0\n3.125\n3.125\n10.0\n5.0\n3.535534\n\n\n3\nPOLYGON ((3 0, 3 1, 4 1, 4 0, 3 0))\n0.25\n75.0\n1.0\n1.250\n5.000\n5.0\n5.0\nNaN\n\n\n4\nPOLYGON ((4 0, 4 1, 5 1, 5 0, 4 0))\n0.00\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\naois_no_nas = create_area_zonal_stats(\n    simple_aoi,\n    simple_data,\n    [\n        dict(func=[\"sum\", \"count\"], column=\"population\", fillna=[True, True]),\n        dict(\n            func=[\"mean\", \"imputed_mean\", \"raw_max\", \"raw_min\", \"raw_std\"],\n            column=\"internet_speed\",\n            output=[\n                \"internet_speed_mean\",\n                \"internet_speed_imputed_mean\",\n                \"internet_speed_max\",\n                \"internet_speed_min\",\n                \"internet_speed_std\",\n            ],\n            fillna=[True, True, True, True, True],\n        ),\n    ],\n    fix_min=False,\n)\n\nCPU times: user 12.1 ms, sys: 679 µs, total: 12.8 ms\nWall time: 12.3 ms\n\n\n\naois_no_nas\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\npopulation_sum\npopulation_count\ninternet_speed_mean\ninternet_speed_imputed_mean\ninternet_speed_max\ninternet_speed_min\ninternet_speed_std\n\n\n\n\n0\nPOLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))\n0.75\n75.0\n1.0\n15.000\n20.000\n20.0\n20.0\n0.000000\n\n\n1\nPOLYGON ((1 0, 1 1, 2 1, 2 0, 1 0))\n1.00\n175.0\n2.0\n6.250\n6.250\n20.0\n10.0\n7.071068\n\n\n2\nPOLYGON ((2 0, 2 1, 3 1, 3 0, 2 0))\n1.00\n275.0\n2.0\n3.125\n3.125\n10.0\n5.0\n3.535534\n\n\n3\nPOLYGON ((3 0, 3 1, 4 1, 4 0, 3 0))\n0.25\n75.0\n1.0\n1.250\n5.000\n5.0\n5.0\n0.000000\n\n\n4\nPOLYGON ((4 0, 4 1, 5 1, 5 0, 4 0))\n0.00\n0.0\n0.0\n0.000\n0.000\n0.0\n0.0\n0.000000",
    "crumbs": [
      "Module Reference",
      "Area Zonal Stats"
    ]
  },
  {
    "objectID": "polygon_fill.html#overview",
    "href": "polygon_fill.html#overview",
    "title": "Polygon Fill",
    "section": "Overview",
    "text": "Overview\nWe will go over utility functions that leverage these 2 algorithms for filling in pixels in polygons fast:\n\nVoxel Traversal Algorithm: We use this for filling in pixels along the polygon boundary. 2D voxel traversal is used for every line segment of the polygon boundary.\nScanline Fill Algorithm: We use this for filling in pixels in the polygon interior.\n\nThe utility functions are currently used in FastSquareGridGenerator and FastBingTileGridGenerator\nAt the end of this notebook, there’s a section for error correction using off-boundary pixels.\n\nIn a nutshell, how do we speed up polygon fill?\n\nTranslate polygons from geographic coordinates (epsg:4326, epsg:3857) to pixel coordinates (integers only)\nUse the fast polygon fill algorithms to get the polygon pixels and off-boundary pixels (focus of this notebook)\nTranslate pixels back from pixel coordinates to geographic coordinates (square polygons)\nPerform off-boundary pixel error correction\n\nThis notebook focuses on the fast polygon fill algorithms, while the translation functions and error correction proper are found in FastSquareGridGenerator and FastBingTileGridGenerator.\n\npolygon_test_cases = {\n    \"Square\": [(0, 0), (10, 0), (10, 10), (0, 10)],\n    \"Triangle\": [(0, 0), (10, 0), (5, 10)],\n    \"Right Triangle\": [(0, 0), (10, 0), (0, 10)],\n    \"Pentagon\": [(2, 0), (8, 0), (10, 6), (5, 10), (0, 6)],\n    \"Star\": [\n        (6, 2),\n        (8, 8),\n        (12, 8),\n        (9, 12),\n        (11, 18),\n        (6, 14),\n        (1, 18),\n        (3, 12),\n        (0, 8),\n        (4, 8),\n    ],\n\n    \"Complex Shape 1\": [(0, 0), (5, 2), (3, 5), (8, 8), (5, 10), (0, 7)],\n    \"Complex Shape 2\": [\n        (0, 0),\n        (2, 6),\n        (4, 10),\n        (6, 8),\n        (8, 12),\n        (10, 4),\n        (12, 2),\n        (8, 0),\n    ],\n    \"Complex Shape 3\": [(2, 3), (5, 3), (6, 6), (3, 7), (1, 5)],\n    \"Complex Shape 4\": [(1, 1), (2, 5), (4, 3), (6, 7)],\n    \"Complex Shape 5\": [(1, 2), (3, 6), (5, 5), (7, 4), (9, 5), (11, 2)],\n}",
    "crumbs": [
      "Module Reference",
      "Polygon Fill"
    ]
  },
  {
    "objectID": "polygon_fill.html#voxel-traversal",
    "href": "polygon_fill.html#voxel-traversal",
    "title": "Polygon Fill",
    "section": "Voxel Traversal",
    "text": "Voxel Traversal\nWe use the 2D voxel traversal algorithm to fill in pixels between two points.\n\nsource\n\nvoxel_traversal_2d\n\n voxel_traversal_2d (start_vertex:Tuple[int,int],\n                     end_vertex:Tuple[int,int], debug:bool=False)\n\n*Returns all pixels between two points as inspired by Amanatides & Woo’s “A Fast Voxel Traversal Algorithm For Ray Tracing”\nImplementation adapted from https://www.redblobgames.com/grids/line-drawing/ in the supercover lines section\nThis also returns the off-diagonal pixels that can be useful for correcting errors at the corners of polygons during polygon fill*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nstart_vertex\nTuple\n\n\n\n\nend_vertex\nTuple\n\n\n\n\ndebug\nbool\nFalse\nif true, prints diagnostic info for the algorithm\n\n\nReturns\nDict\n\n\n\n\n\nVoxel traversal is used on every line segment to fill the polygon boundary.\n\npolygon_pixels = {}\nfor test_polygon_name, vertices in polygon_test_cases.items():\n    offset_vertices = vertices[1:] + vertices[:1]\n\n    pixels = set()\n    for start_vertex, end_vertex in zip(vertices, offset_vertices):\n        pixels.update(voxel_traversal_2d(start_vertex, end_vertex)[\"line_pixels\"])\n\n    polygon_pixels[test_polygon_name] = pixels\n    \nplot_all_polygons(polygon_test_cases, polygon_pixels)",
    "crumbs": [
      "Module Reference",
      "Polygon Fill"
    ]
  },
  {
    "objectID": "polygon_fill.html#scanline-fill-algorithm",
    "href": "polygon_fill.html#scanline-fill-algorithm",
    "title": "Polygon Fill",
    "section": "Scanline Fill Algorithm",
    "text": "Scanline Fill Algorithm\nWe use the scanline fill algorithm to fill in pixels within the polygon boundary.\n\nsource\n\nscanline_fill\n\n scanline_fill (vertices:List[Tuple[int,int]], debug:bool=False)\n\nReturns all pixels within the interior of a polygon defined by vertices\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nvertices\nList\n\nlist of polygon vertices in order (either clockwise or counterclockwise)\n\n\ndebug\nbool\nFalse\nif true, prints diagnostic info for the algorithm\n\n\nReturns\nSet\n\n\n\n\n\nWe use scanline fill on every set of vertices. Notice that the scanline can fill parts of the boundary as well, but it doesn’t capture the entire boundary.\n\npolygon_pixels = {}\nfor test_polygon_name, vertices in polygon_test_cases.items():\n    polygon_pixels[test_polygon_name] = scanline_fill(vertices)\n    \nplot_all_polygons(polygon_test_cases, polygon_pixels)",
    "crumbs": [
      "Module Reference",
      "Polygon Fill"
    ]
  },
  {
    "objectID": "polygon_fill.html#combining-voxel-traversal-and-scanline-fill-for-our-polygon-fill-algorithm",
    "href": "polygon_fill.html#combining-voxel-traversal-and-scanline-fill-for-our-polygon-fill-algorithm",
    "title": "Polygon Fill",
    "section": "Combining Voxel Traversal and Scanline Fill for our Polygon Fill Algorithm",
    "text": "Combining Voxel Traversal and Scanline Fill for our Polygon Fill Algorithm\n\nsource\n\nvoxel_traversal_scanline_fill\n\n voxel_traversal_scanline_fill (vertices_df:Union[pandas.core.frame.DataFr\n                                ame,polars.dataframe.frame.DataFrame],\n                                x_col:str='x', y_col:str='y',\n                                debug:bool=False)\n\n*Returns pixels that intersect a polygon.\nThis uses voxel traversal to fill the boundary, and scanline fill for the interior. All coordinates are assumed to be integers.\nThis also returns the off-boundary pixels that can be useful for correcting errors at the corners of polygons during polygon fill*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nvertices_df\nUnion\n\ndataframe with x_col and y_col for the polygon vertices\n\n\nx_col\nstr\nx\n\n\n\ny_col\nstr\ny\n\n\n\ndebug\nbool\nFalse\nif true, prints diagnostic info for both voxel traversal and scanline fill algorithms\n\n\nReturns\nDict\n\n\n\n\n\nBy using both algorithms, we can fill all the pixels per polygon.\n\npolygon_pixels = {}\nfor test_polygon_name, vertices in polygon_test_cases.items():\n    vertices_df = pd.DataFrame(vertices, columns=[\"x\", \"y\"])\n    polygon_pixels[test_polygon_name] = voxel_traversal_scanline_fill(vertices_df)[\"polygon_pixels\"]\n    \nplot_all_polygons(polygon_test_cases, polygon_pixels)",
    "crumbs": [
      "Module Reference",
      "Polygon Fill"
    ]
  },
  {
    "objectID": "polygon_fill.html#putting-it-all-together-to-fill-multiple-polygons-in-a-geodataframe",
    "href": "polygon_fill.html#putting-it-all-together-to-fill-multiple-polygons-in-a-geodataframe",
    "title": "Polygon Fill",
    "section": "Putting it all together to fill multiple polygons in a GeoDataFrame",
    "text": "Putting it all together to fill multiple polygons in a GeoDataFrame\nHere we build up to the fast_polygon_fill function that can fill in multiple polygons and MultiPolygon geometries in an AOI. This essentially means using voxel_traversal_scanline_fill on each individual polygon in the AOI.\n\nmultipolygon_dict = {\n    \"Square\": Polygon([(15, 0), (25, 0), (25, 10), (15, 10)]),\n    \"Triangle MultiPolygon\": MultiPolygon(polygons = [\n        Polygon([(0, 0), (10, 0), (5, 10)]), \n        Polygon([(0, 12), (10, 12), (0, 22)])],\n    ),\n    \"Pentagon\": Polygon([(17, 15), (23, 15), (25, 21), (20, 25), (15, 21)]),\n}\n\nmultipolygon_gdf = gpd.GeoDataFrame(geometry=gpd.GeoSeries(multipolygon_dict))\nmultipolygon_gdf.index.name = \"geom_name\"\nmultipolygon_gdf = multipolygon_gdf.reset_index()\nmultipolygon_gdf\n\n\n\n\n\n\n\n\ngeom_name\ngeometry\n\n\n\n\n0\nSquare\nPOLYGON ((15 0, 25 0, 25 10, 15 10, 15 0))\n\n\n1\nTriangle MultiPolygon\nMULTIPOLYGON (((0 0, 10 0, 5 10, 0 0)), ((0 12...\n\n\n2\nPentagon\nPOLYGON ((17 15, 23 15, 25 21, 20 25, 15 21, 1...\n\n\n\n\n\n\n\n\nmultipolygon_gdf.boundary.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nConverting Polygons and MultiPolygons to a list of vertices\nThe polygons_to_vertices function can convert all polygons and multipolygons in a GeoDataFrame to a Polars DataFrame of vertices. This is a preparation step for fast_polygon_fill.\nNote: It is also feasible to convert it to a Pandas DataFrame but using Polars is more efficient for vectorized translations between geographic coordinates and pixel coordinates.\n\nsource\n\n\npolygons_to_vertices\n\n polygons_to_vertices (polys_gdf:geopandas.geodataframe.GeoDataFrame,\n                       unique_id_col:Optional[str]=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npolys_gdf\nGeoDataFrame\n\n\n\n\nunique_id_col\nOptional\nNone\nthe ids under this column will be preserved in the output tiles\n\n\nReturns\nDataFrame\n\n\n\n\n\nThe output is a dataframe of vertices across all polygons.\nIf the original coordinates are based on a geographic coordinate system such as epsg:4326 or epsg:3857, then there would normally need to be an additional step to translate it from geographic coordinates to pixel coordinates. But since our sample polygons are already based on pixel coordinates, then we only need to cast the vertex coordinates x, y to an integer dtype.\n\nvertices_df = polygons_to_vertices(multipolygon_gdf, \"geom_name\")\nvertices_df = vertices_df.cast({\"x\":PIXEL_DTYPE, \"y\":PIXEL_DTYPE})\nvertices_df.head()\n\n\nshape: (5, 4)\n\n\n\ngeom_name\n__subpolygon_id__\nx\ny\n\n\nstr\ni64\ni32\ni32\n\n\n\n\n\"Square\"\n0\n15\n0\n\n\n\"Square\"\n0\n25\n0\n\n\n\"Square\"\n0\n25\n10\n\n\n\"Square\"\n0\n15\n10\n\n\n\"Square\"\n0\n15\n0\n\n\n\n\n\n\n\n\nGetting pixels within each polygon\nThe fast_polygon_fill function is generally a wrapper on voxel_traversal_scanline_fill to find all pixel coordinates within each polygon in the AOI.\n\nsource\n\n\nfast_polygon_fill\n\n fast_polygon_fill (vertices_df:polars.dataframe.frame.DataFrame,\n                    unique_id_col:Optional[str]=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nvertices_df\nDataFrame\n\ninteger vertices of all polygons in the AOI\n\n\nunique_id_col\nOptional\nNone\nthe ids under this column will be preserved in the output tiles\n\n\nReturns\nDict\n\n\n\n\n\nThe output is a polars datafarame containing all the pixels within all the AOI polygons. The unique_id_col parameter can be used to assign to each pixel its corresponding geometry name from the original AOI. This saves us effort from having to perform another spatial join to get the geometry names.\nIf the original AOI is based on a geographic coordinate system such as epsg:4326 or epsg:3857, then there would need to be an additional step to translate it from pixel coordinates back to geographic coordinates. To represent a pixel in geographic coordinates, you would need translate both the lower left corner and upper right corner to represent a rectangular polygon. But in this case it’s not necessary to do the translation since the original AOIs are already based on pixel coordinates. You can refer to the _xy_to_bbox method in FastSquareGridGenerator and FastBingTileGridGenerator for reference.\n\nfilled_polygons = fast_polygon_fill(vertices_df, \"geom_name\")[\"tiles_in_geom\"]\nfilled_polygons.head()\n\n\nshape: (5, 3)\n\n\n\nx\ny\ngeom_name\n\n\ni32\ni32\nstr\n\n\n\n\n18\n10\n\"Square\"\n\n\n8\n1\n\"Triangle MultiPolygon\"\n\n\n8\n12\n\"Triangle MultiPolygon\"\n\n\n20\n20\n\"Pentagon\"\n\n\n3\n0\n\"Triangle MultiPolygon\"\n\n\n\n\n\n\n\n# counting pixels per geometry\nfilled_polygons.group_by(\"geom_name\").len()\n\n\nshape: (3, 2)\n\n\n\ngeom_name\nlen\n\n\nstr\nu32\n\n\n\n\n\"Pentagon\"\n87\n\n\n\"Triangle MultiPolygon\"\n137\n\n\n\"Square\"\n121\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(5,5))\nax = multipolygon_gdf.boundary.plot(ax = ax)\nfor idx, row in filled_polygons.to_pandas().iterrows():\n    x = row[\"x\"]\n    y = row[\"y\"]\n    rect = patches.Rectangle(\n                xy=(x - 0.5, y - 0.5),\n                width=1,\n                height=1,\n                linewidth=1,\n                edgecolor=\"black\",\n                facecolor=\"r\",\n                alpha=0.6,\n            )\n    ax.add_patch(rect)\nplt.show()",
    "crumbs": [
      "Module Reference",
      "Polygon Fill"
    ]
  },
  {
    "objectID": "polygon_fill.html#error-correction-using-off-boundary-pixels",
    "href": "polygon_fill.html#error-correction-using-off-boundary-pixels",
    "title": "Polygon Fill",
    "section": "Error Correction using Off-Boundary Pixels",
    "text": "Error Correction using Off-Boundary Pixels\nOff-boundary pixels are pixels that have at least one corner tangential to an AOI polygon’s edge. They are useful for gridding error correction in FastSquareGridGenerator and FastBingTileGridGenerator.\nWhen we translate a polygon from geographic coordinates to pixel coordinates, we inevitably have to round the polygon vertex coordinates to the nearest higher or lower integer. For some pixels, this rounding results in one of the pixel corners to be just tangent to the translated polygon boundary. But if it were in the original geographic coordinates, the boundary would have had intersected a portion of the pixel’s interior, not just exactly at a corner.\nThus, there will sometimes be pixels that when in geographic coordinates actually intersect the AOI, but when in pixel coordinates are only tangential to the AOI polygon. When we use the fast polygon fill algorithm, it doesn’t consider these tangential pixels, also called off-boundary pixels, as part of the filled-in pixel set. So to correct this error, we need to first identify the off-boundary pixels and then select which ones to add to the filled-in pixel set.\n\nHow do we implement error correction?\nWe determine which pixels to add to the filled-in pixel set by intersecting the polygon boundary linestring with the off-boundary pixel polygon. Both the linestring and the off-boundary pixel polygon should be in geographic coordinates, not pixel coordinates. The pixels that intersect should be added to the filled-in pixel set. You can find this implementation in the generate_grid method under FastSquareGridGenerator and FastBingTileGridGenerator\n\nWhy can’t we just add all of the off-boundary pixels? We can’t because not all of the off-boundary pixels actually intersect the polygon when in geographic coordinates.\nWon’t there be an increased computational cost from using a geometry intersection operation? Yes, this additional step will add compute time but the increase in computational cost should be minimal since we’re doing a linestring to polygon intersection (not a polygon to polygon intersection), and the off-boundary pixels should be a small fraction of the total pixels.\nWhy is error correction not implemented in this notebook? In this particular notebook we’re only working with pixel coordinates, so the translation problem isn’t a concern and we don’t need error correction. It’s a concern when you’re starting off with geographic coordinates, as shown in FastSquareGridGenerator and FastBingTileGridGenerator.\n\nThe section below demonstrates the utility functions for getting off-boundary pixels\n\nGet off-diagonal pixels for a single polygon using voxel_traversal_2d\nGet off-boundary pixels for a single polygon using voxel_traversal_scanline_fill\nGet off-boundary pixels for a GeoDataFrame using fast_polygon_fill\n\n\n\nOff-Diagonal Pixels\nOff-boundary pixels originate from off-diagonal pixels. Off-diagonal pixels occur whenever there is a diagonal step in the voxel traversal algorithm (hence the name).\nNotice below that some of the off-diagonal pixels are in the interior. Later in the voxel_travresal_scanline_fill function we’ll be filtering these further to include only off-diagonal pixels on the polygon’s exterior. The filtered pixels are the off-boundary pixels.\n\noff_diagonal_pixels = {}\nfor test_polygon_name, vertices in polygon_test_cases.items():\n    offset_vertices = vertices[1:] + vertices[:1]\n\n    pixels = set()\n    for start_vertex, end_vertex in zip(vertices, offset_vertices):\n        pixels.update(voxel_traversal_2d(start_vertex, end_vertex)[\"off_diagonal_pixels\"])\n\n    off_diagonal_pixels[test_polygon_name] = pixels\n    \nplot_all_polygons(polygon_test_cases, off_diagonal_pixels)\n\n\n\n\n\n\n\n\n\n\nOff-Boundary Pixels\nOff-boundary pixels are almost the same as the off-diagonal pixels, just filtered to only include pixels on the polygon exterior. These are what we use for gridding error correction.\nInside voxel_traversal_scanline_fill, the filtering is done by getting the set difference between the the off-boundary pixels and the interior pixels from scanline fill.\n\noff_boundary_pixels = {}\nfor test_polygon_name, vertices in polygon_test_cases.items():\n    vertices_df = pd.DataFrame(vertices, columns=[\"x\", \"y\"])\n    off_boundary_pixels[test_polygon_name] = voxel_traversal_scanline_fill(vertices_df)[\"off_boundary_pixels\"]\n    \nplot_all_polygons(polygon_test_cases, off_boundary_pixels)\n\n\n\n\n\n\n\n\n\n\nPutting it all together to get off-boundary pixels of a GeoDataFrame\nThe fast_polygon_fill function also returns the off-boundary pixels across all geometries in a GeoDataFrame\n\nmultipolygon_gdf.head()\n\n\n\n\n\n\n\n\ngeom_name\ngeometry\n\n\n\n\n0\nSquare\nPOLYGON ((15 0, 25 0, 25 10, 15 10, 15 0))\n\n\n1\nTriangle MultiPolygon\nMULTIPOLYGON (((0 0, 10 0, 5 10, 0 0)), ((0 12...\n\n\n2\nPentagon\nPOLYGON ((17 15, 23 15, 25 21, 20 25, 15 21, 1...\n\n\n\n\n\n\n\n\nvertices_df = polygons_to_vertices(multipolygon_gdf, \"geom_name\")\nvertices_df = vertices_df.cast({\"x\":PIXEL_DTYPE, \"y\":PIXEL_DTYPE})\n\ntiles_off_boundary = fast_polygon_fill(vertices_df, \"geom_name\")[\"tiles_off_boundary\"]\ntiles_off_boundary.head()\n\n\nshape: (5, 3)\n\n\n\nx\ny\ngeom_name\n\n\ni32\ni32\nstr\n\n\n\n\n9\n14\n\"Triangle MultiPolygon\"\n\n\n24\n16\n\"Pentagon\"\n\n\n2\n21\n\"Triangle MultiPolygon\"\n\n\n6\n17\n\"Triangle MultiPolygon\"\n\n\n10\n13\n\"Triangle MultiPolygon\"\n\n\n\n\n\n\n\n# counting pixels per geometry\ntiles_off_boundary.group_by(\"geom_name\").len()\n\n\nshape: (2, 2)\n\n\n\ngeom_name\nlen\n\n\nstr\nu32\n\n\n\n\n\"Pentagon\"\n4\n\n\n\"Triangle MultiPolygon\"\n10\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(5,5))\nax = multipolygon_gdf.boundary.plot(ax = ax)\nfor idx, row in tiles_off_boundary.to_pandas().iterrows():\n    x = row[\"x\"]\n    y = row[\"y\"]\n    rect = patches.Rectangle(\n                xy=(x - 0.5, y - 0.5),\n                width=1,\n                height=1,\n                linewidth=1,\n                edgecolor=\"black\",\n                facecolor=\"r\",\n                alpha=0.6,\n            )\n    ax.add_patch(rect)\nplt.show()",
    "crumbs": [
      "Module Reference",
      "Polygon Fill"
    ]
  }
]